{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec9298c3-efe9-40a3-a485-83250611688f",
   "metadata": {},
   "source": [
    "# TODO \n",
    "\n",
    "* Сделай аттеншн"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6092b42-6423-4b4f-81b3-b6ddec64ecf1",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24c94665-4148-40ed-b2a9-516dd3becc7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import tensorflow as tf\n",
    "import tqdm.notebook as tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c231a4b1-bebe-47eb-b428-729791170259",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bob1ch/Рабочий стол/NN-NLP/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#import keras\n",
    "import os\n",
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import sklearn.metrics\n",
    "#import tensorflow as tf\n",
    "import tqdm.notebook as tqdm\n",
    "import sklearn.model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#pytorch\n",
    "\n",
    "import torch\n",
    "# from torcheval.metrics import MultilabelA\n",
    "from torchmetrics.classification import Accuracy\n",
    "#from torchsummary import summary\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9490154-b4d9-4fe5-b596-16b3042d24b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'models'\n",
    "MAX_TOKENS = 32\n",
    "MAX_LENGTH = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c18c6e-1c88-4e6b-8f13-476b78b88a2b",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e38ac2-a5e2-4435-8c95-0982e3039768",
   "metadata": {},
   "source": [
    "Get the dataset from [here](https://tatoeba.org/en/downloads). Preferably use russian to english translations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e09a5d-8537-4ffa-8583-f09c30028b2d",
   "metadata": {},
   "source": [
    "Use a custom tokenizer that can add bos and eos tokens (pass `add_special_tokens=True` when calling the tokenizer to add them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8312a719-f1cd-4982-a2e8-2178a7abe850",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Tokenizer(transformers.GPT2Tokenizer):\n",
    "\n",
    "    def build_inputs_with_special_tokens(self, token_ids_0, token_ids_1=None):\n",
    "        if token_ids_1 is None:\n",
    "            return [self.bos_token_id, *token_ids_0, self.eos_token_id]\n",
    "\n",
    "        return [self.bos_token_id, *token_ids_0, self.bos_token_id, *token_ids_1, self.eos_token_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b187545e-882a-4cd1-8bab-dcec2f33b5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'Tokenizer'.\n",
      "/home/bob1ch/Рабочий стол/NN-NLP/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afff2909-320a-40b0-81bb-7990b09bc319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tokenize(data):\n",
    "    return tokenizer(data, max_length=MAX_TOKENS, truncation=True, padding=True)['input_ids']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f4f399-308a-457b-a3ce-a8ede414603e",
   "metadata": {},
   "source": [
    "Since the dataset is rather large, you can omit the validation dataset and just use a set of test sentences after the training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff78613-15ce-4695-aced-4379ec067765",
   "metadata": {},
   "source": [
    "Create a dataset that returns the following\n",
    "* A pair of tensors `((None, L), (None, P))` -- input sequence of tokens and output sequence of tokens to be fed into decoder (this should start with the BOS token)\n",
    "* A tensor `(None, P)` -- output sequence of tokens to be predicted (this should end with EOS token)\n",
    "* A tensor `(None, P)` -- a masking tensor marking padded tokens with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1abf130f-0d7f-4df8-bb8d-a772685bd584",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('seq2seq_dataset.tsv', \n",
    "            sep='\\t', \n",
    "            on_bad_lines='skip',\n",
    "            names=['id_1', 'rus', 'id_2', 'eng'])[['rus', 'eng']]#тут скип, потомучта какое-то говно возникало\n",
    "\n",
    "X, y = to_tokenize(data['rus'].to_list()), to_tokenize(data['eng'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f05fd112-eb16-4d0c-a1d9-217e8bfb7e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size = 0.7, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "834aa559-0808-493c-ae5c-86f3dcefaa18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50256,   141,   220, ...,   252,   140, 50256],\n",
       "       [50256, 35072,   109, ...,   242,   140, 50256],\n",
       "       [50256, 50256, 50256, ...,   250,   140, 50256],\n",
       "       ...,\n",
       "       [50256, 50256, 50256, ...,   250,   140, 50256],\n",
       "       [50256, 50256, 50256, ...,   250,   140, 50256],\n",
       "       [50256, 50256, 50256, ...,   252,   140, 50256]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X)[:, ::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf228cef-62a1-40e8-9c34-a685410d0752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_collate(batch):\n",
    "    (inp, out_BOS, out_EOS, masking_PAD) = zip(*batch)\n",
    "    inp = torch.nn.utils.rnn.pad_sequence(inp, batch_first=True, padding_value=tokenizer.eos_token_id)\n",
    "    out_BOS = torch.nn.utils.rnn.pad_sequence(out_BOS, batch_first=True, padding_value=tokenizer.eos_token_id)\n",
    "    out_EOS = torch.nn.utils.rnn.pad_sequence(out_EOS, batch_first=True, padding_value=tokenizer.eos_token_id)\n",
    "    masking_PAD = torch.nn.utils.rnn.pad_sequence(masking_PAD, batch_first=True, padding_value=tokenizer.eos_token_id)\n",
    "\n",
    "    return inp, out_BOS, out_EOS, masking_PAD\n",
    "\n",
    "def get_dataloader(batch, X, y):\n",
    "    X = np.array(X) #Торч поругался, что я не могу сделать отрицательный степ\n",
    "    inp = torch.LongTensor(X.copy()).to('cuda') #а потом он ещё поругался, что в массиве у меня отрицательный страйд и попросил .copy()\n",
    "    out_BOS = torch.LongTensor(y).to('cuda')[:, :-1]\n",
    "    out_EOS = torch.LongTensor(y).to('cuda')[:, 1:]\n",
    "    masking_PAD = (out_EOS != tokenizer.pad_token_id).to('cuda')\n",
    "    #masking_PAD[:, 0] =  1 #BOS==EOS поэтому тут ручками доделал\n",
    "    data = torch.utils.data.TensorDataset(inp,\n",
    "                                          out_BOS,\n",
    "                                          out_EOS,\n",
    "                                          masking_PAD)\n",
    "    return torch.utils.data.DataLoader(data, batch_size=batch, shuffle=True, collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfe5eee3-003e-4192-b8ec-5e033d0ff8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_dataloader(64, X_train, y_train)\n",
    "data_test = get_dataloader(64, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff24dcac-c9f8-4d56-b584-5208c423f196",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c219a81a-59ea-4b56-96da-caa0e24c3db5",
   "metadata": {},
   "source": [
    "Create a model for training. The model should have two inputs: input sequence `(None, L)` and output sequence`(None, P)`. The model output is a single tensor `(None, P)` logits (or probabilities) of the next token predicted for each input one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db0b74d9-6e62-4236-bc31-508c30606e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, cell_type, units: int, n_tokens: int, n_stacks: int, bidirectional: bool, name: str):\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "        self.embedding = torch.nn.Embedding(n_tokens, units)\n",
    "        self.rnn = cell_type(units, units, num_layers=n_stacks, bidirectional=bidirectional, batch_first=True)\n",
    "\n",
    "    def forward(self, text):\n",
    "        emb = self.embedding(text)\n",
    "        out, h = self.rnn(emb)\n",
    "        return h\n",
    "\n",
    "class Decoder(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, cell_type, units: int, n_tokens: int, n_stacks: int, bidirectional: bool, name: str):\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "        self.out_dim = n_tokens\n",
    "        self.embedding = torch.nn.Embedding(n_tokens, units)\n",
    "        self.rnn = cell_type(units, units, num_layers=n_stacks, bidirectional=bidirectional, batch_first=True)\n",
    "        self.FC = torch.nn.LazyLinear(n_tokens)\n",
    "\n",
    "    def forward(self, h, target, is_teacher):\n",
    "        batch_size = target.shape[0]\n",
    "        target_length = target.shape[1]\n",
    "        target_vocab_size = self.out_dim\n",
    "        outputs = torch.empty(batch_size, target_length, target_vocab_size, dtype=float, device='cuda').fill_(tokenizer.bos_token_id)\n",
    "\n",
    "        inp = target[:, 0].unsqueeze(1)\n",
    "\n",
    "        for t in range(1, MAX_LENGTH-1):\n",
    "            emb = self.embedding(inp)\n",
    "            out, h = self.rnn(emb, h)\n",
    "            out = self.FC(out)\n",
    "            outputs[:, t] = out.squeeze()\n",
    "            top1 = out.argmax(-1).detach()\n",
    "            inp = target[:, t].unsqueeze(1) if is_teacher else top1\n",
    "\n",
    "        return outputs\n",
    "\n",
    "class Seq2Seq(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, encoder, decoder, name):\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, text, target, is_teacher):\n",
    "\n",
    "        h = self.encoder(text)     \n",
    "        outputs = self.decoder(h, target, is_teacher)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f5da771-0456-42e2-96a3-580683f3793a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, cell_type, units: int, n_tokens: int, n_stacks: int, bidirectional: bool, name: str):\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "        self.embedding = torch.nn.Embedding(n_tokens, units)\n",
    "        self.rnn = cell_type(units, units, num_layers=n_stacks, bidirectional=bidirectional, batch_first=True)\n",
    "\n",
    "    def forward(self, text):\n",
    "        emb = self.embedding(text)\n",
    "        out, h = self.rnn(emb)\n",
    "        return h\n",
    "\n",
    "class Decoder(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, cell_type, units: int, n_tokens: int, n_stacks: int, bidirectional: bool, name: str):\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "        self.out_dim = n_tokens\n",
    "        self.embedding = torch.nn.Embedding(n_tokens, units)\n",
    "        self.rnn = cell_type(units, units, num_layers=n_stacks, bidirectional=bidirectional, batch_first=True)\n",
    "        self.FC = torch.nn.LazyLinear(n_tokens)\n",
    "\n",
    "    def forward(self, text, h):\n",
    "        emb = self.embedding(text)\n",
    "        out, h = self.rnn(emb, h)\n",
    "        prediction = self.FC(out)\n",
    "\n",
    "        return prediction, h\n",
    "\n",
    "class Seq2Seq(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, encoder, decoder, name):\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, text, target, is_teacher):\n",
    "\n",
    "        batch_size = target.shape[0]\n",
    "        target_length = target.shape[1]\n",
    "        target_vocab_size = self.decoder.out_dim\n",
    "        #outputs = torch.zeros(batch_size, target_length+1, target_vocab_size).to('cuda')\n",
    "        outputs = torch.empty(batch_size, target_length, target_vocab_size, dtype=float, device='cuda').fill_(tokenizer.bos_token_id)\n",
    "        \n",
    "        h = self.encoder(text)\n",
    "        inp = target[:, 0].unsqueeze(1) #get bos\n",
    "        \n",
    "        for t in range(1, MAX_LENGTH-1):\n",
    "            out, h = self.decoder(inp, h)\n",
    "            outputs[:, t] = out.squeeze()\n",
    "            top1 = out.argmax(-1).detach()\n",
    "            inp = target[:, t].unsqueeze(1) if is_teacher else top1\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dba42e4d-dbe8-4780-a11d-2033f8dee6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(torch.nn.GRU, 32, tokenizer.vocab_size, 2, True, 'encoder').to('cuda')\n",
    "decoder = Decoder(torch.nn.GRU, 32, tokenizer.vocab_size, 2, True, 'decoder').to('cuda')\n",
    "seq2seq = Seq2Seq(encoder, decoder, 'seq2seq').to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "55ce0ef1-7af0-43f3-bd3a-2fc26c671834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(50257, 32)\n",
       "    (rnn): GRU(32, 32, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(50257, 32)\n",
       "    (rnn): GRU(32, 32, num_layers=2, batch_first=True, bidirectional=True)\n",
       "    (FC): LazyLinear(in_features=0, out_features=50257, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0eebed6d-37e8-4999-9101-9624230b49e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inp, out_BOS, out_EOS, mask = next(iter(data))\n",
    "pred = seq2seq(inp, out_BOS, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03a5f240-ffa9-4e13-b73a-575a0b76979d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, cell_type, units: int, n_tokens: int, n_stacks: int, bidirectional: bool, name: str):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.name = name\n",
    "        self.units = units\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        self.embeddings = torch.nn.Embedding(n_tokens, units)\n",
    "        self.rnn = cell_type(units, units, num_layers=n_stacks, bidirectional=bidirectional, batch_first=True) #можно поменять\n",
    "\n",
    "    def forward(self, text):\n",
    "        embeds = self.embeddings(text)      \n",
    "        out, h = self.rnn(embeds)\n",
    "\n",
    "        return out, h\n",
    "\n",
    "# class BahdanauAttention(torch.nn.Module):\n",
    "#     def __init__(self, hidden_size):\n",
    "#         super(BahdanauAttention, self).__init__()\n",
    "#         self.Wa = torch.nn.Linear(hidden_size, hidden_size)\n",
    "#         self.Ua = torch.nn.Linear(hidden_size, hidden_size)\n",
    "#         self.Va = torch.nn.Linear(hidden_size, 1)\n",
    "\n",
    "#     def forward(self, query, keys):\n",
    "#         scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
    "#         scores = scores.squeeze(2).unsqueeze(1)\n",
    "\n",
    "#         weights = F.softmax(scores, dim=-1)\n",
    "#         context = torch.bmm(weights, keys)\n",
    "\n",
    "#         return context, weights\n",
    "\n",
    "#https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html#the-decoder\n",
    "class Decoder(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, cell_type, units: int, n_tokens: int, n_stacks: int, bidirectional: bool, name: str): \n",
    "        super(Decoder, self).__init__()\n",
    "        self.name = name\n",
    "        self.units = units\n",
    "        #self.bidirectional = bidirectional\n",
    "        \n",
    "        self.embeddings = torch.nn.Embedding(n_tokens, units)\n",
    "        # self.attention = BahdanauAttention(units)\n",
    "        self.rnn = cell_type(units, units, num_layers=n_stacks, bidirectional=bidirectional, batch_first=True)\n",
    "        self.FC = torch.nn.Linear(2*units if bidirectional else units, n_tokens)\n",
    "\n",
    "    def forward(self, enc_outs, enc_h, target=None):\n",
    "        #enc_outs нужен чтобы батч узнать\n",
    "        batch_size = enc_outs.size(0)\n",
    "        dec_inp = torch.empty(batch_size, 1, dtype=torch.long, device='cuda').fill_(tokenizer.bos_token_id)\n",
    "        dec_h, dec_out = enc_h, []\n",
    "        \n",
    "        #цикл генерации токенов, подумой можно ли остановить, если пришел паддинг\n",
    "        out, dec_h = self.apply_rnn(dec_inp, dec_h, enc_outs)\n",
    "        dec_out.append(out)\n",
    "        for i in range(1, MAX_LENGTH-1):\n",
    "            out, dec_h = self.apply_rnn(dec_inp, dec_h, enc_outs)\n",
    "            dec_out.append(out)\n",
    "            dec_inp = target[:, i].unsqueeze(1) if target is not None else out.argmax(dim=-1).detach()\n",
    "            \n",
    "            \n",
    "        dec_out = torch.cat(dec_out, dim=1)\n",
    "        return dec_out\n",
    "\n",
    "    def apply_rnn(self, inp, h, enc_out):\n",
    "        embeds = self.embeddings(inp)\n",
    "        \n",
    "        out, h = self.rnn(embeds, h)\n",
    "        out = self.FC(out)\n",
    "\n",
    "        return out, h\n",
    "\n",
    "class Seq2Seq(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, cell_type, units: int, n_tokens: int, n_stacks: int, bidirectional: bool, name: str):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = Encoder(cell_type, units, n_tokens, n_stacks, bidirectional, name+'_encoder').to('cuda')\n",
    "        self.decoder = Decoder(cell_type, units, n_tokens, n_stacks, bidirectional, name+'_decoder').to('cuda')\n",
    "\n",
    "    def forward(self, text, target=None):\n",
    "        enc_outs, enc_h = self.encoder(text)\n",
    "        dec_out = self.decoder(enc_outs, enc_h, target)\n",
    "        \n",
    "        return dec_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ebe8ec38-fba7-4168-979e-cc9a8fcdf36e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 31, 50257])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Encoder(torch.nn.GRU, 32, tokenizer.vocab_size, 1, True, 'encoder').to('cuda')\n",
    "decoder = Decoder(torch.nn.GRU, 32, tokenizer.vocab_size, 1, True, 'decoder').to('cuda')\n",
    "text = next(iter(data))[0][:4]\n",
    "enc_outs, enc_h = encoder(text)\n",
    "dec_out = decoder(enc_outs, enc_h)\n",
    "dec_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d7dfc450-05bf-4c58-a1b0-6ceac8870dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_outs.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b8216683-85d9-458e-bfc3-3649a9a362c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Encoder.__init__() missing 1 required positional argument: 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[85], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSeq2Seq\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mseq2seq\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m model(text)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\n",
      "Cell \u001b[0;32mIn[83], line 83\u001b[0m, in \u001b[0;36mSeq2Seq.__init__\u001b[0;34m(self, units, n_tokens, n_stacks, bidirectional, name)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, units: \u001b[38;5;28mint\u001b[39m, n_tokens: \u001b[38;5;28mint\u001b[39m, n_stacks: \u001b[38;5;28mint\u001b[39m, bidirectional: \u001b[38;5;28mbool\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28msuper\u001b[39m(Seq2Seq, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m---> 83\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m \u001b[43mEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43munits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_stacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_encoder\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder \u001b[38;5;241m=\u001b[39m Decoder(units, n_tokens, n_stacks, bidirectional, name\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_decoder\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Encoder.__init__() missing 1 required positional argument: 'name'"
     ]
    }
   ],
   "source": [
    "model = Seq2Seq(32, tokenizer.vocab_size, 1, False, 'seq2seq')\n",
    "model(text)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee04317-1bbe-4f23-8e1e-595577d35663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(\n",
    "    units: int,\n",
    "    n_tokens: int,\n",
    "    n_labels: int,\n",
    "    n_stacks: int = 1,\n",
    "    bidirectional: bool = False,\n",
    "    name: str | None = None,\n",
    "    cell_type: type[keras.layers.Layer] = keras.layers.LSTMCell\n",
    ") -> keras.Model:\n",
    "    '''Creates a model with RNN architecture for sequence to sequence classification.\n",
    "\n",
    "    Arguments:\n",
    "        units: dimensionality of RNN cells\n",
    "        n_tokens: number of tokens in the tokenizer dictionary\n",
    "        n_labels: number of labels to be predicted\n",
    "        n_stacks: number of RNN cells in the stack (1 -- no stacking)\n",
    "        bidirectional: whether or not the model is bidirectional\n",
    "        name: the model name\n",
    "        cell_type: type of a cell to use, either keras.layers.LSTMCell or keras.layers.GRUCell\n",
    "\n",
    "    Returns:\n",
    "        The model'''\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaf444d-10f3-497d-8cc5-22a86835f433",
   "metadata": {},
   "source": [
    "Try to add attention to your model (for example [additive attention](https://keras.io/api/layers/attention_layers/additive_attention/)), does it perform better?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c5d763-e07d-48cd-a539-987a99ad74a7",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2006bfa0-eee3-439d-899d-7612e7a95a90",
   "metadata": {},
   "source": [
    "Train your model using teacher forcing. The idea is that the model predicts the next token that should follow, so one part of the model (called encoder) reads the text and output some state containing information about the text read. The other part of the model (called decoder) reads and already generated text (or in case of the teacher forcing the expected output) and predicts the next token for each one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26530629-8f9b-40cf-82aa-9a0f0b1ca890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, loss_f, dataloader, teacher = None):\n",
    "\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    \n",
    "    running_loss = 0  \n",
    "    for i, batch in enumerate(dataloader, start=1):\n",
    "        inp, out_BOS, out_EOS, masking_PAD = batch\n",
    "        decoder_optimizer.zero_grad()\n",
    "        encoder_optimizer.zero_grad()\n",
    "        enc_outs, enc_h = encoder(inp)\n",
    "        seq_pred = decoder(enc_outs, enc_h, out_BOS if teacher else None)\n",
    "        #seq_pred = model(inp, out_BOS if teacher else None) #out_EOS\n",
    "        loss = loss_f(seq_pred[masking_PAD], \n",
    "                      out_EOS[masking_PAD])\n",
    "        # loss = loss_f(seq_pred.view(-1, seq_pred.size(-1)), \n",
    "        #               out_EOS.view(-1))\n",
    "        #return seq_pred, masking_PAD, out_EOS\n",
    "\n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % (len(dataloader) // 4) == 0:\n",
    "            print(f'batch{i} cur_loss {running_loss / i}')\n",
    "        \n",
    "    return running_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca850eff-c65b-4865-9941-cdc56b405865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5d206b29-2836-4f49-9f72-7c362bf957ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_f, dataloader, teacher = None):\n",
    "\n",
    "    #encoder.train()\n",
    "    #decoder.train()\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0  \n",
    "    for i, batch in enumerate(dataloader, start=1):\n",
    "        inp, out_BOS, out_EOS, masking_PAD = batch\n",
    "        model.zero_grad()\n",
    "        seq_pred = model(inp, out_BOS if teacher else None)\n",
    "        #seq_pred = model(inp, out_BOS if teacher else None) #out_EOS\n",
    "        loss = loss_f(seq_pred[masking_PAD], \n",
    "                      out_EOS[masking_PAD])\n",
    "        # loss = loss_f(seq_pred.view(-1, seq_pred.size(-1)), \n",
    "        #               out_EOS.view(-1))\n",
    "        #return seq_pred, masking_PAD, out_EOS\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if  i % 1000 == 999:\n",
    "            print(running_loss / i)\n",
    "            print(f'{i} / {len(dataloader)}')\n",
    "        \n",
    "        if i % (len(dataloader) // 4) == 0:\n",
    "            print(f'batch{i} cur_loss {running_loss / i}')\n",
    "        \n",
    "    return running_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f67cd6d0-870d-41c5-bdee-cc584b9b01f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate(model, dataloader, tokenizer, metric, target = None):\n",
    "#     model.to('cuda')\n",
    "#     model.eval()\n",
    "#     running_loss = 0\n",
    "#     running_metric = 0\n",
    "    \n",
    "#     for i, batch in enumerate(dataloader, start=1):\n",
    "#         inp, out_BOS, out_EOS, masking_PAD = batch\n",
    "#         seq_pred = model(inp) #out_EOS\n",
    "\n",
    "#         for seq, y_true, pad in zip(seq_pred, out_EOS, masking_PAD):\n",
    "#             seq = seq.argmax(dim=-1)\n",
    "#             candidates = tokenizer.decode(seq[pad])\n",
    "#             references = torch.Tensor(tokenizer.decode(y_true[pad])).to('cuda')\n",
    "#             metric.update(torch.Tensor(\"I wouldn't be able to solve the problem, even if I tried.\").to('cuda'), [references])\n",
    "        \n",
    "#         loss = loss_f(seq_pred.view(-1, seq_pred.size(-1)), \n",
    "#                       out_EOS.view(-1))\n",
    "#         running_loss += loss.item()\n",
    "        \n",
    "#         #if i % (len(dataloader) // 4) == 0:\n",
    "#         #    print(f'batch{i} cur_loss {running_loss / i}')\n",
    "#     print(metric.device)\n",
    "#     return running_loss / len(dataloader), metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fff65bdb-6554-4636-880b-d6319ee417b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1984, 50257]), torch.Size([1984]))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "717e69c9-c74e-482d-8992-fdf2f247b353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.462266148367258\n",
      "3.462266148367258\n",
      "3.462266148367258\n",
      "3.462266148367258\n",
      "Teacher forcing is OVER\n",
      "3.462266148367258\n",
      "3.462266148367258\n",
      "3.462266148367258\n",
      "3.462266148367258\n",
      "3.462266148367258\n",
      "3.462266148367258\n",
      "CPU times: user 476 ms, sys: 58.9 ms, total: 535 ms\n",
      "Wall time: 267 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "EPOCHS = 10\n",
    "model = Seq2Seq(torch.nn.GRU, 512, tokenizer.vocab_size, 3, True, 'seq2seq')\n",
    "#encoder = Encoder(torch.nn.GRU, 32, tokenizer.vocab_size, 1, False, 'encoder').to('cuda')\n",
    "#decoder = Decoder(torch.nn.GRU, 32, tokenizer.vocab_size, 1, False, 'decoder').to('cuda')\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "#optimizer_decoder = torch.optim.Adam(decoder.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "loss_f = torch.nn.CrossEntropyLoss() \n",
    "teacher = True\n",
    "for epoch in range(EPOCHS):\n",
    "    #metric = BLEUScore(n_gram=3, device='cuda')\n",
    "    \n",
    "    if epoch == 4:\n",
    "        teacher = False\n",
    "        print(f'Teacher forcing is OVER')\n",
    "    loss = train(model, optimizer, loss_f, data, teacher)\n",
    "    print(loss)\n",
    "#score = evaluate(model, data_test, tokenizer, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "80f12d98-8e3f-4539-a817-b35ced28eb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch859 cur_loss 6.321829462217924\n",
      "batch1718 cur_loss 5.906346020515362\n",
      "batch2577 cur_loss 5.651012868995948\n",
      "batch3436 cur_loss 5.477710629369938\n",
      "5.477212694849722\n",
      "batch859 cur_loss 4.788064752385558\n",
      "batch1718 cur_loss 4.737839936099869\n",
      "batch2577 cur_loss 4.694841530325804\n",
      "batch3436 cur_loss 4.665027769258608\n",
      "4.664837566701851\n",
      "batch859 cur_loss 4.494034110181406\n",
      "batch1718 cur_loss 4.479209102768282\n",
      "batch2577 cur_loss 4.462422271361405\n",
      "batch3436 cur_loss 4.44551437371546\n",
      "4.4455013519873905\n",
      "batch859 cur_loss 4.339796916986095\n",
      "batch1718 cur_loss 4.334090857899924\n",
      "batch2577 cur_loss 4.325849133958917\n",
      "batch3436 cur_loss 4.317845097590103\n",
      "4.317761133700895\n",
      "batch859 cur_loss 4.241072207585202\n",
      "batch1718 cur_loss 4.236105502415036\n",
      "batch2577 cur_loss 4.232704722978461\n",
      "batch3436 cur_loss 4.22858605826137\n",
      "4.22831930348817\n",
      "CPU times: user 10min 53s, sys: 433 ms, total: 10min 53s\n",
      "Wall time: 10min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "EPOCHS = 5\n",
    "#model = Seq2Seq(32, tokenizer.vocab_size, 3, True, 'seq2seq')\n",
    "encoder = Encoder(torch.nn.GRU, 32, tokenizer.vocab_size, 1, False, 'encoder').to('cuda')\n",
    "decoder = Decoder(torch.nn.GRU, 32, tokenizer.vocab_size, 1, False, 'decoder').to('cuda')\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=0.001)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=0.001)\n",
    "\n",
    "loss_f = torch.nn.CrossEntropyLoss()\n",
    "teacher = True\n",
    "for epoch in range(EPOCHS):\n",
    "    #metric = BLEUScore(n_gram=3, device='cuda')\n",
    "    \n",
    "    if epoch == 9:\n",
    "        teacher = False\n",
    "        print(f'Teacher forcing is OVER')\n",
    "    loss = train(encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, loss_f, data, teacher = teacher)\n",
    "    print(loss)\n",
    "#score = evaluate(model, data_test, tokenizer, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "708ffd4c-4c15-408d-93d4-60e4cb519ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch859 cur_loss 2.392586445919432\n",
      "batch1718 cur_loss 1.9209044858102056\n",
      "batch2577 cur_loss 1.7363049594940583\n",
      "batch3436 cur_loss 1.6277941676318577\n",
      "1.6273915018755254\n",
      "batch859 cur_loss 1.2576480487728008\n",
      "batch1718 cur_loss 1.2407764716462013\n",
      "batch2577 cur_loss 1.2280551945464668\n",
      "batch3436 cur_loss 1.2183420067442727\n",
      "1.2183333249693868\n",
      "batch859 cur_loss 1.1718669483769897\n",
      "batch1718 cur_loss 1.1651504768342718\n",
      "batch2577 cur_loss 1.1579339662216226\n",
      "batch3436 cur_loss 1.1538523602298307\n",
      "1.153810159121533\n",
      "batch859 cur_loss 1.1250854542563486\n",
      "batch1718 cur_loss 1.119661390538543\n",
      "batch2577 cur_loss 1.118158749475653\n",
      "batch3436 cur_loss 1.1159583223122795\n",
      "1.1160503899541556\n",
      "batch859 cur_loss 1.0945259714987003\n",
      "batch1718 cur_loss 1.0930846831712513\n",
      "batch2577 cur_loss 1.0918675166116374\n",
      "batch3436 cur_loss 1.0899569661778261\n",
      "1.0898750732720817\n",
      "batch859 cur_loss 1.073588047302366\n",
      "batch1718 cur_loss 1.0725797521984757\n",
      "batch2577 cur_loss 1.0709766620436887\n",
      "batch3436 cur_loss 1.0705338169726282\n",
      "1.0704591506856511\n",
      "batch859 cur_loss 1.0600925411278765\n",
      "batch1718 cur_loss 1.0580797691561707\n",
      "batch2577 cur_loss 1.0551557310755326\n",
      "batch3436 cur_loss 1.0545786993536876\n",
      "1.0545235023002149\n",
      "batch859 cur_loss 1.045682315568291\n",
      "batch1718 cur_loss 1.0412747339194812\n",
      "batch2577 cur_loss 1.0422309185351148\n",
      "batch3436 cur_loss 1.0403641367090457\n",
      "1.0403340212062682\n",
      "batch859 cur_loss 1.0284034596610818\n",
      "batch1718 cur_loss 1.0288704764509922\n",
      "batch2577 cur_loss 1.028055921676874\n",
      "batch3436 cur_loss 1.0277489416466048\n",
      "1.0277004425662242\n",
      "Teacher forcing is OVER\n",
      "batch859 cur_loss 1.2876276375944873\n",
      "batch1718 cur_loss 1.2637609025166392\n",
      "batch2577 cur_loss 1.2531299384518284\n",
      "batch3436 cur_loss 1.2459546248661626\n",
      "1.245942378761672\n",
      "batch859 cur_loss 1.213184294794991\n",
      "batch1718 cur_loss 1.2134648849439567\n",
      "batch2577 cur_loss 1.2140030241956257\n",
      "batch3436 cur_loss 1.210996926351254\n",
      "1.2111332558656578\n",
      "batch859 cur_loss 1.2002501710468731\n",
      "batch1718 cur_loss 1.1996085445317457\n",
      "batch2577 cur_loss 1.1995116049668841\n",
      "batch3436 cur_loss 1.1981095370681516\n",
      "1.1980721332646276\n",
      "batch859 cur_loss 1.1879666395598156\n",
      "batch1718 cur_loss 1.1887588073890896\n",
      "batch2577 cur_loss 1.1891490101906788\n",
      "batch3436 cur_loss 1.188575528969726\n",
      "1.1885507163976508\n",
      "batch859 cur_loss 1.1784887220862303\n",
      "batch1718 cur_loss 1.1793551423149975\n",
      "batch2577 cur_loss 1.1816631018490953\n",
      "batch3436 cur_loss 1.1810207845723393\n",
      "1.181030664342751\n",
      "batch859 cur_loss 1.17954486095031\n",
      "batch1718 cur_loss 1.1748440199389585\n",
      "batch2577 cur_loss 1.1738135114537684\n",
      "batch3436 cur_loss 1.174581197733374\n",
      "1.1745934063142454\n",
      "batch859 cur_loss 1.169635097000735\n",
      "batch1718 cur_loss 1.1693463612074624\n",
      "batch2577 cur_loss 1.1688747517489906\n",
      "batch3436 cur_loss 1.168799372973209\n",
      "1.168735293202984\n",
      "batch859 cur_loss 1.1645225797182468\n",
      "batch1718 cur_loss 1.1613254743141401\n",
      "batch2577 cur_loss 1.16390131539414\n",
      "batch3436 cur_loss 1.1636017515162511\n",
      "1.1635991944133905\n",
      "batch859 cur_loss 1.1600973567945994\n",
      "batch1718 cur_loss 1.1592246959803407\n",
      "batch2577 cur_loss 1.1599059718775573\n",
      "batch3436 cur_loss 1.1595247914891027\n",
      "1.1593642482129458\n",
      "batch859 cur_loss 1.1604327447061904\n",
      "batch1718 cur_loss 1.1576970042324732\n",
      "batch2577 cur_loss 1.1567942303745238\n",
      "batch3436 cur_loss 1.1553853594798842\n",
      "1.1554956285369087\n",
      "batch859 cur_loss 1.1487367367577914\n",
      "batch1718 cur_loss 1.1518100234002258\n",
      "batch2577 cur_loss 1.1522129132482124\n",
      "batch3436 cur_loss 1.1517363781493257\n",
      "1.1518557578819233\n",
      "CPU times: user 53min 18s, sys: 1.1 s, total: 53min 19s\n",
      "Wall time: 53min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "EPOCHS = 20\n",
    "#model = Seq2Seq(32, tokenizer.vocab_size, 3, True, 'seq2seq')\n",
    "encoder = Encoder(32, tokenizer.vocab_size, 1, False, 'encoder').to('cuda')\n",
    "decoder = Decoder(32, tokenizer.vocab_size, 1, False, 'decoder').to('cuda')\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=0.001)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=0.001)\n",
    "\n",
    "loss_f = torch.nn.CrossEntropyLoss()\n",
    "teacher = True\n",
    "for epoch in range(EPOCHS):\n",
    "    #metric = BLEUScore(n_gram=3, device='cuda')\n",
    "    \n",
    "    if epoch == 9:\n",
    "        teacher = False\n",
    "        print(f'Teacher forcing is OVER')\n",
    "    loss = train(encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, loss_f, data, teacher = teacher)\n",
    "    print(loss)\n",
    "#score = evaluate(model, data_test, tokenizer, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bcbaae51-6e01-4001-86b9-17e57cd500ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50256, 25443,   111, 12466, 16843,   121, 12466,    11, 16142, 43666,\n",
       "         16843,   123,   140, 18849, 21727, 15166, 30143, 16843,   110, 12466,\n",
       "         20375, 16843,   121, 12466, 40623, 22177, 16843,   120, 12466,    96,\n",
       "           140, 50256],\n",
       "        [50256,   229,   141, 21727,   220, 40623,   220,   116, 12466, 15166,\n",
       "         20375,   220,    11, 38857, 18849, 30143, 20375, 21727, 16142,   229,\n",
       "           141, 21727,   220, 45035, 20375,   220, 18849, 30143, 21727,   243,\n",
       "           140, 50256]], device='cuda:0')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e67be964-0b1b-43db-858a-a8f6d4cda222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50256, 50256, 50256,  ...,   240,   140, 50256],\n",
       "        [50256,   220, 16142,  ...,   107,   140, 50256],\n",
       "        [50256, 16843,   114,  ...,   107,   140, 50256],\n",
       "        ...,\n",
       "        [50256, 50256, 50256,  ...,   255,   140, 50256],\n",
       "        [50256, 18849,   123,  ...,   243,   140, 50256],\n",
       "        [50256, 50256, 50256,  ...,   242,   140, 50256]], device='cuda:0')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "46d4e83d-3cf0-4783-baa0-9efc106c1dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The policeman stood like a statue with his arms folded across his chest.\n",
      "The police was the the the was..<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "inp, out_BOS, out_EOS, masking_PAD = next(iter(data))\n",
    "enc_outs, enc_h = encoder(inp[:2])\n",
    "print(tokenizer.decode(out_EOS[0][masking_PAD[0]]))\n",
    "print(tokenizer.decode(decoder(enc_outs, enc_h)[0].argmax(dim=-1)[masking_PAD[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c96e4a0-7c9c-4d1c-97f6-a8d3846b4fde",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7f3475-22b9-47b4-824c-7ebc758b75a2",
   "metadata": {},
   "source": [
    "Make a function for text translation. Translate some text and evaluate model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602f831b-9ddd-4070-ba8f-b7b16bc26463",
   "metadata": {},
   "source": [
    "Take note that your model is set for training. During the inference process you will have to use parts of the model independently (including the RNN cells)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a32f4dc-3c53-426d-bf67-35b1efe2bbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(\n",
    "    text: str,\n",
    "    tokenizer: Tokenizer,\n",
    "    model: keras.Model,\n",
    "    max_len: int = 20\n",
    ") -> str:\n",
    "    '''Predicts `text`translation using the `model`.\n",
    "\n",
    "    Arguments:\n",
    "        text: text to be translated\n",
    "        tokenizer: tokenizer to use\n",
    "        model: model ot use\n",
    "        max_len: maximum length of the prediction (in tokens)\n",
    "\n",
    "    Returns:\n",
    "        tranlated text'''\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8031f6c3-6037-4592-a187-2570002af077",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83d7cc2f-028c-424d-b9fd-a1fbf518c4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, hidden = self.gru(embedded)\n",
    "        return output, hidden\n",
    "\n",
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Va = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        context = torch.bmm(weights, keys)\n",
    "\n",
    "        return context, weights\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = BahdanauAttention(hidden_size)\n",
    "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(tokenizer.pad_token_id)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for i in range(MAX_LENGTH-1):\n",
    "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attentions.append(attn_weights)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        attentions = torch.cat(attentions, dim=1)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, attentions\n",
    "\n",
    "\n",
    "    def forward_step(self, input, hidden, encoder_outputs):\n",
    "        embedded =  self.dropout(self.embedding(input))\n",
    "\n",
    "        query = hidden.permute(1, 0, 2)\n",
    "        context, attn_weights = self.attention(query, encoder_outputs)\n",
    "        input_gru = torch.cat((embedded, context), dim=2)\n",
    "\n",
    "        output, hidden = self.gru(input_gru, hidden)\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3c0fab4-d9ed-41da-b055-b138fb139692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, teacher_forcing):\n",
    "\n",
    "    total_loss = 0\n",
    "    total_metric = 0\n",
    "    for data in dataloader:\n",
    "        inp, out_BOS, out_EOS, masking_PAD = data\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(inp)\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, out_BOS if teacher_forcing else None)\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            out_EOS.view(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        decoder_outputs = decoder_outputs.argmax(-1)\n",
    "        total_metric += (decoder_outputs[masking_PAD].detach().cpu().numpy() == out_EOS[masking_PAD].detach().cpu().numpy()).mean()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader), total_metric / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00832f93-4c03-4aff-ae91-73821a8afbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c47be9e-c348-4b5f-9aef-eb64b8304f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17dbf0cc-15fd-45f0-afc2-caa5651c3090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
    "               print_every=100, plot_every=100, end_teacher_forcing=1):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    optimizer_encoder = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    optimizer_decoder = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    teacher_forcing = True\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        if epoch == end_teacher_forcing:\n",
    "            teacher_forcing = False\n",
    "        print('ok')\n",
    "        loss, metric = train_epoch(train_dataloader, encoder, decoder, optimizer_encoder, optimizer_decoder, criterion, teacher_forcing)\n",
    "        loss_test, metric_test = evaluate(data_test, encoder, decoder, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        print(f'EVAL: loss={loss_test:.2f} metric={metric_test:.2f}')\n",
    "        \n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print(f\"train metric: {metric}\")\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
    "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "        \n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c8bbc66-5588-4b3e-b786-5f730d18c23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader, encoder, decoder, criterion):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        total_metric = 0\n",
    "        total_loss = 0\n",
    "        for data in dataloader:\n",
    "            inp, out_BOS, out_EOS, masking_PAD = data\n",
    "\n",
    "            encoder_outputs, encoder_hidden = encoder(inp)\n",
    "            decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
    "            loss = criterion(\n",
    "                        decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "                        out_EOS.view(-1)\n",
    "                    )\n",
    "            total_loss += loss.item()\n",
    "            decoder_outputs = decoder_outputs.argmax(-1)\n",
    "            total_metric += (decoder_outputs[masking_PAD].detach().cpu().numpy() == out_EOS[masking_PAD].detach().cpu().numpy()).mean()\n",
    "            \n",
    "    return total_loss / len(dataloader), total_metric / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e8f8352-09f5-4db7-b8c9-cb2a46110210",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m evaluate(data_test, \u001b[43mencoder\u001b[49m, decoder, nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'encoder' is not defined"
     ]
    }
   ],
   "source": [
    "evaluate(data_test, encoder, decoder, nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27adc0aa-603c-4fa2-bcb0-f691d7312de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "EVAL: loss=1.06 metric=0.34\n",
      "train metric: 0.2340712389536886\n",
      "18m 35s (- 353m 10s) (1 5%) 1.2603\n",
      "ok\n",
      "EVAL: loss=0.93 metric=0.38\n",
      "train metric: 0.3510618831079997\n",
      "37m 6s (- 333m 54s) (2 10%) 0.9511\n",
      "ok\n",
      "EVAL: loss=0.89 metric=0.38\n",
      "train metric: 0.39021586976772876\n",
      "55m 37s (- 315m 10s) (3 15%) 0.8538\n",
      "ok\n",
      "EVAL: loss=0.88 metric=0.40\n",
      "train metric: 0.4122011463852013\n",
      "74m 7s (- 296m 31s) (4 20%) 0.7988\n",
      "ok\n",
      "EVAL: loss=0.86 metric=0.41\n",
      "train metric: 0.42705171646671536\n",
      "92m 38s (- 277m 55s) (5 25%) 0.7615\n",
      "ok\n",
      "EVAL: loss=0.86 metric=0.41\n",
      "train metric: 0.43908789921947755\n",
      "111m 9s (- 259m 22s) (6 30%) 0.7347\n",
      "ok\n",
      "EVAL: loss=0.85 metric=0.42\n",
      "train metric: 0.4485462276771167\n",
      "129m 41s (- 240m 50s) (7 35%) 0.7139\n",
      "ok\n",
      "EVAL: loss=0.86 metric=0.43\n",
      "train metric: 0.45630706231607626\n",
      "148m 11s (- 222m 17s) (8 40%) 0.6974\n",
      "ok\n",
      "EVAL: loss=0.86 metric=0.42\n",
      "train metric: 0.46263068291268866\n",
      "166m 42s (- 203m 45s) (9 45%) 0.6841\n",
      "ok\n",
      "EVAL: loss=0.86 metric=0.43\n",
      "train metric: 0.4689370918353905\n",
      "185m 13s (- 185m 13s) (10 50%) 0.6726\n",
      "ok\n",
      "EVAL: loss=0.86 metric=0.42\n",
      "train metric: 0.4732971420380331\n",
      "203m 45s (- 166m 42s) (11 55%) 0.6633\n",
      "ok\n",
      "EVAL: loss=0.86 metric=0.42\n",
      "train metric: 0.47791068632292194\n",
      "222m 16s (- 148m 10s) (12 60%) 0.6542\n",
      "ok\n",
      "EVAL: loss=0.86 metric=0.42\n",
      "train metric: 0.4810714005768516\n",
      "240m 47s (- 129m 39s) (13 65%) 0.6473\n",
      "ok\n",
      "EVAL: loss=0.87 metric=0.43\n",
      "train metric: 0.4847333028405658\n",
      "259m 18s (- 111m 7s) (14 70%) 0.6410\n",
      "ok\n",
      "EVAL: loss=0.87 metric=0.44\n",
      "train metric: 0.48737077151359676\n",
      "277m 49s (- 92m 36s) (15 75%) 0.6356\n",
      "ok\n",
      "EVAL: loss=0.87 metric=0.43\n",
      "train metric: 0.4901684689305095\n",
      "296m 20s (- 74m 5s) (16 80%) 0.6300\n",
      "ok\n",
      "EVAL: loss=0.87 metric=0.43\n",
      "train metric: 0.492796722891187\n",
      "314m 51s (- 55m 33s) (17 85%) 0.6249\n",
      "ok\n",
      "EVAL: loss=0.87 metric=0.43\n",
      "train metric: 0.495280673078351\n",
      "333m 22s (- 37m 2s) (18 90%) 0.6208\n",
      "ok\n",
      "EVAL: loss=0.87 metric=0.43\n",
      "train metric: 0.4967514241497708\n",
      "351m 53s (- 18m 31s) (19 95%) 0.6174\n",
      "ok\n",
      "EVAL: loss=0.88 metric=0.44\n",
      "train metric: 0.4986119772102638\n",
      "370m 23s (- 0m 0s) (20 100%) 0.6134\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "batch_size = 32\n",
    "device = 'cuda'\n",
    "\n",
    "encoder = EncoderRNN(tokenizer.vocab_size, hidden_size).to(device)\n",
    "decoder = AttnDecoderRNN(hidden_size, tokenizer.vocab_size).to(device)\n",
    "\n",
    "train(data, encoder, decoder, 20, print_every=1, plot_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f496ddc3-8319-463f-a521-f93c29d24304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfdf82b-60bd-4913-a9dd-c06eaea9d06c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
