{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6092b42-6423-4b4f-81b3-b6ddec64ecf1",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24c94665-4148-40ed-b2a9-516dd3becc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bob1ch/Рабочий стол/NN-NLP/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#import keras\n",
    "import os\n",
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import sklearn.metrics\n",
    "#import tensorflow as tf\n",
    "import tqdm.notebook as tqdm\n",
    "import sklearn.model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#pytorch\n",
    "\n",
    "import torch\n",
    "# from torcheval.metrics import MultilabelA\n",
    "from torchmetrics.classification import Accuracy\n",
    "#from torchsummary import summary\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bf51054-c9ea-4c26-92fc-cb471bdc4e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'models'\n",
    "MAX_TOKENS = 32\n",
    "MAX_LENGTH = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c18c6e-1c88-4e6b-8f13-476b78b88a2b",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e38ac2-a5e2-4435-8c95-0982e3039768",
   "metadata": {},
   "source": [
    "Get the dataset from [here](https://tatoeba.org/en/downloads). Preferably use russian to english translations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e09a5d-8537-4ffa-8583-f09c30028b2d",
   "metadata": {},
   "source": [
    "Use a custom tokenizer that can add bos and eos tokens (pass `add_special_tokens=True` when calling the tokenizer to add them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8312a719-f1cd-4982-a2e8-2178a7abe850",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Tokenizer(transformers.GPT2Tokenizer):\n",
    "\n",
    "    def build_inputs_with_special_tokens(self, token_ids_0, token_ids_1=None):\n",
    "        if token_ids_1 is None:\n",
    "            return [self.bos_token_id, *token_ids_0, self.eos_token_id]\n",
    "\n",
    "        return [self.bos_token_id, *token_ids_0, self.bos_token_id, *token_ids_1, self.eos_token_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b187545e-882a-4cd1-8bab-dcec2f33b5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'Tokenizer'.\n",
      "/home/bob1ch/Рабочий стол/NN-NLP/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f4f399-308a-457b-a3ce-a8ede414603e",
   "metadata": {},
   "source": [
    "Since the dataset is rather large, you can omit the validation dataset and just use a set of test sentences after the training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff78613-15ce-4695-aced-4379ec067765",
   "metadata": {},
   "source": [
    "Create a dataset that returns the following\n",
    "* A pair of tensors `((None, L), (None, P))` -- input sequence of tokens and output sequence of tokens to be fed into decoder (this should start with the BOS token)\n",
    "* A tensor `(None, P)` -- output sequence of tokens to be predicted (this should end with EOS token)\n",
    "* A tensor `(None, P)` -- a masking tensor marking padded tokens with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1abf130f-0d7f-4df8-bb8d-a772685bd584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tokenize(data):\n",
    "    return tokenizer(data, max_length=MAX_TOKENS, truncation=True, padding=True)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99e913b7-d944-4fc6-84c6-3f3b644dd6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('seq2seq_dataset.tsv', \n",
    "            sep='\\t', \n",
    "            on_bad_lines='skip',\n",
    "            names=['id_1', 'rus', 'id_2', 'eng'])[['rus', 'eng']]#тут скип, потомучта какое-то говно возникало\n",
    "\n",
    "X, y = to_tokenize(data['rus'].to_list()), to_tokenize(data['eng'].to_list())\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size = 0.7, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f9cd66a-b43d-4878-b555-1d0cd50d7b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_collate(batch):\n",
    "    (inp, out_BOS, out_EOS, masking_PAD) = zip(*batch)\n",
    "    inp = torch.nn.utils.rnn.pad_sequence(inp, batch_first=True, padding_value=tokenizer.eos_token_id)\n",
    "    out_BOS = torch.nn.utils.rnn.pad_sequence(out_BOS, batch_first=True, padding_value=tokenizer.eos_token_id)\n",
    "    out_EOS = torch.nn.utils.rnn.pad_sequence(out_EOS, batch_first=True, padding_value=tokenizer.eos_token_id)\n",
    "    masking_PAD = torch.nn.utils.rnn.pad_sequence(masking_PAD, batch_first=True, padding_value=tokenizer.eos_token_id)\n",
    "\n",
    "    return inp, out_BOS, out_EOS, masking_PAD\n",
    "\n",
    "def get_dataloader(batch, X, y):\n",
    "    X = np.array(X) #Торч поругался, что я не могу сделать отрицательный степ\n",
    "    inp = torch.LongTensor(X.copy()).to('cuda') #а потом он ещё поругался, что в массиве у меня отрицательный страйд и попросил .copy()\n",
    "    out_BOS = torch.LongTensor(y).to('cuda')[:, :-1]\n",
    "    out_EOS = torch.LongTensor(y).to('cuda')[:, 1:]\n",
    "    masking_PAD = (out_BOS != tokenizer.pad_token_id).to('cuda')\n",
    "    masking_PAD[:, 0] = True # я получаю маску по BOS [50625, ..., 30, 50625] -> [False, ..., True, False] -> [True, ..., True, False]\n",
    "    data = torch.utils.data.TensorDataset(inp,\n",
    "                                          out_BOS,\n",
    "                                          out_EOS,\n",
    "                                          masking_PAD)\n",
    "    return torch.utils.data.DataLoader(data, batch_size=batch, shuffle=True, collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12f7f8dd-51fc-431d-93be-eda45164faf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_dataloader(256, X_train, y_train)\n",
    "data_test = get_dataloader(256, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff24dcac-c9f8-4d56-b584-5208c423f196",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c219a81a-59ea-4b56-96da-caa0e24c3db5",
   "metadata": {},
   "source": [
    "Create a model for training. The model should have two inputs: input sequence `(None, L)` and output sequence`(None, P)`. The model output is a single tensor `(None, P)` logits (or probabilities) of the next token predicted for each input one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ee04317-1bbe-4f23-8e1e-595577d35663",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_model\u001b[39m(\n\u001b[1;32m      2\u001b[0m     units: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m      3\u001b[0m     n_tokens: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m      4\u001b[0m     n_labels: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m      5\u001b[0m     n_stacks: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      6\u001b[0m     bidirectional: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      7\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m----> 8\u001b[0m     cell_type: \u001b[38;5;28mtype\u001b[39m[keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLayer] \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLSTMCell\n\u001b[1;32m      9\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m keras\u001b[38;5;241m.\u001b[39mModel:\n\u001b[1;32m     10\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Creates a model with RNN architecture for sequence to sequence classification.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m    Arguments:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m        The model'''\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "def get_model(\n",
    "    units: int,\n",
    "    n_tokens: int,\n",
    "    n_labels: int,\n",
    "    n_stacks: int = 1,\n",
    "    bidirectional: bool = False,\n",
    "    name: str | None = None,\n",
    "    cell_type: type[keras.layers.Layer] = keras.layers.LSTMCell\n",
    ") -> keras.Model:\n",
    "    '''Creates a model with RNN architecture for sequence to sequence classification.\n",
    "\n",
    "    Arguments:\n",
    "        units: dimensionality of RNN cells\n",
    "        n_tokens: number of tokens in the tokenizer dictionary\n",
    "        n_labels: number of labels to be predicted\n",
    "        n_stacks: number of RNN cells in the stack (1 -- no stacking)\n",
    "        bidirectional: whether or not the model is bidirectional\n",
    "        name: the model name\n",
    "        cell_type: type of a cell to use, either keras.layers.LSTMCell or keras.layers.GRUCell\n",
    "\n",
    "    Returns:\n",
    "        The model'''\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11647ab4-c310-4320-b918-2e50c101ce38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, cell_type, input_size, hidden_size, bidirectional, num_layers):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = cell_type(hidden_size, hidden_size, batch_first=True, bidirectional=bidirectional, num_layers=num_layers)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.embedding(input)\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        return output, hidden\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, cell_type, hidden_size, output_size, bidirectional, num_layers):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = nn.MultiheadAttention(hidden_size, num_heads=1, batch_first=True)\n",
    "        self.rnn = cell_type(2 * hidden_size, hidden_size, batch_first=True, num_layers=num_layers, bidirectional=bidirectional)\n",
    "        self.out = nn.Linear(2 * hidden_size if bidirectional else hidden_size, output_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, max_len, is_inference, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(tokenizer.pad_token_id)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i in range(max_len-1):\n",
    "            decoder_output, decoder_hidden = self.forward_step(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                #Teacher forcing\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1)\n",
    "            else:\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()\n",
    "            if is_inference and topi == tokenizer.pad_token_id:\n",
    "                break\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "\n",
    "\n",
    "        return decoder_outputs\n",
    "\n",
    "\n",
    "    def forward_step(self, input, hidden, encoder_outputs):\n",
    "        embedded =  self.embedding(input)\n",
    "        query = hidden.permute(1, 0, 2)\n",
    "        \n",
    "        if query.shape[1] != 1:\n",
    "            query = query.mean(dim=1, keepdim=True)\n",
    "            encoder_outputs = encoder_outputs[..., :query.shape[-1]] + encoder_outputs[..., query.shape[-1]:]\n",
    "        context, _ = self.attention(query, encoder_outputs, encoder_outputs)\n",
    "        input_rnn = torch.cat((embedded, context[:, -1, :].unsqueeze(1)), dim=2)\n",
    "\n",
    "        output, hidden = self.rnn(input_rnn, hidden)\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "class Seq2seq(nn.Module):\n",
    "    def __init__(self, cell_type, input_size, hidden_size, device, bidirectional, num_layers):\n",
    "        super(Seq2seq, self).__init__()\n",
    "        self.encoder = EncoderRNN(cell_type, input_size, hidden_size, bidirectional, num_layers).to(device)\n",
    "        self.decoder = AttnDecoderRNN(cell_type, hidden_size, input_size, bidirectional, num_layers).to(device)\n",
    "\n",
    "    def forward(self, inp, out_BOS, max_len, teacher_forcing, is_inference=False):\n",
    "        encoder_outputs, encoder_hidden = self.encoder(inp)\n",
    "        decoder_outputs = self.decoder(encoder_outputs, encoder_hidden, max_len, is_inference, out_BOS if teacher_forcing else None)\n",
    "\n",
    "        return decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "087c003a-eb62-4e79-b764-58b8b1c68aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, cell_type, input_size, hidden_size, bidirectional, num_layers):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = cell_type(hidden_size, hidden_size, batch_first=True, bidirectional=bidirectional, num_layers=num_layers)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.embedding(input)\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        return output, hidden\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, cell_type, hidden_size, output_size, bidirectional, num_layers):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = nn.MultiheadAttention(hidden_size, num_heads=1, batch_first=True)\n",
    "        self.rnn = cell_type(2 * hidden_size, hidden_size, batch_first=True, num_layers=num_layers, bidirectional=bidirectional)\n",
    "        self.out = nn.Linear(2 * hidden_size if bidirectional else hidden_size, output_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, max_len, is_inference, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        \n",
    "        # Используем начальный токен BOS для всей последовательности\n",
    "        if target_tensor is not None:\n",
    "            decoder_input = target_tensor[:, :]  # сдвиг на один шаг для teacher forcing\n",
    "        else:\n",
    "            decoder_input = torch.full((batch_size, max_len), tokenizer.pad_token_id, dtype=torch.long, device=device)\n",
    "            decoder_input[:, 0] = tokenizer.bos_token_id  # BOS для начала последовательности\n",
    "\n",
    "        # Эмбеддинги для всех временных шагов\n",
    "        embedded = self.embedding(decoder_input)\n",
    "        \n",
    "        # Повторяем attention для каждого временного шага\n",
    "        # attention_outputs = []\n",
    "        # for t in range(max_len - 1):\n",
    "        #     query = encoder_hidden[-1].unsqueeze(1)  # используем последний скрытый слой в качестве query\n",
    "        #     context, _ = self.attention(query, encoder_outputs, encoder_outputs)\n",
    "        #     attention_outputs.append(context)\n",
    "\n",
    "        # # Объединяем контексты для всех временных шагов\n",
    "        # attention_outputs = torch.cat(attention_outputs, dim=1)\n",
    "        \n",
    "        # # Объединяем эмбеддинги с attention context для RNN\n",
    "        # input_rnn = torch.cat((embedded, attention_outputs), dim=2)\n",
    "        \n",
    "        # Запускаем RNN и получаем выходные данные\n",
    "        output, hidden = self.rnn(embedded, encoder_hidden)\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "class Seq2seq(nn.Module):\n",
    "    def __init__(self, cell_type, input_size, hidden_size, device, bidirectional, num_layers):\n",
    "        super(Seq2seq, self).__init__()\n",
    "        self.encoder = EncoderRNN(cell_type, input_size, hidden_size, bidirectional, num_layers).to(device)\n",
    "        self.decoder = AttnDecoderRNN(cell_type, hidden_size, input_size, bidirectional, num_layers).to(device)\n",
    "\n",
    "    def forward(self, inp, out_BOS, max_len, teacher_forcing, is_inference=False):\n",
    "        encoder_outputs, encoder_hidden = self.encoder(inp)\n",
    "        decoder_outputs = self.decoder(encoder_outputs, encoder_hidden, max_len-1, is_inference, out_BOS if teacher_forcing else None)\n",
    "\n",
    "        return decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c7f3031-6820-4be0-937d-d0fd21bc8161",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, cell_type, input_size, hidden_size, bidirectional, num_layers):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = cell_type(hidden_size, hidden_size, batch_first=True, bidirectional=bidirectional, num_layers=num_layers)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.embedding(input)\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        return output, hidden\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, cell_type, hidden_size, output_size, bidirectional, num_layers):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = nn.MultiheadAttention(hidden_size, num_heads=1, batch_first=True)\n",
    "        self.rnn = cell_type(2 * hidden_size, hidden_size, batch_first=True, num_layers=num_layers, bidirectional=bidirectional)\n",
    "        self.out = nn.Linear(2 * hidden_size if bidirectional else hidden_size, output_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, max_len, is_inference, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        device = encoder_outputs.device\n",
    "        \n",
    "        # Если инференс, просто инициализируем последовательность с токеном BOS\n",
    "        if is_inference:\n",
    "            decoder_input = torch.full((batch_size, 1), tokenizer.bos_token_id, dtype=torch.long, device=device)\n",
    "            outputs = []\n",
    "    \n",
    "            # Генерация всей последовательности токенов за один вызов\n",
    "            for _ in range(max_len):\n",
    "                embedded = self.embedding(decoder_input)\n",
    "                attn_output, _ = self.attention(embedded, encoder_outputs, encoder_outputs)\n",
    "                # Concatenate attention output with embedded input for the RNN\n",
    "                rnn_input = torch.cat((embedded, attn_output), dim=2)\n",
    "                output, encoder_hidden = self.rnn(rnn_input, encoder_hidden)\n",
    "                output = self.out(output[:, -1, :])  # Предсказание для текущего шага\n",
    "                outputs.append(output.unsqueeze(1))\n",
    "    \n",
    "                # Находим наиболее вероятный токен\n",
    "                top1 = output.argmax(1).unsqueeze(1)\n",
    "                decoder_input = top1 # Добавляем предсказанный токен к входу\n",
    "    \n",
    "            outputs = torch.cat(outputs, dim=1)\n",
    "            return outputs\n",
    "    \n",
    "        else:\n",
    "            # Если teacher forcing включен, используем target_tensor сдвинутый на один шаг\n",
    "            decoder_input = torch.full((batch_size, max_len), tokenizer.pad_token_id, dtype=torch.long, device=device)\n",
    "            decoder_input[:, 0] = tokenizer.bos_token_id  # BOS токен в начале последовательности\n",
    "            \n",
    "            if target_tensor is not None:\n",
    "                decoder_input[:, 1:] = target_tensor[:, :-1]  # Сдвиг на один шаг\n",
    "            \n",
    "            embedded = self.embedding(decoder_input)\n",
    "            attn_output, _ = self.attention(embedded, encoder_outputs, encoder_outputs)\n",
    "\n",
    "            Concatenate attention output with embedded input for the RNN\n",
    "            rnn_input = torch.cat((embedded, attn_output), dim=2)\n",
    "            output, hidden = self.rnn(rnn_input, encoder_hidden)\n",
    "            output = self.out(output)\n",
    "            return output\n",
    "\n",
    "class Seq2seq(nn.Module):\n",
    "    def __init__(self, cell_type, input_size, hidden_size, device, bidirectional, num_layers):\n",
    "        super(Seq2seq, self).__init__()\n",
    "        self.encoder = EncoderRNN(cell_type, input_size, hidden_size, bidirectional, num_layers).to(device)\n",
    "        self.decoder = AttnDecoderRNN(cell_type, hidden_size, input_size, bidirectional, num_layers).to(device)\n",
    "\n",
    "    def forward(self, inp, out_BOS, max_len, teacher_forcing, is_inference=False):\n",
    "        encoder_outputs, encoder_hidden = self.encoder(inp)\n",
    "        decoder_outputs = self.decoder(encoder_outputs, encoder_hidden, max_len-1, is_inference, out_BOS if teacher_forcing else None)\n",
    "\n",
    "        return decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58b97e2d-3faa-437a-a4df-7646744f08a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, cell_type, input_size, hidden_size, bidirectional, num_layers):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = cell_type(hidden_size, hidden_size, batch_first=True, bidirectional=bidirectional, num_layers=num_layers)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.embedding(input)\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        return output, hidden\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, cell_type, hidden_size, output_size, bidirectional, num_layers):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = nn.MultiheadAttention(hidden_size, num_heads=1, batch_first=True)\n",
    "        self.rnn = cell_type(2 * hidden_size, hidden_size, batch_first=True, num_layers=num_layers, bidirectional=bidirectional)\n",
    "        self.out = nn.Linear(2 * hidden_size if bidirectional else hidden_size, output_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, max_len, is_inference, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        device = encoder_outputs.device\n",
    "        \n",
    "        # Если инференс, просто инициализируем последовательность с токеном BOS\n",
    "        if is_inference:\n",
    "            decoder_input = torch.full((batch_size, 1), tokenizer.bos_token_id, dtype=torch.long, device=device)\n",
    "            outputs = []\n",
    "    \n",
    "            # Генерация всей последовательности токенов за один вызов\n",
    "            for _ in range(max_len):\n",
    "                output, encoder_hidden = self.forward_step(decoder_input, encoder_hidden, encoder_outputs)\n",
    "                outputs.append(output.unsqueeze(1))\n",
    "                decoder_input = output.argmax(dim=1).unsqueeze(1)\n",
    "    \n",
    "            outputs = torch.cat(outputs, dim=1)\n",
    "            return outputs\n",
    "    \n",
    "        else:\n",
    "            # Если teacher forcing включен, используем target_tensor сдвинутый на один шаг\n",
    "            decoder_input = torch.full((batch_size, max_len), tokenizer.pad_token_id, dtype=torch.long, device=device)\n",
    "            decoder_input[:, 0] = tokenizer.bos_token_id  # BOS токен в начале последовательности\n",
    "            \n",
    "            if target_tensor is not None:\n",
    "                decoder_input[:, 1:] = target_tensor[:, :-1]  # Сдвиг на один шаг\n",
    "            \n",
    "            embedded = self.embedding(decoder_input)\n",
    "            attn_output, _ = self.attention(embedded, encoder_outputs, encoder_outputs)\n",
    "\n",
    "            #Concatenate attention output with embedded input for the RNN\n",
    "            rnn_input = torch.cat((embedded, attn_output), dim=2)\n",
    "            output, hidden = self.rnn(rnn_input, encoder_hidden)\n",
    "            output = self.out(output)\n",
    "            return output\n",
    "            \n",
    "    def forward_step(self, decoder_input, decoder_hidden, encoder_outputs):\n",
    "        # Встраиваем входной токен\n",
    "        embedded = self.embedding(decoder_input)\n",
    "        \n",
    "        # Рассчитываем внимание\n",
    "        attn_output, _ = self.attention(embedded, encoder_outputs, encoder_outputs)\n",
    "        \n",
    "        # Объединяем контекстный вектор с вложением\n",
    "        rnn_input = torch.cat((embedded, attn_output), dim=2)\n",
    "        \n",
    "        # Пропускаем через RNN\n",
    "        rnn_output, decoder_hidden = self.rnn(rnn_input, decoder_hidden)\n",
    "        output = self.out(rnn_output.squeeze(1))  # Предсказание для текущего шага\n",
    "        return output, decoder_hidden\n",
    "\n",
    "class Seq2seq(nn.Module):\n",
    "    def __init__(self, cell_type, input_size, hidden_size, device, bidirectional, num_layers):\n",
    "        super(Seq2seq, self).__init__()\n",
    "        self.encoder = EncoderRNN(cell_type, input_size, hidden_size, bidirectional, num_layers).to(device)\n",
    "        self.decoder = AttnDecoderRNN(cell_type, hidden_size, input_size, bidirectional, num_layers).to(device)\n",
    "\n",
    "    def forward(self, inp, out_BOS, max_len, teacher_forcing, is_inference=False):\n",
    "        encoder_outputs, encoder_hidden = self.encoder(inp)\n",
    "        decoder_outputs = self.decoder(encoder_outputs, encoder_hidden, max_len-1, is_inference, out_BOS if teacher_forcing else None)\n",
    "\n",
    "        return decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a35cdc29-81e8-4262-ae2e-646bdfc4374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, cell_type, input_size, hidden_size, bidirectional, num_layers):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = cell_type(hidden_size, hidden_size, batch_first=True, bidirectional=bidirectional, num_layers=num_layers)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.embedding(input)\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        return output, hidden\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, cell_type, hidden_size, output_size, bidirectional, num_layers):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = nn.MultiheadAttention(hidden_size, num_heads=1, batch_first=True)\n",
    "        self.rnn = cell_type(2 * hidden_size, hidden_size, batch_first=True, num_layers=num_layers, bidirectional=bidirectional)\n",
    "        self.out = nn.Linear(2 * hidden_size if bidirectional else hidden_size, output_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, max_len, is_inference, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        device = encoder_outputs.device\n",
    "        \n",
    "        # Если инференс, просто инициализируем последовательность с токеном BOS\n",
    "        if is_inference:\n",
    "            decoder_input = torch.full((batch_size, 1), tokenizer.bos_token_id, dtype=torch.long, device=device)\n",
    "            outputs = []\n",
    "    \n",
    "            # Генерация всей последовательности токенов за один вызов\n",
    "            for _ in range(max_len):\n",
    "                output, encoder_hidden = self.forward_step(decoder_input, encoder_hidden, encoder_outputs)\n",
    "                outputs.append(output.unsqueeze(1))\n",
    "                decoder_input = output.argmax(dim=1).unsqueeze(1)\n",
    "    \n",
    "            outputs = torch.cat(outputs, dim=1)\n",
    "            return outputs\n",
    "    \n",
    "        else:\n",
    "            # Если teacher forcing включен, используем target_tensor сдвинутый на один шаг\n",
    "            decoder_input = torch.full((batch_size, max_len), tokenizer.pad_token_id, dtype=torch.long, device=device)\n",
    "            decoder_input[:, 0] = tokenizer.bos_token_id  # BOS токен в начале последовательности\n",
    "            \n",
    "            if target_tensor is not None:\n",
    "                decoder_input[:, 1:] = target_tensor[:, :-1]  # Сдвиг на один шаг\n",
    "            \n",
    "            embedded = self.embedding(decoder_input)\n",
    "            attn_output, _ = self.attention(embedded, encoder_outputs, encoder_outputs)\n",
    "\n",
    "            #Concatenate attention output with embedded input for the RNN\n",
    "            rnn_input = torch.cat((embedded, attn_output), dim=2)\n",
    "            output, hidden = self.rnn(rnn_input, encoder_hidden)\n",
    "            output = self.out(output)\n",
    "            return output\n",
    "            \n",
    "    def forward_step(self, decoder_input, decoder_hidden, encoder_outputs):\n",
    "        # Встраиваем входной токен\n",
    "        embedded = self.embedding(decoder_input)\n",
    "        \n",
    "        # Рассчитываем внимание\n",
    "        query = decoder_hidden.permute(1, 0, 2)\n",
    "        attn_output, _ = self.attention(query, encoder_outputs, encoder_outputs)\n",
    "        \n",
    "        # Объединяем контекстный вектор с вложением\n",
    "        rnn_input = torch.cat((embedded, attn_output), dim=2)\n",
    "        \n",
    "        # Пропускаем через RNN\n",
    "        rnn_output, decoder_hidden = self.rnn(rnn_input, decoder_hidden)\n",
    "        output = self.out(rnn_output.squeeze(1))  # Предсказание для текущего шага\n",
    "        return output, decoder_hidden\n",
    "\n",
    "class Seq2seq(nn.Module):\n",
    "    def __init__(self, cell_type, input_size, hidden_size, device, bidirectional, num_layers):\n",
    "        super(Seq2seq, self).__init__()\n",
    "        self.encoder = EncoderRNN(cell_type, input_size, hidden_size, bidirectional, num_layers).to(device)\n",
    "        self.decoder = AttnDecoderRNN(cell_type, hidden_size, input_size, bidirectional, num_layers).to(device)\n",
    "\n",
    "    def forward(self, inp, out_BOS, max_len, teacher_forcing, is_inference=False):\n",
    "        encoder_outputs, encoder_hidden = self.encoder(inp)\n",
    "        decoder_outputs = self.decoder(encoder_outputs, encoder_hidden, max_len-1, is_inference, out_BOS if teacher_forcing else None)\n",
    "\n",
    "        return decoder_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaf444d-10f3-497d-8cc5-22a86835f433",
   "metadata": {},
   "source": [
    "Try to add attention to your model (for example [additive attention](https://keras.io/api/layers/attention_layers/additive_attention/)), does it perform better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8bafcb5-cc7e-4e5d-9355-537fe4ad8a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden_size = 128\n",
    "# #batch_size = 256\n",
    "# device = 'cuda'\n",
    "\n",
    "# model = Seq2seq(nn.GRU, tokenizer.vocab_size, hidden_size, device, True, 2)\n",
    "\n",
    "# train(data, model, 5, print_every=1, plot_every=1, end_teacher_forcing=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c5d763-e07d-48cd-a539-987a99ad74a7",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2006bfa0-eee3-439d-899d-7612e7a95a90",
   "metadata": {},
   "source": [
    "Train your model using teacher forcing. The idea is that the model predicts the next token that should follow, so one part of the model (called encoder) reads the text and output some state containing information about the text read. The other part of the model (called decoder) reads and already generated text (or in case of the teacher forcing the expected output) and predicts the next token for each one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "873979a0-c6d5-488f-b3c5-399d2e65e973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26530629-8f9b-40cf-82aa-9a0f0b1ca890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, model, optimizer, criterion, teacher_forcing):\n",
    "\n",
    "    total_loss = 0\n",
    "    total_metric = 0\n",
    "    for data in dataloader:\n",
    "        inp, out_BOS, out_EOS, masking_PAD = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        decoder_outputs = model(inp, out_BOS, MAX_LENGTH, teacher_forcing)\n",
    "        \n",
    "        loss = criterion(\n",
    "            decoder_outputs[masking_PAD],\n",
    "            out_EOS[masking_PAD]\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        decoder_outputs = decoder_outputs.argmax(-1)\n",
    "        total_metric += (decoder_outputs[masking_PAD].detach().cpu().numpy() == out_EOS[masking_PAD].detach().cpu().numpy()).mean()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader), total_metric / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2df423df-d8a0-42a6-9c13-d6c87b979d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, model, n_epochs, learning_rate=0.001, eval_every=1,\n",
    "               print_every=100, plot_every=100, end_teacher_forcing=1):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0\n",
    "    plot_loss_total = 0\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    teacher_forcing = True\n",
    "    for epoch in range(1, n_epochs):\n",
    "        if epoch == end_teacher_forcing:\n",
    "            teacher_forcing = False\n",
    "        print('='*40)\n",
    "        print(f'Epoch №{epoch}')\n",
    "        loss, metric = train_epoch(train_dataloader, model, optimizer, criterion, teacher_forcing)\n",
    "        \n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "        if epoch % eval_every == 0:\n",
    "            loss_test, metric_test = evaluate(data_test, model, criterion)\n",
    "            print(f'EVAL: loss={loss_test:.2f} metric={metric_test:.2f}')\n",
    "        \n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print(f\"train metric: {metric}\")\n",
    "            print('%s (%d %d%%) train loss: %.4f' % (timeSince(start, epoch / n_epochs),\n",
    "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "        \n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e55d69b0-cd1e-4326-abad-32b9336e8d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader, model, criterion):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        total_metric = 0\n",
    "        total_loss = 0\n",
    "        for data in dataloader:\n",
    "            inp, out_BOS, out_EOS, masking_PAD = data\n",
    "\n",
    "            decoder_outputs = model(inp, out_BOS, MAX_LENGTH, None, True)\n",
    "            loss = criterion(\n",
    "                decoder_outputs[masking_PAD],\n",
    "                out_EOS[masking_PAD]\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "            decoder_outputs = decoder_outputs.argmax(-1)\n",
    "            total_metric += (decoder_outputs[masking_PAD].detach().cpu().numpy() == out_EOS[masking_PAD].detach().cpu().numpy()).mean()\n",
    "            \n",
    "    return total_loss / len(dataloader), total_metric / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0364e5d-f39b-4d97-ac0d-71b9e65bb4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Epoch №1\n",
      "EVAL: loss=5.74 metric=0.09\n",
      "train metric: 0.23118498125924067\n",
      "5m 35s (- 55m 56s) (1 9%) train loss: 4.9870\n",
      "========================================\n",
      "Epoch №2\n",
      "EVAL: loss=5.77 metric=0.10\n",
      "train metric: 0.36949854132393617\n",
      "11m 13s (- 50m 31s) (2 18%) train loss: 3.9363\n",
      "========================================\n",
      "Epoch №3\n",
      "EVAL: loss=5.79 metric=0.11\n",
      "train metric: 0.42500288733471187\n",
      "16m 51s (- 44m 56s) (3 27%) train loss: 3.4733\n",
      "========================================\n",
      "Epoch №4\n",
      "EVAL: loss=5.83 metric=0.10\n",
      "train metric: 0.4617090400788305\n",
      "22m 30s (- 39m 23s) (4 36%) train loss: 3.1656\n",
      "========================================\n",
      "Epoch №5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m Seq2seq(nn\u001b[38;5;241m.\u001b[39mGRU, tokenizer\u001b[38;5;241m.\u001b[39mvocab_size, hidden_size, device, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_teacher_forcing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 17\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_dataloader, model, n_epochs, learning_rate, eval_every, print_every, plot_every, end_teacher_forcing)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m40\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch №\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m loss, metric \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteacher_forcing\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m print_loss_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m     20\u001b[0m plot_loss_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n",
      "Cell \u001b[0;32mIn[18], line 20\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(dataloader, model, optimizer, criterion, teacher_forcing)\u001b[0m\n\u001b[1;32m     18\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     19\u001b[0m     decoder_outputs \u001b[38;5;241m=\u001b[39m decoder_outputs\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m     total_metric \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[43mdecoder_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmasking_PAD\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;241m==\u001b[39m out_EOS[masking_PAD]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     21\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader), total_metric \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hidden_size = 128\n",
    "device = 'cuda'\n",
    "\n",
    "model = Seq2seq(nn.GRU, tokenizer.vocab_size, hidden_size, device, False, 1)\n",
    "\n",
    "train(data, model, 11, eval_every=1, print_every=1, plot_every=1, end_teacher_forcing=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d115f529-8e19-463a-a547-207c0df606a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "EVAL: loss=5.45 metric=0.14\n",
      "train metric: 0.24856439097195143\n",
      "9m 19s (- 270m 39s) (1 3%) train loss: 4.9509\n",
      "ok\n",
      "EVAL: loss=5.25 metric=0.17\n",
      "train metric: 0.3787704378143097\n",
      "18m 38s (- 261m 3s) (2 6%) train loss: 3.9018\n",
      "ok\n",
      "EVAL: loss=5.24 metric=0.18\n",
      "train metric: 0.43367459468838837\n",
      "27m 57s (- 251m 35s) (3 10%) train loss: 3.4365\n",
      "ok\n",
      "EVAL: loss=5.13 metric=0.19\n",
      "train metric: 0.4663576027297193\n",
      "37m 15s (- 242m 12s) (4 13%) train loss: 3.1429\n",
      "ok\n",
      "EVAL: loss=5.10 metric=0.19\n",
      "train metric: 0.4900443761178413\n",
      "46m 34s (- 232m 51s) (5 16%) train loss: 2.9278\n",
      "ok\n",
      "EVAL: loss=5.05 metric=0.19\n",
      "train metric: 0.5072819624984329\n",
      "55m 52s (- 223m 31s) (6 20%) train loss: 2.7629\n",
      "ok\n",
      "EVAL: loss=4.98 metric=0.20\n",
      "train metric: 0.5211834606161164\n",
      "65m 11s (- 214m 12s) (7 23%) train loss: 2.6321\n",
      "ok\n",
      "EVAL: loss=5.00 metric=0.20\n",
      "train metric: 0.5330060863661616\n",
      "74m 30s (- 204m 52s) (8 26%) train loss: 2.5252\n",
      "ok\n",
      "EVAL: loss=5.01 metric=0.20\n",
      "train metric: 0.5426380785171968\n",
      "83m 48s (- 195m 34s) (9 30%) train loss: 2.4373\n",
      "ok\n",
      "EVAL: loss=5.03 metric=0.20\n",
      "train metric: 0.5511333203042805\n",
      "93m 8s (- 186m 16s) (10 33%) train loss: 2.3629\n",
      "ok\n",
      "EVAL: loss=5.02 metric=0.20\n",
      "train metric: 0.5586432162778981\n",
      "102m 26s (- 176m 57s) (11 36%) train loss: 2.2972\n",
      "ok\n",
      "EVAL: loss=5.05 metric=0.20\n",
      "train metric: 0.5654125954644377\n",
      "111m 45s (- 167m 38s) (12 40%) train loss: 2.2412\n",
      "ok\n",
      "EVAL: loss=5.07 metric=0.20\n",
      "train metric: 0.5715148749795028\n",
      "121m 4s (- 158m 20s) (13 43%) train loss: 2.1905\n",
      "ok\n",
      "EVAL: loss=5.10 metric=0.20\n",
      "train metric: 0.5775854029973583\n",
      "130m 24s (- 149m 2s) (14 46%) train loss: 2.1440\n",
      "ok\n",
      "EVAL: loss=5.12 metric=0.20\n",
      "train metric: 0.5828094083516191\n",
      "139m 44s (- 139m 44s) (15 50%) train loss: 2.1042\n",
      "ok\n",
      "EVAL: loss=5.13 metric=0.20\n",
      "train metric: 0.5879088227701056\n",
      "149m 4s (- 130m 26s) (16 53%) train loss: 2.0669\n",
      "ok\n",
      "EVAL: loss=5.19 metric=0.20\n",
      "train metric: 0.5922636867588856\n",
      "158m 24s (- 121m 7s) (17 56%) train loss: 2.0336\n",
      "ok\n",
      "EVAL: loss=5.17 metric=0.20\n",
      "train metric: 0.5967139992417875\n",
      "167m 44s (- 111m 49s) (18 60%) train loss: 2.0018\n",
      "ok\n",
      "EVAL: loss=5.17 metric=0.20\n",
      "train metric: 0.6006240852696653\n",
      "177m 4s (- 102m 31s) (19 63%) train loss: 1.9739\n",
      "ok\n",
      "EVAL: loss=5.19 metric=0.20\n",
      "train metric: 0.6043260836541325\n",
      "186m 24s (- 93m 12s) (20 66%) train loss: 1.9465\n",
      "ok\n",
      "EVAL: loss=5.19 metric=0.20\n",
      "train metric: 0.6075318712726837\n",
      "195m 45s (- 83m 53s) (21 70%) train loss: 1.9231\n",
      "ok\n",
      "EVAL: loss=5.26 metric=0.20\n",
      "train metric: 0.6109065248493531\n",
      "205m 5s (- 74m 34s) (22 73%) train loss: 1.8998\n",
      "ok\n",
      "EVAL: loss=5.27 metric=0.20\n",
      "train metric: 0.6140708773068525\n",
      "214m 26s (- 65m 15s) (23 76%) train loss: 1.8787\n",
      "ok\n",
      "EVAL: loss=5.29 metric=0.20\n",
      "train metric: 0.6170361166943202\n",
      "223m 46s (- 55m 56s) (24 80%) train loss: 1.8575\n",
      "ok\n",
      "EVAL: loss=5.26 metric=0.20\n",
      "train metric: 0.6200870506527937\n",
      "233m 6s (- 46m 37s) (25 83%) train loss: 1.8386\n",
      "ok\n",
      "EVAL: loss=5.31 metric=0.20\n",
      "train metric: 0.6222478527616431\n",
      "242m 27s (- 37m 18s) (26 86%) train loss: 1.8209\n",
      "ok\n",
      "EVAL: loss=5.35 metric=0.20\n",
      "train metric: 0.6250858644510806\n",
      "251m 47s (- 27m 58s) (27 90%) train loss: 1.8036\n",
      "ok\n",
      "EVAL: loss=5.35 metric=0.20\n",
      "train metric: 0.6271555469770418\n",
      "261m 9s (- 18m 39s) (28 93%) train loss: 1.7876\n",
      "ok\n",
      "EVAL: loss=5.36 metric=0.20\n",
      "train metric: 0.6295012353083068\n",
      "270m 29s (- 9m 19s) (29 96%) train loss: 1.7723\n",
      "ok\n",
      "EVAL: loss=3.11 metric=0.44\n",
      "train metric: 0.4206281380100585\n",
      "280m 36s (- 0m 0s) (30 100%) train loss: 3.0273\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 128\n",
    "#batch_size = 256\n",
    "device = 'cuda'\n",
    "\n",
    "model = Seq2seq(nn.GRU, tokenizer.vocab_size, hidden_size, device, False, 1)\n",
    "\n",
    "train(data, model, 30, print_every=1, plot_every=1, end_teacher_forcing=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f3b59e9-3092-4f51-aec3-d802ac464fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), os.path.join(MODEL_PATH, 'seq2seq'+'.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c96e4a0-7c9c-4d1c-97f6-a8d3846b4fde",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7f3475-22b9-47b4-824c-7ebc758b75a2",
   "metadata": {},
   "source": [
    "Make a function for text translation. Translate some text and evaluate model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602f831b-9ddd-4070-ba8f-b7b16bc26463",
   "metadata": {},
   "source": [
    "Take note that your model is set for training. During the inference process you will have to use parts of the model independently (including the RNN cells)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a32f4dc-3c53-426d-bf67-35b1efe2bbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(\n",
    "    text: str,\n",
    "    tokenizer: Tokenizer,\n",
    "    model: nn.Module,\n",
    "    max_len: int = 20\n",
    ") -> str:\n",
    "    '''Predicts `text`translation using the `model`.\n",
    "\n",
    "    Arguments:\n",
    "        text: text to be translated\n",
    "        tokenizer: tokenizer to use\n",
    "        model: model ot use\n",
    "        max_len: maximum length of the prediction (in tokens)\n",
    "\n",
    "    Returns:\n",
    "        tranlated text'''\n",
    "    ...\n",
    "    text = tokenizer(text, return_tensors='pt')['input_ids'].to(device)\n",
    "    tokens_translated = model(text, None, max_len, None, is_inference=True).argmax(dim=-1).squeeze()\n",
    "    return tokenizer.decode(tokens_translated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83d7cc2f-028c-424d-b9fd-a1fbf518c4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good is early. is a.. it to. is old<|endoftext|>\n",
      "Hi! is dead! are dead<|endoftext|>\n",
      "What the is day?'s?'s a?'s a!'s a!'s a!'s a!'s a!'s a!'s\n",
      "The cat sitting sitting the on table<|endoftext|>\n",
      "The is this is. tastes.'s!'s a.. you't<|endoftext|>\n",
      "The was was hospital a..<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "corpus = ['Доброе утро',\n",
    "          'Привет мир!', \n",
    "          'Какой чудесный день!',\n",
    "          'Кот сидит на столе.',\n",
    "          'Пицца это вкусно.', \n",
    "          'Принц был болен.']\n",
    "\n",
    "for document in corpus:\n",
    "    print(translate(document, tokenizer, model, max_len=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93432d00-a7b3-4f1d-a206-f730ab83cc11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
