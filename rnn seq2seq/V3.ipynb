{
 "cells": [
  {
   "attachments": {
    "4cfe7b86-a772-44ca-914a-989d1cf1dd56.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAABeCAIAAAB9xjJMAAAAA3NCSVQICAjb4U/gAAAcc0lEQVR4Xu3ddbQtR7EHYBIgDw3vEtx56MPdgwQP7u6e4E5IgiQEXSQLSAhwcQ3u7pYgIVh4uLs7QZK8Dwp6zZrpmdNz9j3nnp1T+4+99q5pqa7urq7uqV/1Dscff/yJ8pMSSAmkBEYksOMIPckpgZRASuCfEkgdkeMgJZASmJJA6ogp6eSzlEBKIHVEjoGUQEpgSgKpI6akk89SAimB1BE5BlICKYEpCaSOmJJOPksJpARSR+QYSAmkBKYkkDpiSjr5LCWQEjhJiwjufe97H3nkkd2Uz33uc7du3bq8xKOOOur5z39+t0X3vOc9d9xxxyQWmSwukMtd7nJGTlfIl7jEJfbYY49NS3zhC1/YMt02WpodWnyxf/3rX//tb3/rsn7a0572j3/84/IScY7/botOdapT+ZvEIpPFBbLTTjsZOV0hoyh20xLNmo02/1v4adIR97jHPT772c92i7Pe+iwvkR3BFOq2yOJ24hOfOIlFJosL5PKXv7yR0xXypS51qT333HPTEl/84he3zMmNlqZJR6Qd0e22xRdYpW0GgyXtiO6wIY0Tsh2x0RRb8pMSSAmsmwTyvca6iTorSgkspQRSRyxltyXTKYF1k0DqiHUTdVaUElhKCaSOWMpuS6ZTAusmgdQR6ybqrCglsJQS2G464nvf+x4/vKWUWTKdEthMEmjSET/84Q//p/NZ57n985///JOf/KRO+f3vf/+tb32r9M7+++9/9atfHV9f+tKXNlOXZVtTAusqgSYdERx9+ctf/r9/fT7+8Y+vJ48f/ehH73jHO/LjuvWtb931eL/ABS7wzGc+Mzya1pOfrCslsKkkMENH/Nd/PjzGyOjrX//6Fa94xUc+8pE3vvGN73SnO/3yl78Mwb33ve/dbbfdeN0+8IEP/MMf/hBEboWPecxjOOde+tKXPuigg4qIn/GMZ1z0ohe9wQ1u8OMf/3hC7mr+2te+9o1vfONxj3tcSXarW91KLTvssMNExnyUEkgJLCiBGTpiWNPPfvaza17zmm9961vtPp70pCdJQFM89KEPfdrTnmZ3ADd14IEHRi5zm5r4wAc+wCi44AUvGESmwRnPeMbPfe5z5znPeV72spcNyy+Uc57znN/85jfBz05ykiag6kRR+SglkBKYJYEZOoIiYAX43O9+94s6Tn7yk1/72tf2+yY3ucmHP/xhPz7xiU+wCy5zmcuc7GQnu/vd7/7BD34Q8dhjj33b296211572Rec8pSnvN71rhfZTfg73OEOJz3pSSma73znOxN8n+Mc53DGKQHDZJ999umeSkzkykcpgZTA4hKYsSyzFyAjVcnyj4p33nlnMRf8Ps1pTvO73/3uH//4x69+9avTne508fT0pz99bEB8H3fccWc605l67JbsNi9//etfJxpDm/z973+XgCXi+9WvfvXee+89kT4fpQRSAttKAjN0hEkeOqLU/Zvf/MbUZQh49WDCm8m77LJLOZj4xS9+4a/EtAZV4sThrGc966r5jjgXGLBDOdvZzrbqcjJjSiAlMEsCM/YalvryiTqcODhHoCZ8ew2JeKUrXcmbSHEljjnmmBe96EUOLxFN7Bve8IYHHHCAncKf//xnh5qzWKRrbFJsXuSyKznvec/riNRvZktYHxjoRbuZVX4mTgmkBCYkMENHXOQiF/nf/3wcMSj0LGc5y7e//e1LXvKSvh03oNhfeFXxiEc8wisPZsVDHvKQqPsJT3iCeW6G77rrrkcfffQEQ71HfCIOPvjga1zjGuc617k8csDxjne847Wvfa3fgqlhh9655S1vebGLXay9zEyZEkgJtEugKcZMtTjvPgUU+tjHPlZ9msSUQErghCGBGXbECaPB2YqUQEpglgRSR8wSVyZOCWw6Cax+r7HpRJUNTglsSgmkHbEpuz0bnRJolsAS6Ah+U96GXPjCF37961/f3K7Nm5A7LJzu5m1/tnxbS6BJR1Sx4Te72c1e97rXFX5M4/C8RuEuDYLBsSqe8mKA4F71wPXG1NsT39u67ZXyfvSjH4GKQZT4/slPflJJ8R+Sdzrc0r0Pvutd7xpN46YB4XaFK1yBN7r3sj/96U8nss96tN9++z3nOc9pzIKHLVu2NCbuJmtvO4/76173uhe60IVud7vbBRiPU0w3eoDfpfdXwUlm2VASaNIRwXEPG37Vq171U5/6VDwyvIwJ0yP+fuQjHwHW8r2hmtrCDC8PkPNPf/rT1MRjH/vYiSzQKO9+97tB16gJkFYp6QgXKLz85S8HXeGuHsSJEtboEW8RoJhVFN7Ydl5wEL0PetCDvvCFLzDuQkqEEHEDfD/rWc+6+MUvfoYznGEVPGSWjSgBPs4rfn7wgx+c+9zn5tfYTfmZz3zmKle5SlDsAm5/+9vHb34TPJoOPfRQ0K+g8LmUXSHDiiAvrn/96w/pQ8oDHvAAZkuX/p73vIdvFQ8uj7haxaN3vetdV7va1YxRC91Xv/rVCeKwCoUwfxgFHuGWQycHrWGyHsXlSxzGekQhNtxtOZZXQ25605tCyoPDMli0As5FYpYL1SMj2Bs4LIpvQjYDtciP2972tqVMQiY9nqwQdKSNztlMGk3oihpSxo1qZMK6udvd7tbrxFJae9tdccaAiowYJqU//elP3Za64OslL3nJWNuTvnQSOFELx1UdYbQZpjGjOFa6BS+KMiLvda97caY0KGNETugIuazbLTz0dAQHbYsYPfWXv/zlPve5Dz/OKERECUS/YUNZNxPEYaUMZsxYJ5/+9Kf79pvpNExWKPe97321kfozOXvJnve854mLM5aXjjBdNUFemHfeqG95y1skvvnNby5qDnuEJcKrnYN5lPDEJz7x2c9+dq80wrffMT9pge9+97vl6WUve9mujuCTep3rXAdqVrFvf/vbfVe5am87HUErRSE2GppgVShlUnacX0PlVStK4tJJYMZeo4cNh8IwjmO7wTh3HhFmkvFtXTVQYL16F4IO7SjTzGo/pK9IqYLQ5RJyhrlrhtsScxWPcoZEczhw7uWbtqJuWOnG9xve8AbffitngpMnP/nJb3zjGy2bVu9uMlNUvKzpvQa0O6ibLQkfcxA11fFnF0SHGc+H3bIPDrei0zpdfIpTnELrxNcY4/NNb3oTIatOsWL5+F6w7ec///l54lM3VL/1QIF+lNopO1vOJb20bkyGm5w+A/c5xIabG3QETWE1c4JFlALJWMb33XdfA9dYoS9Y1Gsh4ioIXUWWdJ+nPvWp9iDWZPiRKlHcCjEvuoyBk1iNNcSMPfzwwz3y2wycYP6///VxPGnuOZgIUCyj3dQFXQ+BjGWPxL7jY9Y54zTZAhonF/XUu197WFQL/tV2oOjKKGHBtpMJo4Zp4yTCBvPUpz51N1xgKM0hq0lZXgnM0BFDbLhjy61btx5xxBGURcSMsw+3v4jpxwa2mD/qUY/aJtJhlSiwFFUFoXtKJfmYYA9+8IOdFDjkrxJf8YpXDK8Iv/Od74x5OxQYdt/m7cT6XDgxye0azGf6yBscCsIRw41udKNZrWZ/Eq+D3ir+hWwlGBYYimZI71LOfOYz2w92NfXibb/yla/sMEgttjBKO/vZzx41iicoVtC1rnWtaZby6XJJYMZeY4gNNzgMX+YlZRHN/tCHPuRczfbBR1g6xnN5g2h3XUooI/5Vr3qVw8UWkbHJ7VxKxioI3Wb7ne98p9WYQhGxIo73q0SHBUZ593OXu9zFkmj0M8WpGFa03VNZIb/yla84WfQdrJoJzgut/KL1CdJHDhQEnXL/+9/fJkvh0dKWdpU0NvZ2H/QaPcWEAW+194mnCifJWaWVxA5Htej73/++Yr2I8b1g25XsmEboEJsj+ymvUWw3ojpH105bRSdbHauZa2NKYIaOGGLDNYl2oAvKhtzviF7nkYXRsSKtES23vBRo+ec///kgsswjCN2K0mHWGpR4iAhUVRA6DULpWDNtc6yxPBcUWyWa/NjrfkIdCHLhOMPBJ3UgNn/hypzHZ4SrQKSDaEZngbw2KMEXvOAFiJZr7l5CafQQ9Cs2LRLQtocccgijDP+kSkeEaeYpV5SwBUQGnyiNFqPXIoC4H1Z1ic1hR6EibmiU80tlLth2ZepTJya0Dzvr0Y9+dLBERZIJ4gSH+WgZJVA3YpexJclzSiAlsBYSmGFHrEX1WWZKICWwwSWQOmKDd1CylxLYzhJIHbGdOyCrTwlscAmkjtjgHZTspQS2swTWT0dwji6+mNu50Z3qE0m9cfoiOdmYEpihI3gTruhbPdFIbytLmOyJZIs/msXnqpHUVT4b4dVjSGouqpiHAXGFKlRlVMF/pMCuYbeCyBOBmxY8Vbx27TLzvve9T/pyQUE1ZZXIHYM0wECAyrhUKLPKZ5UocZVP/iPeQAOkWR54uAefXmB3geTucENvTxmFSK8cqPlu2/P3mkigHWGy++67B1yqPct2Sbkd+eSpyUPZlWWcOKC2xprPYZSjV3zMED4FkZJbh0tJOBq89KUv5YAQRF4YHN4jcUFt8lDw4fXA16tbCw8OzhThBxn0asoqkacDN23uYWD+FIHsVT6rRImrfIKQ77HHHtznFAhuH2AzTEZzQMJ40BCX7O0po138aGlJLuHd5ufvtZBAkx3B+c86wNVvzz339MOVv6GuwvuQUzMfKnBDyC7jG4IIUAo0UK+Db0RKHsqAXt29Bpckdj4/JdhwN/RM3BsOVGrsKl+cFRXBUEWZjBrrrUUvMJSI7XxKzGEJP5bibvAbIrYyA01YTsG04xoRiTlW8QHzPaGnAckhzSDiXVkGisqrujS/l4sjU7mEPXSEBPxB+XTzQOMh6ptnJEpk5LIV6YvzNQ59hh6NXONpnG78iGrKIdGkhcfRs/xZWXyWaFVX+awSx/jUrTy78K9AnuYQMVK6ujGaw+9TFxAXYntKiUHm6R2QnKg3v9dUAk06wiQ04s93vvOBS/kRIIhgiz8yx2FEEWV43ZljJrOAVGZL995wE49jf68lbv2jOER8kGX63nCLqlAL3J/f//73m6jsTJguescd5UceeSTjHDZc4e18Smx9w3YPocgI98GMUXiLW9xCc4JnU4iXp++JzqD1eCUr0C1E4CTm84oupHwi8RDgDhNJWCfSoBo4WdKGKFGdNZMEIF9++9vfTjBALLJzSJ1IM/ZI61zaKu6DfQFDrEQPivRdPksJQ+KQT37fcH12MbqJ+dC7KomoWT1RYHtKhoylxcox1pakb1sJNOmIiSrNInBmaws4oIXCJBHUwGizUFjQpnHfrueLCHTchFe8NxzGEdRKFiAloxPUQi7roanIsihh8sZY7fE5lmyIpI6UcRfZ9MI1F1qu5B6SGtgBqFzcCuaAeH9R9cMe9jBEwZ0swtN4c1h1gJGCnhhrY5VO0VPZpMQZnAElWkdxPB/yGSX0mK/yycqLDQXNZf8VJkNkNzbCdoi/7SkPO+wwiizubau2JYnbVgIzcJ/VioUkYzqWR3T8QQcdZDWLDSecUjVXEAtiyrDujshhFuZ3YKg98iOQ1N2gFXgA/egOwV4hPT6HVQRliKQeSzmks/xnQcuV0EVSsxEoOzaITQ1zyVkDxUfz2udHXWwlgFptr8I9GT5OTBsBclXmHXbYKGkFiIeFmtZ2ghApq4jvHrHKJ8uCKmcAMqm0iJanC6JMRgSDpWsrtaS0fXMEo+phE5KyRhKYYUeYqMX2Ltz0xqs9LViXOEtM6IgNtRZ8YwMcy6qrlvgAiRUF0cLnGFeBpB57Ok231QpouWQt0PIektosoumczpg2vinNnhWGruHDLgiuYDHZ8/G+wMmRU6HhK48J/plpjEGfSFN++FtFfFeJkbfLpybQOIxKkWmogAjMIdkQANaYkulBUA68tFToUCdQ7NaJduWjxSUwQ0c4yhKVbLpK53bWCpFXDAJ2+3TiRZ5atSgj22Zzxjk8SHgprYXPsaqHSOpI2cOGV7O3Q8sju4W0i6RmPDvBYTtoUezhBY9yxOAtpsMXSseBokOK2EoQLyXCaosfsnil4kwhPk6OvCV1XqOiYcoqUZc5FYq3Ko5RzWqTsMpnlTjGJwisZQMP3miwdMTajOwaaNvoYLtIsjElXVOayTBxAmUjVu2OJG4rCczQESxh+2SnjE95ylPGqgdDti1nEtvTFkvVey/H1w6lHHD6sWp7uFupUAsOUHFia+rcK3DQkaCFTykbkdRRpgnZxYaPNb8RWi77cCF1iOPQQQQtR7BiUtiyaaNkiITm1Y/12dOomo1gUoGiUxx+FKz9kLFqyipR4Q4jHCt64yPSVGwhh3xWmR/jU5l4c44D1e5EtuxH+EoYJF1rpT3lsI1JWVMJJDZ8TcWbhacEll4CM+yIpW9rNiAlkBKYL4HUEfNlljlSAptJAqkjNlNvZ1tTAvMlkDpivswyR0pgM0kgdcRm6u1sa0pgvgSWXke85jWvmXgXO18g2zmHuznaw+TzFOChtF04nsXnghxy9udLsopCvG7vIQlXUUhmabrvEz6CV3X5xHW14fPX8l3NXiW2lNZNw6+R7wC3i7kZpecMyumAV08XXl0lthfu/X+RUrkAdVaZ3NhhLhprhKzl71QSt1fEe4XXI1y2W0XK5aBDIt9HvifUUPdGz6iunU/IGrDdxhZVk3GWcytq9dGKRBk5nq2YbC0ScAzhEsJ7hWBXLJ/Pm8gAEkMMR2LAX3LTR659dgtcEA11XcaHRaPozSCaBSIS6FDup8DyfFVWrG5WglYdAWj074AHxxzDvW9WHdTBMHuVOKtYicVBKPeVryLvMARDNbBCe8nVGAqzyiRkne2GmxUrhe/gm8RjraRsr8h1apxTBW5w+7HFNkoYEg1upooAYu4r7PHTzufiOmJFUUwk2I46AkA54PYr6og3v/nNQn4IzqLfoZCiOXQBNAPXW+pYR7sXCr0aZQMcBriRM645RaEAs0wIZBWPZuw1SsiDcI8bC+swZpv1skeyIVFMAQ2G/OGn3PWerBYLkC4IRfXRisRhDAVZhsTAL9Pxj3/84zkL6gM9MVE4b8iWWA82FJZozTQ4DJFSoLwWE+vGRBXxiE8kzcujuaQcMj9WiEp5rEO4cOWkAiJZlQiP08W/AK1F4kY+WXl77bUXIIkfPgJkRHarJVdOXrkEGz7jXM454Aoz4bsE0YLvkMta2t1riGYG/+o6OAxzCR1r4xgdXMDmhSLWlaUiMxCeDZF7eLl7qUqMYqHRbHLHqgg6P2OofxKeTuapSW42qTo84lHMZMqCGWI4mQh8cP1Fr0bZQJRXUIItW7b4UTp0xXobE7TiPtkznJf553KhhRcyblQgqIFmgCRzChYWhdM+eHi14mr2KpHVJFCaplrBuhOgWiwlgoHqo21IJHrOy5SRMHAcwK23YtuMlQ/p6JGhbxzr8rFkBx54IFy8bYWloxdfB1CCkW8UjuUNujQFUjGdsvrUlBDjA4zy4Q9/eEnQIwoUAvFtSRASTtvdFa73Ta1I38InxJ15KB7HMHqI5U64LZiUEhaAXzkdIUgf04aQDXqnCUowpXtNsPeBEI9lU+IJvO+w7ZzcLc60MBScOHoAMjDBdBB3+wiSVKIEVolRoME5HctjWO8EhcVhx+d+NhqBxmRB/Ate989P5KIybD381ljyFNAQgKjE4zAadaLZJ4HAS9v8eK5JR5irYkDRi7rTsiDMkWZgSAfDX3bDOlR1RDV7lahMciEyl263TAB48G7MpYluWOSRZloNrJxgV/CRjLqx0swobFtsATfoiN61w91clCwAiKJEo6GDuo9A5q11Y1UUujSLtJ1mFzDCNCj3MCq5R2SnWOKYOXqfRnMPexfm28jnWEPA5wjW0wggUKAcFnMIWnuECQtRYtg2c9t4E0Zs+or2HgOUgmYGogzYh6Jk0OkOmy/zUPeVeqvEKK0HyR1rYyPdgGEV2pRZLW5zm9tYIJlOIHavfOUrBRYSKAA94hsxPMUB8pQ20R2hHI1JKD76VHVAbjI21tuYrGmvIaYAg8cMYUqwEi0pUfowrEO11mr2KlF2C7Xy9RNUXzFNq8UiklGxfiPNUUcdpZt9aNyxXHPpMTEigEVErxgrwdgV/M7Is5M0Fp0ejaWkQZhR0jOtmeLdZCY/COlYxkKXptf2FbN0E7BxsOqgwcJV+OwRDVwLlPXcSk5Z6BHrZymkkc8xrozs7iOruvJddGpzoRbCGcuI3h55ZFgIvVzsfxsuilIa57LqdXBg4JmZkatKHBa4OIXCcqxG+JRdHEwok+3GXMIPg8sN2NHkiMdhEXVW7XgysHxQf8wQFoTP0UcfDXi5OEvdEpp0RDcDBTY29FlEKzJXzd4lsriYpqw+SkR0gOkCLXS93VcEjDLIhsbtdFHtTxubGYdDY8Uyvmw3HFNZTqE8u8kwXyCzY9nRpVl850nlUcS9E5ZCdE7OMre5cLQJl2nUFuApBhr5jG3psCG9yCMiXwkO6BWGzYXVqEXIwzKHlOF4Y7iFXpBY2/31wyy1YkOss5jodycRY8RhFYtT2FNlW1F+uIyetvriF79ozuvoGBLVKBuIlnCq3CeCqizOUreEJh1hcaaiHINT9kIMOBubxUQ1e5UolKNIEMwqXWtsrWhLOxCJs5xZ/ERimq4XggG9SmwsfCyGQrVMu0onEWGIdZup7baaYTdO1+vIw3GM9xolWbWiYSE2jIwCb9EwTD0Zi5bTKlEvRHb9QmULihWTB7GdT4W3wOptG5nQSvZmfXHdV1ptM+LMpRtYlC3MXNf1hrSjB+u2xEZRHIvYUWp14OKrxCiZ9eeG+qFsuxRqTi0MovjRXVl72ZmTSiNbDXdQEpsdoQlto+yA7FvZjBG/qxplA9F+hFnHrnQyyDycZmz201jupr+ZzYxA4T2MXStJNJsVagdFzzlhlt2339VyqtmrRDL1TtjrX5tSMWn1brXAQsQJE3F1/hEOC4ZOH0Mip4MI0G4Eq9e62gtXX5gRBsZhkg7TnQKI6914NCwT3eG5baddicWz630g2q0VdbrV5ak3Yd6ulb/VioZFsUttekWp0CImLkUjTZVY8pq3QmNZo4prTDuf3pTj0ybZ4CkyEeNDCKIubw5ETRW9v++++/JbcWbpKdPacQkL3Hjwg2oLIiMx8sqyoreOcFWsS43VQXJZ6vSOPrLUea0Y5WDGekMmNMg0MdIzYIv/S7cV3d8Y6w6wbvpedoqeiJzXElFpmjfZbGop7ZodlETJXoc5pMenFYIdGkTTxLseItJMu8K4i2CMq1XQm/wjVlHuumXxCoqiXbfq1rqiqsPSWKWWnQjePZZg7eiz+Fw7NrLkdZBAxpiZbXllhpTAppJA03nEppJINjYlkBLoSiB1RI6HlEBKYEoCqSOmpJPPUgIpgdQROQZSAimBKQmkjpiSTj5LCaQEUkfkGEgJpASmJJA6Yko6+SwlkBJIHZFjICWQEpiSQBM2nOdsD5vIsRTUZHmJ0CJcqruCgYCEnkhikcniAoE7MHK6QuYBzcV+0xKX9GrSJj9LuEBhObqdDWHGS3x5iTjHf7dFgb1NYpHJ4gKBjOohSlEUu2mJZs3Uer1RnzXpCNe3A8l1m2C99VleIjuiFwDG4gatnMTSy4sLBCTJyOkOG7gjeKpNS1wx1sHG1BJNOiLtiLQ4QgKzjIu0I7rDhjROyHbExlRvyVVKICWwDhLI9xrrIOSsIiWwxBJIHbHEnZespwTWQQKpI9ZByFlFSmCJJfD/WA+BV8XVDjoAAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "id": "459f6f0f-f81f-4ba2-9855-3bc11f1be415",
   "metadata": {},
   "source": [
    "![изображение.png](attachment:4cfe7b86-a772-44ca-914a-989d1cf1dd56.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6092b42-6423-4b4f-81b3-b6ddec64ecf1",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24c94665-4148-40ed-b2a9-516dd3becc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bob1ch/Рабочий стол/NN-NLP/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#import keras\n",
    "import os\n",
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import sklearn.metrics\n",
    "#import tensorflow as tf\n",
    "import tqdm.notebook as tqdm\n",
    "import sklearn.model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#pytorch\n",
    "\n",
    "import torch\n",
    "# from torcheval.metrics import MultilabelA\n",
    "from torchmetrics.classification import Accuracy\n",
    "#from torchsummary import summary\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchinfo import summary\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa64dd82-a3ac-449a-a143-161cef4a0fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'models'\n",
    "MAX_TOKENS = 32\n",
    "MAX_LENGTH = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c18c6e-1c88-4e6b-8f13-476b78b88a2b",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e38ac2-a5e2-4435-8c95-0982e3039768",
   "metadata": {},
   "source": [
    "Get the dataset from [here](https://tatoeba.org/en/downloads). Preferably use russian to english translations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e09a5d-8537-4ffa-8583-f09c30028b2d",
   "metadata": {},
   "source": [
    "Use a custom tokenizer that can add bos and eos tokens (pass `add_special_tokens=True` when calling the tokenizer to add them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8312a719-f1cd-4982-a2e8-2178a7abe850",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Tokenizer(transformers.GPT2Tokenizer):\n",
    "\n",
    "    def build_inputs_with_special_tokens(self, token_ids_0, token_ids_1=None):\n",
    "        if token_ids_1 is None:\n",
    "            return [self.bos_token_id, *token_ids_0, self.eos_token_id]\n",
    "\n",
    "        return [self.bos_token_id, *token_ids_0, self.bos_token_id, *token_ids_1, self.eos_token_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b187545e-882a-4cd1-8bab-dcec2f33b5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'Tokenizer'.\n",
      "/home/bob1ch/Рабочий стол/NN-NLP/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7f058be-ac90-4848-85a4-26d682cbee87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tokenize(data):\n",
    "    return tokenizer(data, max_length=MAX_TOKENS, truncation=True, padding=True)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8085cd75-b06f-4137-ab61-259246221c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('seq2seq_dataset.tsv', \n",
    "            sep='\\t', \n",
    "            on_bad_lines='skip',\n",
    "            names=['id_1', 'rus', 'id_2', 'eng'])[['rus', 'eng']]\n",
    "\n",
    "X, y = to_tokenize(data['rus'].to_list()), to_tokenize(data['eng'].to_list())\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size = 0.7, shuffle=True, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdaee73f-f7b0-4784-ba6e-28fb68efa65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_collate(batch):\n",
    "    (inp, out_BOS, out_EOS, masking_PAD) = zip(*batch)\n",
    "    inp = torch.nn.utils.rnn.pad_sequence(inp, batch_first=True, padding_value=tokenizer.eos_token_id)\n",
    "    out_BOS = torch.nn.utils.rnn.pad_sequence(out_BOS, batch_first=True, padding_value=tokenizer.eos_token_id)\n",
    "    out_EOS = torch.nn.utils.rnn.pad_sequence(out_EOS, batch_first=True, padding_value=tokenizer.eos_token_id)\n",
    "    masking_PAD = torch.nn.utils.rnn.pad_sequence(masking_PAD, batch_first=True, padding_value=tokenizer.eos_token_id)\n",
    "\n",
    "    return inp, out_BOS, out_EOS, masking_PAD\n",
    "\n",
    "def get_dataloader(batch, X, y):\n",
    "    X = np.array(X) #Торч поругался, что я не могу сделать отрицательный степ\n",
    "    inp = torch.LongTensor(X.copy()).to('cuda') #а потом он ещё поругался, что в массиве у меня отрицательный страйд и попросил .copy()\n",
    "    out_BOS = torch.LongTensor(y).to('cuda')[:, :-1]\n",
    "    out_EOS = torch.LongTensor(y).to('cuda')[:, 1:]\n",
    "    masking_PAD = (out_BOS != tokenizer.pad_token_id).to('cuda')\n",
    "    masking_PAD[:, 0] = True # я получаю маску по BOS [50625, ..., 30, 50625] -> [False, ..., True, False] -> [True, ..., True, False]\n",
    "    data = torch.utils.data.TensorDataset(inp,\n",
    "                                          out_BOS,\n",
    "                                          out_EOS,\n",
    "                                          masking_PAD)\n",
    "    return torch.utils.data.DataLoader(data, batch_size=batch, shuffle=True, collate_fn=pad_collate)\n",
    "\n",
    "data = get_dataloader(256, X_train, y_train)\n",
    "data_test = get_dataloader(256, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "639e2629-c729-4155-8907-5e42c4c38da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[   40,  1101,  1016,  ..., 50256, 50256, 50256],\n",
       "         [ 2990,  1053,   587,  ..., 50256, 50256, 50256],\n",
       "         [   40,  4601,   345,  ..., 50256, 50256, 50256],\n",
       "         ...,\n",
       "         [ 2437,  3105,   345,  ..., 50256, 50256, 50256],\n",
       "         [   40,   423,   734,  ..., 50256, 50256, 50256],\n",
       "         [   40,  6520,   284,  ..., 50256, 50256, 50256]], device='cuda:0'),\n",
       " tensor([[ True,  True,  True,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ..., False, False, False],\n",
       "         ...,\n",
       "         [ True,  True,  True,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ..., False, False, False]], device='cuda:0'))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp, out_BOS, out_EOS, masking_PAD = next(iter(data))\n",
    "out_EOS, masking_PAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e233b207-d736-4313-bf4d-c7b9b9f5471b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([   40,  1101,  1016,   284,   466,   345,   257,  2661,    13, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256], device='cuda:0'),\n",
       " tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False], device='cuda:0'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_EOS[0], masking_PAD[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "074114b6-d629-405a-b516-b73ba6d5dde6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([   40,  1101,  1016,   284,   466,   345,   257,  2661,    13, 50256],\n",
       "        device='cuda:0'),\n",
       " \"I'm going to do you a favor.<|endoftext|>\")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_EOS[0][masking_PAD[0]], tokenizer.decode(out_EOS[0][masking_PAD[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1b16299-d391-4627-9407-bc9575e3c315",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pad_collate бесполезен, я его убрать забыл\n",
    "#бесполезен по той причине, что у нас все последовательности уже одинаковой длины\n",
    "#см. Функцию to_tokenize!!\n",
    "def get_dataloader(batch, X, y):\n",
    "    X = np.array(X) #Торч поругался, что я не могу сделать отрицательный степ\n",
    "    inp = torch.LongTensor(X.copy()).to('cuda') #а потом он ещё поругался, что в массиве у меня отрицательный страйд и попросил .copy()\n",
    "    out_BOS = torch.LongTensor(y).to('cuda')[:, :-1]\n",
    "    out_EOS = torch.LongTensor(y).to('cuda')[:, 1:]\n",
    "    masking_PAD = (out_BOS != tokenizer.pad_token_id).to('cuda')\n",
    "    masking_PAD[:, 0] = True # я получаю маску по BOS [50625, ..., 30, 50625] -> [False, ..., True, False] -> [True, ..., True, False]\n",
    "    data = torch.utils.data.TensorDataset(inp,\n",
    "                                          out_BOS,\n",
    "                                          out_EOS,\n",
    "                                          masking_PAD)\n",
    "    return torch.utils.data.DataLoader(data, batch_size=batch, shuffle=True)\n",
    "\n",
    "data = get_dataloader(256, X_train, y_train)\n",
    "data_test = get_dataloader(256, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b492309-09ea-468c-b246-c6d95dd29b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[   40,  1422,   470,  ..., 50256, 50256, 50256],\n",
       "         [24119,  1595,   470,  ..., 50256, 50256, 50256],\n",
       "         [ 1532,   314,   836,  ..., 50256, 50256, 50256],\n",
       "         ...,\n",
       "         [13787,  2125,   470,  ..., 50256, 50256, 50256],\n",
       "         [13787,   655, 12120,  ..., 50256, 50256, 50256],\n",
       "         [13787,  1297,   502,  ..., 50256, 50256, 50256]], device='cuda:0'),\n",
       " tensor([[ True,  True,  True,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ..., False, False, False],\n",
       "         ...,\n",
       "         [ True,  True,  True,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ..., False, False, False]], device='cuda:0'))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp, out_BOS, out_EOS, masking_PAD = next(iter(data))\n",
    "out_EOS, masking_PAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f0338c3-c967-404c-8c4f-8d9257418517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([   40,  1422,   470,  1612,   826,   783,    13, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256], device='cuda:0'),\n",
       " tensor([ True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False], device='cuda:0'))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_EOS[0], masking_PAD[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7dc80761-e75e-47de-a4aa-a2bf791dcf24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([   40,  1422,   470,  1612,   826,   783,    13, 50256],\n",
       "        device='cuda:0'),\n",
       " \"I didn't mean right now.<|endoftext|>\")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_EOS[0][masking_PAD[0]], tokenizer.decode(out_EOS[0][masking_PAD[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f4f399-308a-457b-a3ce-a8ede414603e",
   "metadata": {},
   "source": [
    "Since the dataset is rather large, you can omit the validation dataset and just use a set of test sentences after the training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff78613-15ce-4695-aced-4379ec067765",
   "metadata": {},
   "source": [
    "Create a dataset that returns the following\n",
    "* A pair of tensors `((None, L), (None, P))` -- input sequence of tokens and output sequence of tokens to be fed into decoder (this should start with the BOS token)\n",
    "* A tensor `(None, P)` -- output sequence of tokens to be predicted (this should end with EOS token)\n",
    "* A tensor `(None, P)` -- a masking tensor marking padded tokens with 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff24dcac-c9f8-4d56-b584-5208c423f196",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c219a81a-59ea-4b56-96da-caa0e24c3db5",
   "metadata": {},
   "source": [
    "Create a model for training. The model should have two inputs: input sequence `(None, L)` and output sequence`(None, P)`. The model output is a single tensor `(None, P)` logits (or probabilities) of the next token predicted for each input one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ee04317-1bbe-4f23-8e1e-595577d35663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_model(\n",
    "#     units: int,\n",
    "#     n_tokens: int,\n",
    "#     n_labels: int,\n",
    "#     n_stacks: int = 1,\n",
    "#     bidirectional: bool = False,\n",
    "#     name: str | None = None,\n",
    "#     cell_type: type[keras.layers.Layer] = keras.layers.LSTMCell\n",
    "# ) -> keras.Model:\n",
    "#     '''Creates a model with RNN architecture for sequence to sequence classification.\n",
    "\n",
    "#     Arguments:\n",
    "#         units: dimensionality of RNN cells\n",
    "#         n_tokens: number of tokens in the tokenizer dictionary\n",
    "#         n_labels: number of labels to be predicted\n",
    "#         n_stacks: number of RNN cells in the stack (1 -- no stacking)\n",
    "#         bidirectional: whether or not the model is bidirectional\n",
    "#         name: the model name\n",
    "#         cell_type: type of a cell to use, either keras.layers.LSTMCell or keras.layers.GRUCell\n",
    "\n",
    "#     Returns:\n",
    "#         The model'''\n",
    "#     ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaf444d-10f3-497d-8cc5-22a86835f433",
   "metadata": {},
   "source": [
    "Try to add attention to your model (for example [additive attention](https://keras.io/api/layers/attention_layers/additive_attention/)), does it perform better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0f7fc62-7901-450a-847c-fdd3fef43f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, cell_type, input_size, hidden_size, bidirectional, num_layers):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bidirectional = bidirectional\n",
    "        self.num_layers = num_layers\n",
    "        self.cell_type = cell_type\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = cell_type(hidden_size, hidden_size, batch_first=True, bidirectional=bidirectional, num_layers=num_layers)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.embedding(input)\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        if self.cell_type == torch.nn.LSTM:\n",
    "                h, c = hidden\n",
    "                h = h.view(self.num_layers, 2, -1, self.hidden_size).sum(dim=1)\n",
    "                c = c.view(self.num_layers, 2, -1, self.hidden_size).sum(dim=1)\n",
    "                hidden = (h, c)\n",
    "        else:\n",
    "            hidden = hidden.view(self.num_layers, 2, -1, self.hidden_size).sum(dim=1)\n",
    "            \n",
    "        return output, hidden\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, cell_type, hidden_size, output_size, num_layers):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.rnn = cell_type(hidden_size, hidden_size, batch_first=True, num_layers=num_layers)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor):\n",
    "        decoder_input = target_tensor\n",
    "        embedded = self.embedding(decoder_input)\n",
    "        output, hidden = self.rnn(embedded, encoder_hidden)\n",
    "        output = self.out(output)\n",
    "        return output\n",
    "\n",
    "class Seq2seq(nn.Module):\n",
    "    def __init__(self, cell_type, input_size, hidden_size, device, bidirectional, num_layers):\n",
    "        super(Seq2seq, self).__init__()\n",
    "        self.encoder = EncoderRNN(cell_type, input_size, hidden_size, bidirectional, num_layers).to(device)\n",
    "        self.decoder = DecoderRNN(cell_type, hidden_size, input_size, num_layers).to(device)\n",
    "\n",
    "    def forward(self, inp, out_BOS):\n",
    "        encoder_outputs, encoder_hidden = self.encoder(inp)\n",
    "        decoder_outputs = self.decoder(encoder_outputs, encoder_hidden, out_BOS)\n",
    "\n",
    "        return decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aebf12f0-0a9c-4463-b2c0-04ffe2d93612",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LSTM = Seq2seq(torch.nn.LSTM, tokenizer.vocab_size, 128, 'cuda', True, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82dae730-cc09-46da-ac2f-06fcb67c743a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GRU = Seq2seq(torch.nn.GRU, tokenizer.vocab_size, 128, 'cuda', True, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac941115-30d1-4e56-b325-44bcdfaf47fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "Seq2seq                                  --\n",
       "├─EncoderRNN: 1-1                        --\n",
       "│    └─Embedding: 2-1                    6,432,896\n",
       "│    └─GRU: 2-2                          494,592\n",
       "├─DecoderRNN: 1-2                        --\n",
       "│    └─Embedding: 2-3                    6,432,896\n",
       "│    └─GRU: 2-4                          198,144\n",
       "│    └─Linear: 2-5                       6,483,153\n",
       "=================================================================\n",
       "Total params: 20,041,681\n",
       "Trainable params: 20,041,681\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model_GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e66a546-cca9-444b-9cbd-d3712de31d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnEncoderRNN(nn.Module):\n",
    "    def __init__(self, cell_type, input_size, hidden_size, bidirectional, num_layers):\n",
    "        super(AttnEncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bidirectional = bidirectional\n",
    "        self.num_layers = num_layers\n",
    "        self.cell_type = cell_type\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = cell_type(hidden_size, hidden_size, batch_first=True, bidirectional=bidirectional, num_layers=num_layers)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.embedding(input)\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        if self.bidirectional:\n",
    "            output = output.view(input.shape[0], -1, 2, self.hidden_size) # B, L, D*H\n",
    "            output = output.sum(dim=-2)\n",
    "            \n",
    "            if self.cell_type == torch.nn.LSTM:\n",
    "                h, c = hidden\n",
    "                h = h.view(self.num_layers, 2, -1, self.hidden_size).sum(dim=1)\n",
    "                c = c.view(self.num_layers, 2, -1, self.hidden_size).sum(dim=1)\n",
    "                hidden = (h, c)\n",
    "            else:\n",
    "                hidden = hidden.view(self.num_layers, 2, -1, self.hidden_size).sum(dim=1)\n",
    "            \n",
    "        return output, hidden\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, cell_type, hidden_size, output_size, num_layers):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = nn.MultiheadAttention(hidden_size, num_heads=1, batch_first=True)\n",
    "        self.rnn = cell_type(hidden_size, hidden_size, batch_first=True, num_layers=num_layers)\n",
    "        self.out = nn.Linear(2 * hidden_size, output_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor):\n",
    "        decoder_input = target_tensor\n",
    "        embedded = self.embedding(decoder_input)\n",
    "        \n",
    "        output, hidden = self.rnn(embedded, encoder_hidden)\n",
    "\n",
    "        out, _ = self.attention(output, encoder_outputs, encoder_outputs)\n",
    "        \n",
    "        output = torch.cat((output, out), dim=-1)\n",
    "        \n",
    "        output = self.out(output)\n",
    "        return output\n",
    "\n",
    "class AttnSeq2seq(nn.Module):\n",
    "    def __init__(self, cell_type, input_size, hidden_size, device, bidirectional, num_layers):\n",
    "        super(AttnSeq2seq, self).__init__()\n",
    "        self.encoder = AttnEncoderRNN(cell_type, input_size, hidden_size, bidirectional, num_layers).to(device)\n",
    "        self.decoder = AttnDecoderRNN(cell_type, hidden_size, input_size, num_layers).to(device)\n",
    "\n",
    "    def forward(self, inp, out_BOS):\n",
    "        encoder_outputs, encoder_hidden = self.encoder(inp)\n",
    "        decoder_outputs = self.decoder(encoder_outputs, encoder_hidden, out_BOS)\n",
    "\n",
    "        return decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11d16e78-2fbe-4832-a2bf-34299fc9678a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================================================================================\n",
       "Layer (type:depth-idx)                                  Param #\n",
       "================================================================================\n",
       "AttnSeq2seq                                             --\n",
       "├─AttnEncoderRNN: 1-1                                   --\n",
       "│    └─Embedding: 2-1                                   6,432,896\n",
       "│    └─GRU: 2-2                                         494,592\n",
       "├─AttnDecoderRNN: 1-2                                   --\n",
       "│    └─Embedding: 2-3                                   6,432,896\n",
       "│    └─MultiheadAttention: 2-4                          49,536\n",
       "│    │    └─NonDynamicallyQuantizableLinear: 3-1        16,512\n",
       "│    └─GRU: 2-5                                         198,144\n",
       "│    └─Linear: 2-6                                      12,916,049\n",
       "================================================================================\n",
       "Total params: 26,540,625\n",
       "Trainable params: 26,540,625\n",
       "Non-trainable params: 0\n",
       "================================================================================"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_attn_forwdir = AttnSeq2seq(torch.nn.GRU, tokenizer.vocab_size, 128, 'cuda', True, 2)\n",
    "summary(model_attn_forwdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c5d763-e07d-48cd-a539-987a99ad74a7",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2006bfa0-eee3-439d-899d-7612e7a95a90",
   "metadata": {},
   "source": [
    "Train your model using teacher forcing. The idea is that the model predicts the next token that should follow, so one part of the model (called encoder) reads the text and output some state containing information about the text read. The other part of the model (called decoder) reads and already generated text (or in case of the teacher forcing the expected output) and predicts the next token for each one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26530629-8f9b-40cf-82aa-9a0f0b1ca890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df952b3b-6cc6-4d19-9fb7-4c4b68194690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, model, optimizer, criterion, teacher_forcing):\n",
    "\n",
    "    total_loss = 0\n",
    "    total_metric = 0\n",
    "    for data in dataloader:\n",
    "        inp, out_BOS, out_EOS, masking_PAD = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        decoder_outputs = model(inp, out_BOS)\n",
    "        \n",
    "        loss = criterion(\n",
    "            decoder_outputs[masking_PAD],\n",
    "            out_EOS[masking_PAD]\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        decoder_outputs = decoder_outputs.argmax(-1)\n",
    "        total_metric += (decoder_outputs[masking_PAD].detach().cpu().numpy() == out_EOS[masking_PAD].detach().cpu().numpy()).mean()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader), total_metric / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7292cb1-3e54-40a0-aeab-a2aaf813785b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, model, n_epochs, learning_rate=0.001, eval_every=1,\n",
    "               print_every=100, plot_every=100, end_teacher_forcing=1):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0\n",
    "    plot_loss_total = 0\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    teacher_forcing = True\n",
    "    for epoch in range(1, n_epochs):\n",
    "        if epoch == end_teacher_forcing:\n",
    "            teacher_forcing = False\n",
    "        print('='*40)\n",
    "        print(f'Epoch №{epoch}')\n",
    "        loss, metric = train_epoch(train_dataloader, model, optimizer, criterion, teacher_forcing)\n",
    "        \n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print(f\"train metric: {metric}\")\n",
    "            print('train loss: %.4f' % (print_loss_avg))\n",
    "        \n",
    "        if epoch % eval_every == 0:\n",
    "            loss_test, metric_test = evaluate(data_test, model, criterion)\n",
    "            print(f'EVAL: loss={loss_test:.2f} metric={metric_test:.2f}')\n",
    "\n",
    "        print('%s (%d %d%%)' % (timeSince(start, epoch / n_epochs),\n",
    "                                        epoch, epoch / n_epochs * 100))\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35b950f8-02a1-47aa-8389-563a2054a0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader, model, criterion):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        total_metric = 0\n",
    "        total_loss = 0\n",
    "        for data in dataloader:\n",
    "            inp, out_BOS, out_EOS, masking_PAD = data\n",
    "\n",
    "            decoder_outputs = model(inp, out_BOS)\n",
    "            \n",
    "            loss = criterion(\n",
    "                decoder_outputs[masking_PAD],\n",
    "                out_EOS[masking_PAD]\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "            decoder_outputs = decoder_outputs.argmax(-1)\n",
    "            total_metric += (decoder_outputs[masking_PAD].detach().cpu().numpy() == out_EOS[masking_PAD].detach().cpu().numpy()).mean()\n",
    "            \n",
    "    return total_loss / len(dataloader), total_metric / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eeb7e71e-f1be-40d1-98c7-97f8ecb20126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Epoch №1\n",
      "train metric: 0.31815553375239686\n",
      "train loss: 4.6006\n",
      "EVAL: loss=3.68 metric=0.42\n",
      "4m 36s (- 64m 37s) (1 6%)\n",
      "========================================\n",
      "Epoch №2\n",
      "train metric: 0.46105215737693456\n",
      "train loss: 3.3287\n",
      "EVAL: loss=3.11 metric=0.49\n",
      "9m 15s (- 60m 12s) (2 13%)\n",
      "========================================\n",
      "Epoch №3\n",
      "train metric: 0.5112873696577879\n",
      "train loss: 2.8995\n",
      "EVAL: loss=2.81 metric=0.53\n",
      "13m 54s (- 55m 38s) (3 20%)\n",
      "========================================\n",
      "Epoch №4\n",
      "train metric: 0.544405265169458\n",
      "train loss: 2.6245\n",
      "EVAL: loss=2.61 metric=0.55\n",
      "18m 32s (- 51m 0s) (4 26%)\n",
      "========================================\n",
      "Epoch №5\n",
      "train metric: 0.5687198533038775\n",
      "train loss: 2.4230\n",
      "EVAL: loss=2.47 metric=0.57\n",
      "23m 10s (- 46m 21s) (5 33%)\n",
      "========================================\n",
      "Epoch №6\n",
      "train metric: 0.5885566914214224\n",
      "train loss: 2.2598\n",
      "EVAL: loss=2.35 metric=0.59\n",
      "27m 49s (- 41m 44s) (6 40%)\n",
      "========================================\n",
      "Epoch №7\n",
      "train metric: 0.6062058442929023\n",
      "train loss: 2.1222\n",
      "EVAL: loss=2.26 metric=0.60\n",
      "32m 29s (- 37m 7s) (7 46%)\n",
      "========================================\n",
      "Epoch №8\n",
      "train metric: 0.6208819004841066\n",
      "train loss: 2.0059\n",
      "EVAL: loss=2.19 metric=0.61\n",
      "37m 8s (- 32m 29s) (8 53%)\n",
      "========================================\n",
      "Epoch №9\n",
      "train metric: 0.6337794455863776\n",
      "train loss: 1.9060\n",
      "EVAL: loss=2.14 metric=0.62\n",
      "41m 47s (- 27m 51s) (9 60%)\n",
      "========================================\n",
      "Epoch №10\n",
      "train metric: 0.6451458747597687\n",
      "train loss: 1.8177\n",
      "EVAL: loss=2.09 metric=0.63\n",
      "46m 26s (- 23m 13s) (10 66%)\n",
      "========================================\n",
      "Epoch №11\n",
      "train metric: 0.6556285705940047\n",
      "train loss: 1.7401\n",
      "EVAL: loss=2.06 metric=0.63\n",
      "51m 6s (- 18m 34s) (11 73%)\n",
      "========================================\n",
      "Epoch №12\n",
      "train metric: 0.6649927480872098\n",
      "train loss: 1.6699\n",
      "EVAL: loss=2.03 metric=0.64\n",
      "55m 44s (- 13m 56s) (12 80%)\n",
      "========================================\n",
      "Epoch №13\n",
      "train metric: 0.6741861236258254\n",
      "train loss: 1.6068\n",
      "EVAL: loss=2.01 metric=0.64\n",
      "60m 23s (- 9m 17s) (13 86%)\n",
      "========================================\n",
      "Epoch №14\n",
      "train metric: 0.6821063311481753\n",
      "train loss: 1.5503\n",
      "EVAL: loss=2.00 metric=0.64\n",
      "65m 2s (- 4m 38s) (14 93%)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m train(data, model_LSTM, \u001b[38;5;241m15\u001b[39m, eval_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, print_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, plot_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, end_teacher_forcing\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mstate_dict(), os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(MODEL_PATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseq2seq_lstm\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "train(data, model_LSTM, 15, eval_every=1, print_every=1, plot_every=1, end_teacher_forcing=40)\n",
    "torch.save(model_LSTM.state_dict(), os.path.join(MODEL_PATH, 'seq2seq_lstm'+'.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fe08027-40c0-47aa-bd38-cf24183456bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_LSTM.state_dict(), os.path.join(MODEL_PATH, 'seq2seq_lstm'+'.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0702a8fd-49bf-41f7-8e52-f74afc9ae344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Epoch №1\n",
      "train metric: 0.34192803198240984\n",
      "train loss: 4.3222\n",
      "EVAL: loss=3.47 metric=0.44\n",
      "4m 22s (- 61m 10s) (1 6%)\n",
      "========================================\n",
      "Epoch №2\n",
      "train metric: 0.4783177171394871\n",
      "train loss: 3.1296\n",
      "EVAL: loss=2.94 metric=0.50\n",
      "8m 44s (- 56m 52s) (2 13%)\n",
      "========================================\n",
      "Epoch №3\n",
      "train metric: 0.5235030630867337\n",
      "train loss: 2.7263\n",
      "EVAL: loss=2.67 metric=0.54\n",
      "13m 9s (- 52m 38s) (3 20%)\n",
      "========================================\n",
      "Epoch №4\n",
      "train metric: 0.554183713794994\n",
      "train loss: 2.4648\n",
      "EVAL: loss=2.49 metric=0.56\n",
      "17m 33s (- 48m 16s) (4 26%)\n",
      "========================================\n",
      "Epoch №5\n",
      "train metric: 0.5783230354238562\n",
      "train loss: 2.2647\n",
      "EVAL: loss=2.36 metric=0.58\n",
      "21m 58s (- 43m 57s) (5 33%)\n",
      "========================================\n",
      "Epoch №6\n",
      "train metric: 0.5988351642808118\n",
      "train loss: 2.1036\n",
      "EVAL: loss=2.26 metric=0.59\n",
      "26m 22s (- 39m 33s) (6 40%)\n",
      "========================================\n",
      "Epoch №7\n",
      "train metric: 0.6154914026489132\n",
      "train loss: 1.9718\n",
      "EVAL: loss=2.18 metric=0.60\n",
      "30m 46s (- 35m 9s) (7 46%)\n",
      "========================================\n",
      "Epoch №8\n",
      "train metric: 0.6300569751764089\n",
      "train loss: 1.8621\n",
      "EVAL: loss=2.12 metric=0.62\n",
      "35m 9s (- 30m 45s) (8 53%)\n",
      "========================================\n",
      "Epoch №9\n",
      "train metric: 0.6426896637407329\n",
      "train loss: 1.7682\n",
      "EVAL: loss=2.08 metric=0.62\n",
      "39m 33s (- 26m 22s) (9 60%)\n",
      "========================================\n",
      "Epoch №10\n",
      "train metric: 0.6544270355661121\n",
      "train loss: 1.6877\n",
      "EVAL: loss=2.04 metric=0.63\n",
      "43m 57s (- 21m 58s) (10 66%)\n",
      "========================================\n",
      "Epoch №11\n",
      "train metric: 0.6648316523780646\n",
      "train loss: 1.6184\n",
      "EVAL: loss=2.02 metric=0.63\n",
      "48m 25s (- 17m 36s) (11 73%)\n",
      "========================================\n",
      "Epoch №12\n",
      "train metric: 0.6738312195228273\n",
      "train loss: 1.5582\n",
      "EVAL: loss=1.99 metric=0.64\n",
      "52m 51s (- 13m 12s) (12 80%)\n",
      "========================================\n",
      "Epoch №13\n",
      "train metric: 0.6821466131985985\n",
      "train loss: 1.5052\n",
      "EVAL: loss=1.98 metric=0.64\n",
      "57m 21s (- 8m 49s) (13 86%)\n",
      "========================================\n",
      "Epoch №14\n",
      "train metric: 0.6896028231635856\n",
      "train loss: 1.4588\n",
      "EVAL: loss=1.97 metric=0.64\n",
      "61m 45s (- 4m 24s) (14 93%)\n",
      "CPU times: user 1h 1min 42s, sys: 1.04 s, total: 1h 1min 43s\n",
      "Wall time: 1h 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train(data, model_GRU, 15, eval_every=1, print_every=1, plot_every=1, end_teacher_forcing=40)\n",
    "torch.save(model_GRU.state_dict(), os.path.join(MODEL_PATH, 'seq2seq_gru'+'.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4aa86da6-47c5-4dcb-998f-f8b10610979a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Epoch №1\n",
      "train metric: 0.4344214179310611\n",
      "train loss: 3.6097\n",
      "EVAL: loss=2.53 metric=0.57\n",
      "5m 22s (- 75m 12s) (1 6%)\n",
      "========================================\n",
      "Epoch №2\n",
      "train metric: 0.6207565415272478\n",
      "train loss: 2.1531\n",
      "EVAL: loss=2.01 metric=0.64\n",
      "10m 41s (- 69m 29s) (2 13%)\n",
      "========================================\n",
      "Epoch №3\n",
      "train metric: 0.6679992613289815\n",
      "train loss: 1.7594\n",
      "EVAL: loss=1.82 metric=0.67\n",
      "16m 11s (- 64m 45s) (3 20%)\n",
      "========================================\n",
      "Epoch №4\n",
      "train metric: 0.6933632075197977\n",
      "train loss: 1.5480\n",
      "EVAL: loss=1.74 metric=0.68\n",
      "21m 38s (- 59m 31s) (4 26%)\n",
      "========================================\n",
      "Epoch №5\n",
      "train metric: 0.7125153313572637\n",
      "train loss: 1.4023\n",
      "EVAL: loss=1.68 metric=0.69\n",
      "27m 5s (- 54m 10s) (5 33%)\n",
      "========================================\n",
      "Epoch №6\n",
      "train metric: 0.7275605118902942\n",
      "train loss: 1.2936\n",
      "EVAL: loss=1.66 metric=0.70\n",
      "32m 34s (- 48m 51s) (6 40%)\n",
      "========================================\n",
      "Epoch №7\n",
      "train metric: 0.7398033625306856\n",
      "train loss: 1.2079\n",
      "EVAL: loss=1.64 metric=0.70\n",
      "37m 59s (- 43m 24s) (7 46%)\n",
      "========================================\n",
      "Epoch №8\n",
      "train metric: 0.7502867311865447\n",
      "train loss: 1.1378\n",
      "EVAL: loss=1.64 metric=0.71\n",
      "43m 26s (- 38m 0s) (8 53%)\n",
      "========================================\n",
      "Epoch №9\n",
      "train metric: 0.759308961532796\n",
      "train loss: 1.0786\n",
      "EVAL: loss=1.63 metric=0.71\n",
      "48m 49s (- 32m 33s) (9 60%)\n",
      "========================================\n",
      "Epoch №10\n",
      "train metric: 0.7673612546255861\n",
      "train loss: 1.0276\n",
      "EVAL: loss=1.63 metric=0.71\n",
      "54m 11s (- 27m 5s) (10 66%)\n",
      "========================================\n",
      "Epoch №11\n",
      "train metric: 0.7746634049974398\n",
      "train loss: 0.9822\n",
      "EVAL: loss=1.64 metric=0.71\n",
      "59m 31s (- 21m 38s) (11 73%)\n",
      "========================================\n",
      "Epoch №12\n",
      "train metric: 0.7813321657826126\n",
      "train loss: 0.9422\n",
      "EVAL: loss=1.65 metric=0.71\n",
      "64m 55s (- 16m 13s) (12 80%)\n",
      "========================================\n",
      "Epoch №13\n",
      "train metric: 0.7870936083612988\n",
      "train loss: 0.9072\n",
      "EVAL: loss=1.66 metric=0.71\n",
      "70m 20s (- 10m 49s) (13 86%)\n",
      "========================================\n",
      "Epoch №14\n",
      "train metric: 0.7929323377065384\n",
      "train loss: 0.8748\n",
      "EVAL: loss=1.68 metric=0.71\n",
      "75m 43s (- 5m 24s) (14 93%)\n",
      "CPU times: user 1h 15min 29s, sys: 6.67 s, total: 1h 15min 36s\n",
      "Wall time: 1h 15min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train(data, model_attn_forwdir, 15, eval_every=1, print_every=1, plot_every=1, end_teacher_forcing=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9cbe2421-225a-4a67-bb52-834f4d82bfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_attn_forwdir.state_dict(), os.path.join(MODEL_PATH, 'seq2seq_attn'+'.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c96e4a0-7c9c-4d1c-97f6-a8d3846b4fde",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7f3475-22b9-47b4-824c-7ebc758b75a2",
   "metadata": {},
   "source": [
    "Make a function for text translation. Translate some text and evaluate model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602f831b-9ddd-4070-ba8f-b7b16bc26463",
   "metadata": {},
   "source": [
    "Take note that your model is set for training. During the inference process you will have to use parts of the model independently (including the RNN cells)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a32f4dc-3c53-426d-bf67-35b1efe2bbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def translate(\n",
    "#     text: str,\n",
    "#     tokenizer: Tokenizer,\n",
    "#     model: keras.Model,\n",
    "#     max_len: int = 20\n",
    "# ) -> str:\n",
    "#     '''Predicts `text`translation using the `model`.\n",
    "\n",
    "#     Arguments:\n",
    "#         text: text to be translated\n",
    "#         tokenizer: tokenizer to use\n",
    "#         model: model ot use\n",
    "#         max_len: maximum length of the prediction (in tokens)\n",
    "\n",
    "#     Returns:\n",
    "#         tranlated text'''\n",
    "#     ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70351aa0-0f99-4e9d-8646-8be33cc116eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def translate(\n",
    "    text: str,\n",
    "    tokenizer,\n",
    "    model: nn.Module,\n",
    "    max_len: int = 20,\n",
    "    attention: bool = False\n",
    ") -> str:\n",
    "    '''Predicts `text` translation using the `model`.\n",
    "\n",
    "    Arguments:\n",
    "        text: text to be translated\n",
    "        tokenizer: tokenizer to use\n",
    "        model: model to use\n",
    "        max_len: maximum length of the prediction (in tokens)\n",
    "\n",
    "    Returns:\n",
    "        translated text'''\n",
    "\n",
    "    input_ids = tokenizer(text, return_tensors=\"pt\")['input_ids'].to('cuda')\n",
    "    encoder_outputs, encoder_hidden = model.encoder(input_ids)\n",
    "\n",
    "    decoder_input = torch.tensor([[tokenizer.bos_token_id]]).to('cuda')\n",
    "    decoder_hidden = encoder_hidden\n",
    "    generated_tokens = []\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        embedded = model.decoder.embedding(decoder_input)\n",
    "        decoder_output, decoder_hidden = model.decoder.rnn(embedded, decoder_hidden)\n",
    "        if attention:\n",
    "            out, _ = model.decoder.attention(decoder_output, encoder_outputs, encoder_outputs)\n",
    "            output = torch.cat((decoder_output, out), dim=-1)\n",
    "            output_token_logits = model.decoder.out(output[:, -1, :])\n",
    "        else:\n",
    "            output_token_logits = model.decoder.out(decoder_output[:, -1, :])\n",
    "        output_token = torch.argmax(output_token_logits, dim=-1)\n",
    "        generated_tokens.append(output_token.item())\n",
    "\n",
    "        if output_token.item() == tokenizer.eos_token_id:\n",
    "           break\n",
    "        decoder_input = output_token.unsqueeze(0)\n",
    "    translated_text = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "    return translated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6eaa6df-dcc8-4927-9cb5-6cc1bd24dc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good morning.\n",
      "I'm coming down!\n",
      "What a lovely day, the one is on the floor.\n",
      "The cat is sitting on the table.\n",
      "I like pizza.\n",
      "The princess was sick.\n",
      "The village and the United States is called the capital of the capital of Japan.\n"
     ]
    }
   ],
   "source": [
    "#без атентиона\n",
    "corpus = ['Доброе утро.',\n",
    "          'Привет мир!', \n",
    "          'Какой чудесный день!',\n",
    "          'Кот сидит на столе.',\n",
    "          'Я люблю пиццу.', \n",
    "          'Принцесса была больна.',\n",
    "          'ВЫфрои3424 ЫВФ Афыва']\n",
    "\n",
    "for document in corpus:\n",
    "    print(translate(document, tokenizer, model_LSTM, max_len=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5ea981f-47bc-4f29-b3e5-bc0481f43778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good morning.\n",
      "The peace is a good idea.\n",
      "What a day!\n",
      "The cat is sitting on the table.\n",
      "I like pizza.\n",
      "The princess was ill.\n",
      "The war is located in the United States.\n"
     ]
    }
   ],
   "source": [
    "#без атентиона\n",
    "corpus = ['Доброе утро.',\n",
    "          'Привет мир!', \n",
    "          'Какой чудесный день!',\n",
    "          'Кот сидит на столе.',\n",
    "          'Я люблю пиццу.', \n",
    "          'Принцесса была больна.',\n",
    "          'ВЫфрои3424 ЫВФ Афыва']\n",
    "\n",
    "for document in corpus:\n",
    "    print(translate(document, tokenizer, model_GRU, max_len=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3bf85e85-9ec7-43fb-9528-b3af554dd4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good morning.\n",
      "Break the world!\n",
      "What a wonderful day!\n",
      "The cat is sitting on the table.\n",
      "I like pizza.\n",
      "The princess was sick.\n",
      "The United Nations of the United States is written by the United States.\n"
     ]
    }
   ],
   "source": [
    "#атентиона\n",
    "corpus = ['Доброе утро.',\n",
    "          'Привет мир!', \n",
    "          'Какой чудесный день!',\n",
    "          'Кот сидит на столе.',\n",
    "          'Я люблю пиццу.', \n",
    "          'Принцесса была больна.',\n",
    "          'ВЫфрои3424 ЫВФ Афыва']\n",
    "\n",
    "for document in corpus:\n",
    "    print(translate(document, tokenizer, model_attn_forwdir, max_len=30, attention=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
