{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2dbe8ed-bc36-4ce8-9fd1-22866ca3ad2e",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "* надо придумать как батчи пихнуть (var_text)\n",
    "* \"pack\" the sequences in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4b7aaf-d09b-4b64-91e6-dee2976ce379",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "16f89b44-fede-422c-b525-9a267aad4d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import keras\n",
    "import datasets\n",
    "import numpy as np\n",
    "import transformers\n",
    "import sklearn.metrics\n",
    "#import tensorflow as tf\n",
    "import tqdm.notebook as tqdm\n",
    "import sklearn.model_selection\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "bc4e64b0-7eef-4af2-9906-44c8cdb86c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pytorch\n",
    "import torch\n",
    "#from torchsummary import summary\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "d400cd26-730e-4c4e-aaed-5987f78ef5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfb9f8d-1cf5-4954-8b70-18d47dee46e3",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8cc56a-5c94-4134-902d-e74edf1414aa",
   "metadata": {},
   "source": [
    "Load the dataset (we will be using [go_emotions](https://huggingface.co/datasets/google-research-datasets/go_emotions)). Pretokenize data or make a loader that tokenizes the sentenses as you iterate through the dataset. Implement two datasets: variable and fixed sentence length (in tokens). Don't forget to split the dataset into train and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "fea15226-0e61-4fcd-a188-d6330e545465",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset('google-research-datasets/go_emotions', name='raw', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "b144fe06-9838-4812-9e19-9b74e903bba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = [\n",
    "    'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity',\n",
    "    'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear',\n",
    "    'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief',\n",
    "    'remorse', 'sadness', 'surprise', 'neutral'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "682d6798-62fe-4d5c-8b8b-99394df534ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bob1ch/Рабочий стол/NN-NLP/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50256"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "ddcc3ba9-fb2c-40b2-af4b-db4595895756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This person is the smartest person to play town of salem literally 999999999999999999999999999999999999999999999999999999999999999999999999999999999999999991000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001234567898765432345676543345678987654345678909876543234567898765432345678909876543234567898765432345678987654323456787654345676543456543456434543434343434323456765434567654323454323456543345678987654323456789876565656565656565656565656565454545654565454323456765432345678765456 IQ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1212,  1048,   318,   262, 44730,  1048,   284,   711,  3240,   286,\n",
       "          3664,   368,  7360,   860, 24214, 24214, 24214, 24214, 24214, 24214,\n",
       "         24214, 24214, 24214, 24214, 24214, 24214, 24214, 24214, 24214, 24214,\n",
       "         24214, 24214, 24214, 24214, 24214, 24214,    16, 25645, 25645, 25645,\n",
       "         25645, 25645, 25645, 25645, 25645, 25645, 25645, 25645, 25645, 25645,\n",
       "         25645, 25645, 25645,  8269,   405, 10163,  2231, 30924,  4089, 29143,\n",
       "          3559,  1954,  2231,  3134, 39111,  2091,  2231, 30924,  4089, 29143,\n",
       "          3559,  2231,  3134,  4531,  2931,  5774,  2996,  3559,  1954,  2231,\n",
       "         30924,  4089, 29143,  3559,  1954,  2231,  3134,  4531,  2931,  5774,\n",
       "          2996,  3559,  1954,  2231, 30924,  4089, 29143,  3559,  1954,  2231,\n",
       "         30924,  4089, 29143,  3559,  1954,  2231,  3134,  5774,  2996,  3559,\n",
       "          2231,  3134,  2996,  3559,  2231,  2996,  3559,  2231,  2414, 27712,\n",
       "         47101,  2682,  2682,  2682, 32118,  1954,  2231,  3134,  2996,  3559,\n",
       "          2231,  3134,  2996,  3559,  1954,  2231,  3559,  1954,  2231, 39111,\n",
       "          2091,  2231, 30924,  4089, 29143,  3559,  1954,  2231, 30924,  4089,\n",
       "         29143,  2996,  2996,  2996,  2996,  2996,  2996,  2996,  2996,  2996,\n",
       "          2996,  2996,  2996,  2996,  2231,  2231,  2231,  2996,  2231,  2996,\n",
       "          2231,  3559,  1954,  2231,  3134,  2996,  3559,  1954,  2231,  3134,\n",
       "          5774,  2996, 29228, 18248, 50256]])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longets_text = dataset['text'][np.argmax(list(map(len, dataset['text'])))]\n",
    "print(longets_text)\n",
    "tokenizer(longets_text, return_tensors='pt', padding='max_length', max_length=185, truncation=True)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "02778ee6-1ff7-4fc9-be85-67c3b4895b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1435 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "text_fixed = tokenizer(dataset['text'], return_tensors='pt', padding='max_length', max_length=128, truncation=True)['input_ids']\n",
    "variable_text = tokenizer(dataset['text'])['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "99359e1c-dbf9-4d56-858e-18c7291b5efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = list()\n",
    "for c in emotions:\n",
    "    y.append(dataset[c])\n",
    "y = np.array(y).T\n",
    "y[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "6533700d-ac9f-4753-a8b6-4a542116f222",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fixed, X_test_fixed, y_train, y_test = sklearn.model_selection.train_test_split(text_fixed, y, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "68c0ff65-27ec-4985-b73d-a072584874ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147857"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "0462e916-4b28-4e73-bfb6-3781c1f553ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_var, X_test_var, y_train, y_test = sklearn.model_selection.train_test_split(variable_text, y, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "bd4868c1-cc9a-4828-8e52-b552d8159eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147857"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b628be8-1f04-4212-9392-dee3e207f532",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066591d4-60c1-4918-85e7-fafe734d1804",
   "metadata": {},
   "source": [
    "Implement your model. The model should have the RNN architecture (with LSTM or GRU cells), support stacking and bidirectional feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "e54e3784-2f24-42a2-a8a0-164378480a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(prefix: str | None = None, suffix: str | None = None, separator: str = '_') -> str | None:\n",
    "    return prefix and prefix + separator + suffix or suffix or None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "90a144e0-b2f7-41a9-8f4f-4a84f40d6077",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, units: int, n_tokens: int, n_labels: int, n_stacks: int, bidirectional: bool, name: str, cell_type):\n",
    "        super(Model, self).__init__()\n",
    "        self.name = name\n",
    "        self.units = units\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        #torch.nn.GRU(input_size, hidden_size, num_layers=1, bias=True, batch_first=False, dropout=0.0, bidirectional=False, device=None, dtype=None)\n",
    "        #torch.nn.LSTM(input_size, hidden_size, num_layers=1, bias=True, batch_first=False, dropout=0.0, bidirectional=False, proj_size=0, device=None, dtype=None)\n",
    "        \n",
    "        self.embeddings = torch.nn.Embedding(n_tokens, units)\n",
    "        self.rnn = cell_type(units, units, num_layers=n_stacks, bidirectional=bidirectional)\n",
    "        self.FC = torch.nn.Linear(units*2 if bidirectional else units, n_labels)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embeds = self.embeddings(text)\n",
    "        \n",
    "        # костыль, если у меня без батчей (var_text)\n",
    "        # надо придумать как сюда батчки пихнуть (var_text)\n",
    "        embeds = embeds.permute(1, 0, 2) if len(embeds.shape) == 3 else embeds\n",
    "        out, _ = self.rnn(embeds)\n",
    "        out = out[-1]\n",
    "\n",
    "        out = self.FC(out)\n",
    "        return out\n",
    "\n",
    "def get_model(\n",
    "    units: int,\n",
    "    n_tokens: int,\n",
    "    n_labels: int,\n",
    "    n_stacks: int = 1,\n",
    "    bidirectional: bool = False,\n",
    "    name: str | None = None,\n",
    "    cell_type: type[torch.nn.modules] = torch.nn.LSTM\n",
    ") -> torch.nn.Module:\n",
    "    '''Creates a model with RNN architecture for sequence multilabel classification.\n",
    "\n",
    "    Arguments:\n",
    "        units: dimensionality of RNN cells OR units: Positive integer, dimensionality of the output space\n",
    "        n_tokens: number of tokens in the tokenizer dictionary\n",
    "        n_labels: number of labels to be predicted\n",
    "        n_stacks: number of RNN cells in the stack (1 -- no stacking)\n",
    "        bidirectional: whether or not the model is bidirectional\n",
    "        name: the model name\n",
    "        cell_type: type of a cell to use, either keras.layers.LSTMCell or keras.layers.GRUCell\n",
    "\n",
    "    Returns:\n",
    "        The model'''\n",
    "    return Model(units, n_tokens, n_labels, n_stacks, bidirectional, name, cell_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "c8f8b8ea-b172-462b-88b5-3d8637b6a869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Model(torch.nn.Module):\n",
    "\n",
    "#     def __init__(self, units: int, embed_dim: int, n_tokens: int, n_labels: int, n_stacks: int, bidirectional: bool, name: str, cell_type):\n",
    "#         super(Model, self).__init__()\n",
    "#         self.name = name\n",
    "#         self.units = units\n",
    "#         self.bidirectional = bidirectional\n",
    "        \n",
    "#         #torch.nn.GRU(input_size, hidden_size, num_layers=1, bias=True, batch_first=False, dropout=0.0, bidirectional=False, device=None, dtype=None)\n",
    "#         #torch.nn.LSTM(input_size, hidden_size, num_layers=1, bias=True, batch_first=False, dropout=0.0, bidirectional=False, proj_size=0, device=None, dtype=None)\n",
    "        \n",
    "#         self.embeddings = torch.nn.Embedding(n_tokens, embed_dim)\n",
    "#         #torch.nn.LSTMCell(input_size, hidden_size, bias=True, device=None, dtype=None)\n",
    "#         self.rnn = cell_type(embed_dim, units, num_layers=n_stacks, bidirectional=bidirectional)\n",
    "#         self.FC = torch.nn.Linear(units*2 if bidirectional else units, n_labels)\n",
    "\n",
    "#     def forward(self, text):\n",
    "#         embeds = self.embeddings(text)\n",
    "#         embeds = embeds.permute(1, 0, 2)\n",
    "#         out, _ = self.rnn(embeds)\n",
    "#         out = out[-1]\n",
    "\n",
    "#         # if self.bidirectional:\n",
    "#         #     return out.shape\n",
    "#         #     out = torch.cat((out[0], out[1]), dim=1)\n",
    "\n",
    "#         out = self.FC(out)\n",
    "#         return out\n",
    "\n",
    "# def get_model(\n",
    "#     units: int,\n",
    "#     n_tokens: int,\n",
    "#     n_labels: int,\n",
    "#     n_stacks: int = 1,\n",
    "#     bidirectional: bool = False,\n",
    "#     name: str | None = None,\n",
    "#     cell_type: type[torch.nn.modules] = torch.nn.LSTM\n",
    "# ) -> torch.nn.Module:\n",
    "#     '''Creates a model with RNN architecture for sequence multilabel classification.\n",
    "\n",
    "#     Arguments:\n",
    "#         units: dimensionality of RNN cells OR units: Positive integer, dimensionality of the output space\n",
    "#         n_tokens: number of tokens in the tokenizer dictionary\n",
    "#         n_labels: number of labels to be predicted\n",
    "#         n_stacks: number of RNN cells in the stack (1 -- no stacking)\n",
    "#         bidirectional: whether or not the model is bidirectional\n",
    "#         name: the model name\n",
    "#         cell_type: type of a cell to use, either keras.layers.LSTMCell or keras.layers.GRUCell\n",
    "\n",
    "#     Returns:\n",
    "#         The model'''\n",
    "#     return Model(units, n_tokens, n_labels, n_stacks, bidirectional, name, cell_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "f1d16ca7-0bcd-4213-a3cd-1b3d35662079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0421, -0.0816, -0.0031, -0.0961,  0.1208, -0.0603, -0.0267,  0.0934,\n",
       "         -0.0415, -0.0557, -0.0443,  0.0573, -0.0255, -0.0057,  0.0185, -0.0252,\n",
       "         -0.0311, -0.0089, -0.0755,  0.0568, -0.0703, -0.0257, -0.0613,  0.0885,\n",
       "         -0.0097, -0.0490, -0.0282, -0.0496],\n",
       "        [-0.0421, -0.0816, -0.0031, -0.0961,  0.1208, -0.0603, -0.0267,  0.0934,\n",
       "         -0.0415, -0.0557, -0.0443,  0.0573, -0.0255, -0.0057,  0.0185, -0.0252,\n",
       "         -0.0311, -0.0089, -0.0755,  0.0568, -0.0703, -0.0257, -0.0613,  0.0885,\n",
       "         -0.0097, -0.0490, -0.0282, -0.0496],\n",
       "        [-0.0421, -0.0816, -0.0031, -0.0961,  0.1208, -0.0603, -0.0267,  0.0934,\n",
       "         -0.0415, -0.0557, -0.0443,  0.0573, -0.0255, -0.0057,  0.0185, -0.0252,\n",
       "         -0.0311, -0.0089, -0.0755,  0.0568, -0.0703, -0.0257, -0.0613,  0.0885,\n",
       "         -0.0097, -0.0490, -0.0282, -0.0496]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(units=64, \n",
    "                  n_tokens=len(tokenizer.vocab), \n",
    "                  n_labels=len(emotions), \n",
    "                  n_stacks=100, \n",
    "                  bidirectional=True, \n",
    "                  name='LSTM', \n",
    "                  cell_type=torch.nn.LSTM)\n",
    "#model(torch.Tensor(variable_text[0]).to(int))\n",
    "model(text_fixed[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1790d12f-d3f9-477e-bbfc-067baadf33c6",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42397b6a-e849-4179-a359-647e902300f4",
   "metadata": {},
   "source": [
    "Train several models on the two dataset variants. Use either of the cell types (LSTM or GRU)\n",
    "* Simple RNN (no stacking, one direction)\n",
    "* Stacked RNN (stacking, one direction)\n",
    "* Bidirectional RNN (no stacking, bidirectional)\n",
    "* Stacked Bidirectional RNN (stacking, bidirectional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "d1382d9b-3da7-4a5d-a272-7ea53efc5e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#units, name, bidirectional, n_stacks, cell_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "07bf0549-2961-432a-a457-9d79bd22f848",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = ['Simple RNN', 'Stacked RNN', 'Bidirectional RNN', 'Stacked Bidirectional RNN']\n",
    "architecture = ['LSTM ', 'GRU ']\n",
    "all_names = [arch + config for arch in architecture for config in configs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "a71e161d-5e01-4d4e-8027-4a5a8838c542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LSTM Simple RNN', Model(\n",
      "  (rnn): LSTM(64, 64)\n",
      "  (embeddings): Embedding(50257, 64)\n",
      "  (FC): Linear(in_features=64, out_features=28, bias=True)\n",
      "))\n",
      "('LSTM Stacked RNN', Model(\n",
      "  (rnn): LSTM(64, 64, num_layers=3)\n",
      "  (embeddings): Embedding(50257, 64)\n",
      "  (FC): Linear(in_features=64, out_features=28, bias=True)\n",
      "))\n",
      "('LSTM Bidirectional RNN', Model(\n",
      "  (rnn): LSTM(64, 64, bidirectional=True)\n",
      "  (embeddings): Embedding(50257, 64)\n",
      "  (FC): Linear(in_features=128, out_features=28, bias=True)\n",
      "))\n",
      "('LSTM Stacked Bidirectional RNN', Model(\n",
      "  (rnn): LSTM(64, 64, num_layers=3, bidirectional=True)\n",
      "  (embeddings): Embedding(50257, 64)\n",
      "  (FC): Linear(in_features=128, out_features=28, bias=True)\n",
      "))\n",
      "('GRU Simple RNN', Model(\n",
      "  (rnn): GRU(64, 64)\n",
      "  (embeddings): Embedding(50257, 64)\n",
      "  (FC): Linear(in_features=64, out_features=28, bias=True)\n",
      "))\n",
      "('GRU Stacked RNN', Model(\n",
      "  (rnn): GRU(64, 64, num_layers=3)\n",
      "  (embeddings): Embedding(50257, 64)\n",
      "  (FC): Linear(in_features=64, out_features=28, bias=True)\n",
      "))\n",
      "('GRU Bidirectional RNN', Model(\n",
      "  (rnn): GRU(64, 64, bidirectional=True)\n",
      "  (embeddings): Embedding(50257, 64)\n",
      "  (FC): Linear(in_features=128, out_features=28, bias=True)\n",
      "))\n",
      "('GRU Stacked Bidirectional RNN', Model(\n",
      "  (rnn): GRU(64, 64, num_layers=3, bidirectional=True)\n",
      "  (embeddings): Embedding(50257, 64)\n",
      "  (FC): Linear(in_features=128, out_features=28, bias=True)\n",
      "))\n"
     ]
    }
   ],
   "source": [
    "super_zip = zip([64] * 8,                                  #units\n",
    "                all_names,                                 #name\n",
    "                ([False] * 2 + [True] * 2) * 2,            #bidirectional\n",
    "                [1, 3] * 4,                                #n_stacks\n",
    "                [torch.nn.LSTM] * 4 + [torch.nn.GRU] * 4,) #cell_type\n",
    "\n",
    "models = [\n",
    "    get_model(\n",
    "        units=units,\n",
    "        n_tokens=len(tokenizer.get_vocab()),\n",
    "        n_labels=len(emotions),\n",
    "        name=name,\n",
    "        bidirectional=bidirectional,\n",
    "        n_stacks=n_stacks,\n",
    "        cell_type=cell_type\n",
    "    )\n",
    "    for units, name, bidirectional, n_stacks, cell_type in super_zip\n",
    "]\n",
    "print(*[(model.name, model) for model in models], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92142b18-0255-416d-812b-b2cce689196a",
   "metadata": {},
   "source": [
    "Which loss should be used to multilabel classification? Which metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "be315f1d-1b09-4a6e-a301-c2e9ac0d3bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "# about hamming score https://wiki.cloudfactory.com/docs/mp-wiki/metrics/hamming-score\n",
    "# about metrics 4 multilabel https://mmuratarat.github.io/2020-01-25/multilabel_classification_metrics\n",
    "def Hamming_score(y_true, y_pred):\n",
    "    temp = 0\n",
    "    for i in range(y_true.shape[0]):\n",
    "        temp += sum(np.logical_and(y_true[i], y_pred[i])) / sum(np.logical_or(y_true[i], y_pred[i]))\n",
    "    return temp / y_true.shape[0]\n",
    "test_true = np.array([[0, 1, 1], \n",
    "                      [0, 1, 1]])\n",
    "\n",
    "print(Hamming_score(test_true, np.array([[0, 1, 0], \n",
    "                                         [0, 1, 0]])), \n",
    "      Hamming_score(test_true, np.array([[1, 0, 0], \n",
    "                                         [1, 0, 0]])), \n",
    "      Hamming_score(test_true, np.array([[0, 1, 1], \n",
    "                                         [0, 1, 1]])))\n",
    "\n",
    "# пример для 1 объекта\n",
    "# hamping = 0\n",
    "# y_true, y_pred = np.array([0, 1, 1]), np.array([0, 1, 1])\n",
    "# hamping = sum(np.logical_and(y_true, y_pred)) / sum(np.logical_or(y_true, y_pred))\n",
    "# hamping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "bdfa195e-cb43-4c4a-9f6e-b31b5bd1676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Dataset_multilabel(Dataset):\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        super().__init__()\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "        \n",
    "training_data = Dataset_multilabel(X_train_fixed, y_train)\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "b6245c79-6372-4c78-a3fd-037424f6236f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 5703, 11040,    11,  1521,   466,   345,   892,   326,    30,   679,\n",
       "           468,  5299,  4019,     4,  7546,  1871,  6823,   685, 20608,    60,\n",
       "           220, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0]))"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_fixed[0], y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "5e4b5bb2-0ef2-4ee5-bd84-5b5f63eb235a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2311"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "c416bf78-a954-4837-968c-0ff4365d3fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, optimizer, epochs, metric, X, y, batch_size):\n",
    "    training_data = Dataset_multilabel(X, y)\n",
    "    train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True) #все это можно за ф-ию вынести\n",
    "    \n",
    "    size = len(training_data)\n",
    "    model.to('cuda')\n",
    "    model.train()\n",
    "\n",
    "    percent_of_batch = len(training_data) // batch_size / 2\n",
    "    for i in range(epochs):\n",
    "        y_true_metric = list() #4metric\n",
    "        y_pred_metric = list() #4metric\n",
    "        \n",
    "        for batch, (X, y) in enumerate(train_dataloader):\n",
    "            y_true_metric.extend(y.tolist())\n",
    "            X, y = X.to('cuda'), y.to('cuda')\n",
    "            y_pred = model(X)\n",
    "            y_pred_metric.extend(y_pred.tolist())\n",
    "            loss = loss_fn(y_pred, y.float())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if batch % percent_of_batch == 0:\n",
    "                loss = loss.item()\n",
    "                print(f\"{model.name} loss: {loss:>7f}\")\n",
    "\n",
    "        print(f'Epoch_{i+1} Metric {model.name}: {metric(np.array(y_true_metric), np.array(y_pred_metric))*100:.2f}%')\n",
    "    print('-'*35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "25b2824c-1fa5-42a1-bfa8-c17f861ca49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "####optimizer = torch.optim.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "43a20237-67d0-48a6-a1d9-3efd6a571fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-----------------------------------'"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'-'*35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "d1652d9f-816d-4b36-9bf7-21d38e764e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Simple RNN loss: 0.729661\n",
      "LSTM Simple RNN loss: 0.159827\n",
      "Epoch_1 Metric LSTM Simple RNN: 4.22%\n",
      "LSTM Simple RNN loss: 0.164048\n",
      "LSTM Simple RNN loss: 0.165060\n",
      "Epoch_2 Metric LSTM Simple RNN: 4.22%\n",
      "LSTM Simple RNN loss: 0.156408\n",
      "LSTM Simple RNN loss: 0.143526\n",
      "Epoch_3 Metric LSTM Simple RNN: 4.22%\n",
      "LSTM Stacked RNN loss: 0.699150\n",
      "LSTM Stacked RNN loss: 0.160121\n",
      "Epoch_1 Metric LSTM Stacked RNN: 4.22%\n",
      "LSTM Stacked RNN loss: 0.154612\n",
      "LSTM Stacked RNN loss: 0.143986\n",
      "Epoch_2 Metric LSTM Stacked RNN: 4.22%\n",
      "LSTM Stacked RNN loss: 0.163255\n",
      "LSTM Stacked RNN loss: 0.161501\n",
      "Epoch_3 Metric LSTM Stacked RNN: 4.22%\n",
      "LSTM Bidirectional RNN loss: 0.681607\n",
      "LSTM Bidirectional RNN loss: 0.150659\n",
      "Epoch_1 Metric LSTM Bidirectional RNN: 4.22%\n",
      "LSTM Bidirectional RNN loss: 0.165413\n",
      "LSTM Bidirectional RNN loss: 0.169739\n",
      "Epoch_2 Metric LSTM Bidirectional RNN: 4.22%\n",
      "LSTM Bidirectional RNN loss: 0.162119\n",
      "LSTM Bidirectional RNN loss: 0.163023\n",
      "Epoch_3 Metric LSTM Bidirectional RNN: 4.22%\n",
      "LSTM Stacked Bidirectional RNN loss: 0.683213\n",
      "LSTM Stacked Bidirectional RNN loss: 0.155657\n",
      "Epoch_1 Metric LSTM Stacked Bidirectional RNN: 4.22%\n",
      "LSTM Stacked Bidirectional RNN loss: 0.163245\n",
      "LSTM Stacked Bidirectional RNN loss: 0.145413\n",
      "Epoch_2 Metric LSTM Stacked Bidirectional RNN: 4.22%\n",
      "LSTM Stacked Bidirectional RNN loss: 0.164950\n",
      "LSTM Stacked Bidirectional RNN loss: 0.156591\n",
      "Epoch_3 Metric LSTM Stacked Bidirectional RNN: 4.22%\n",
      "GRU Simple RNN loss: 0.719186\n",
      "GRU Simple RNN loss: 0.151595\n",
      "Epoch_1 Metric GRU Simple RNN: 4.22%\n",
      "GRU Simple RNN loss: 0.151946\n",
      "GRU Simple RNN loss: 0.144060\n",
      "Epoch_2 Metric GRU Simple RNN: 4.22%\n",
      "GRU Simple RNN loss: 0.155037\n",
      "GRU Simple RNN loss: 0.156897\n",
      "Epoch_3 Metric GRU Simple RNN: 4.22%\n",
      "GRU Stacked RNN loss: 0.710192\n",
      "GRU Stacked RNN loss: 0.166495\n",
      "Epoch_1 Metric GRU Stacked RNN: 4.22%\n",
      "GRU Stacked RNN loss: 0.161349\n",
      "GRU Stacked RNN loss: 0.155015\n",
      "Epoch_2 Metric GRU Stacked RNN: 4.22%\n",
      "GRU Stacked RNN loss: 0.154755\n",
      "GRU Stacked RNN loss: 0.155137\n",
      "Epoch_3 Metric GRU Stacked RNN: 4.22%\n",
      "GRU Bidirectional RNN loss: 0.693791\n",
      "GRU Bidirectional RNN loss: 0.168368\n",
      "Epoch_1 Metric GRU Bidirectional RNN: 4.22%\n",
      "GRU Bidirectional RNN loss: 0.155262\n",
      "GRU Bidirectional RNN loss: 0.157065\n",
      "Epoch_2 Metric GRU Bidirectional RNN: 4.22%\n",
      "GRU Bidirectional RNN loss: 0.159679\n",
      "GRU Bidirectional RNN loss: 0.159299\n",
      "Epoch_3 Metric GRU Bidirectional RNN: 4.22%\n",
      "GRU Stacked Bidirectional RNN loss: 0.694335\n",
      "GRU Stacked Bidirectional RNN loss: 0.153240\n",
      "Epoch_1 Metric GRU Stacked Bidirectional RNN: 4.22%\n",
      "GRU Stacked Bidirectional RNN loss: 0.161692\n",
      "GRU Stacked Bidirectional RNN loss: 0.141884\n",
      "Epoch_2 Metric GRU Stacked Bidirectional RNN: 4.22%\n",
      "GRU Stacked Bidirectional RNN loss: 0.151428\n",
      "GRU Stacked Bidirectional RNN loss: 0.152693\n",
      "Epoch_3 Metric GRU Stacked Bidirectional RNN: 4.22%\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 3\n",
    "\n",
    "for model in models:\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "    train(model, loss_fn, optimizer, EPOCHS, Hamming_score, X_train_fixed, y_train, 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3493fca9-bd27-4ae1-845e-13a621cc06f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    model.compile(\n",
    "        loss=torch.nn.BCEWithLogitsLoss(),\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            ...\n",
    "        ),\n",
    "        metrics=[\n",
    "            ...\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d844e36e-34a4-4a42-8818-96d88ad9ef7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_dataset, test_dataset in datasets:\n",
    "    for model in models:\n",
    "        model.fit(train_dataset, validation_data=test_dataset, epochs=...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d19d6cb-a4b7-415e-9dc6-da3623c5a295",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d9afd3-afb6-4549-9a9f-4eb6102694e1",
   "metadata": {},
   "source": [
    "Evaluate the models you trained on the test datasets. Plot ROC curves for each label (use `sklearn.metrics.RocCurveDisplay`) for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f331fc5c-5d19-4fa8-a5e1-3216d9d4457d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    model: keras.Model,\n",
    "    ax: plt.Axes | None = None\n",
    ") -> float:\n",
    "    '''Plots ROC curves for each of the labels (on a single axes) and outputs mean ROC AUC score.\n",
    "\n",
    "    Arguments:\n",
    "        X: model inputs\n",
    "        y: ground thruths\n",
    "        model: model to plot the curve for\n",
    "        ax: axes to plot on\n",
    "\n",
    "    Returns:\n",
    "        Mean ROC AUC score'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d38c983-510f-47f5-8a11-5344b53c15e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "224c37b8-218a-43d8-b056-2389a3869e8c",
   "metadata": {},
   "source": [
    "Plot the mean ROC AUC scores. Which model has the highest score? On what kind of dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba2b2c8-66ec-40e9-aaec-07ac79c86ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f56b9bca-296b-45cd-be57-6027371d0c5a",
   "metadata": {},
   "source": [
    "Inspect the best model performance closer. Come up with some sentences (in English). Does the model output sensible results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f66686-4319-4762-82d0-963edbad5fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_text(text: str, model: keras.Model, threshold: float = 0.5, max_length: int | None = None) -> list[str]:\n",
    "    '''Computes the model output for `text` and outputs a list of emotions that have a probability of at least `threshold`\n",
    "\n",
    "    Arguments:\n",
    "        text: text to label\n",
    "        model: model to use\n",
    "        threshold: threshold to use\n",
    "        max_length: max length for tokenization\n",
    "    \n",
    "    Return:\n",
    "        List of predicted emotion labels'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b59fe95-b472-4b7b-95f9-23d17bba18db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_emotion_scores(text: str, model: keras.Model, max_length: int | None = None, ax: plt.Axes | None = None):\n",
    "    '''Plots a bar plot of emotion probabilities for given `text` using `model`.\n",
    "\n",
    "    Arguments:\n",
    "        text: text to label\n",
    "        model: model to use        \n",
    "        max_length: max length for tokenization\n",
    "        ax: axes to plot on'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e7a3fd-d086-47da-ab93-4927079cd037",
   "metadata": {},
   "source": [
    "For each of your texts get a list of emotion labels and plot emotion scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ae81dd-ab9c-46a0-825f-ab53b367b75c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c98b8e7f-e826-497c-943a-fe944a4f4ba9",
   "metadata": {},
   "source": [
    "# Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa03eefa-90f1-4be9-9ab0-b17e85993aa1",
   "metadata": {},
   "source": [
    "Train and evaluate the same model as your best one, but use a different cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a1a9da-b0a9-4a4d-9d91-b7061fc903b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
