{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2dbe8ed-bc36-4ce8-9fd1-22866ca3ad2e",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "* надо придумать как батчи пихнуть (var_text)\n",
    "* \"pack\" the sequences in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4b7aaf-d09b-4b64-91e6-dee2976ce379",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16f89b44-fede-422c-b525-9a267aad4d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bob1ch/Рабочий стол/NN-NLP/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#import keras\n",
    "import datasets\n",
    "import numpy as np\n",
    "import transformers\n",
    "import sklearn.metrics\n",
    "#import tensorflow as tf\n",
    "import tqdm.notebook as tqdm\n",
    "import sklearn.model_selection\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc4e64b0-7eef-4af2-9906-44c8cdb86c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pytorch\n",
    "import torch\n",
    "#from torchsummary import summary\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d400cd26-730e-4c4e-aaed-5987f78ef5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfb9f8d-1cf5-4954-8b70-18d47dee46e3",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8cc56a-5c94-4134-902d-e74edf1414aa",
   "metadata": {},
   "source": [
    "Load the dataset (we will be using [go_emotions](https://huggingface.co/datasets/google-research-datasets/go_emotions)). Pretokenize data or make a loader that tokenizes the sentenses as you iterate through the dataset. Implement two datasets: variable and fixed sentence length (in tokens). Don't forget to split the dataset into train and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fea15226-0e61-4fcd-a188-d6330e545465",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset('google-research-datasets/go_emotions', name='raw', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b144fe06-9838-4812-9e19-9b74e903bba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = [\n",
    "    'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity',\n",
    "    'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear',\n",
    "    'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief',\n",
    "    'remorse', 'sadness', 'surprise', 'neutral'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "682d6798-62fe-4d5c-8b8b-99394df534ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bob1ch/Рабочий стол/NN-NLP/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50256"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddcc3ba9-fb2c-40b2-af4b-db4595895756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This person is the smartest person to play town of salem literally 999999999999999999999999999999999999999999999999999999999999999999999999999999999999999991000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001234567898765432345676543345678987654345678909876543234567898765432345678909876543234567898765432345678987654323456787654345676543456543456434543434343434323456765434567654323454323456543345678987654323456789876565656565656565656565656565454545654565454323456765432345678765456 IQ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1212,  1048,   318,   262, 44730,  1048,   284,   711,  3240,   286,\n",
       "          3664,   368,  7360,   860, 24214, 24214, 24214, 24214, 24214, 24214,\n",
       "         24214, 24214, 24214, 24214, 24214, 24214, 24214, 24214, 24214, 24214,\n",
       "         24214, 24214, 24214, 24214, 24214, 24214,    16, 25645, 25645, 25645,\n",
       "         25645, 25645, 25645, 25645, 25645, 25645, 25645, 25645, 25645, 25645,\n",
       "         25645, 25645, 25645,  8269,   405, 10163,  2231, 30924,  4089, 29143,\n",
       "          3559,  1954,  2231,  3134, 39111,  2091,  2231, 30924,  4089, 29143,\n",
       "          3559,  2231,  3134,  4531,  2931,  5774,  2996,  3559,  1954,  2231,\n",
       "         30924,  4089, 29143,  3559,  1954,  2231,  3134,  4531,  2931,  5774,\n",
       "          2996,  3559,  1954,  2231, 30924,  4089, 29143,  3559,  1954,  2231,\n",
       "         30924,  4089, 29143,  3559,  1954,  2231,  3134,  5774,  2996,  3559,\n",
       "          2231,  3134,  2996,  3559,  2231,  2996,  3559,  2231,  2414, 27712,\n",
       "         47101,  2682,  2682,  2682, 32118,  1954,  2231,  3134,  2996,  3559,\n",
       "          2231,  3134,  2996,  3559,  1954,  2231,  3559,  1954,  2231, 39111,\n",
       "          2091,  2231, 30924,  4089, 29143,  3559,  1954,  2231, 30924,  4089,\n",
       "         29143,  2996,  2996,  2996,  2996,  2996,  2996,  2996,  2996,  2996,\n",
       "          2996,  2996,  2996,  2996,  2231,  2231,  2231,  2996,  2231,  2996,\n",
       "          2231,  3559,  1954,  2231,  3134,  2996,  3559,  1954,  2231,  3134,\n",
       "          5774,  2996, 29228, 18248, 50256]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longets_text = dataset['text'][np.argmax(list(map(len, dataset['text'])))]\n",
    "print(longets_text)\n",
    "tokenizer(longets_text, return_tensors='pt', padding='max_length', max_length=185, truncation=True)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02778ee6-1ff7-4fc9-be85-67c3b4895b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1435 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "#text_fixed = tokenizer(dataset['text'], return_tensors='pt', padding='max_length', max_length=128, truncation=True)['input_ids']\n",
    "text_fixed = tokenizer(dataset['text'], return_tensors='pt', padding='max_length', max_length=32, truncation=True)['input_ids']\n",
    "variable_text = tokenizer(dataset['text'])['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99359e1c-dbf9-4d56-858e-18c7291b5efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = list()\n",
    "for c in emotions:\n",
    "    y.append(dataset[c])\n",
    "y = np.array(y).T\n",
    "y[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6533700d-ac9f-4753-a8b6-4a542116f222",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fixed, X_test_fixed, y_train, y_test = sklearn.model_selection.train_test_split(text_fixed, y, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68c0ff65-27ec-4985-b73d-a072584874ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147857"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0462e916-4b28-4e73-bfb6-3781c1f553ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_var, X_test_var, y_train, y_test = sklearn.model_selection.train_test_split(variable_text, y, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd4868c1-cc9a-4828-8e52-b552d8159eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147857"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b628be8-1f04-4212-9392-dee3e207f532",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066591d4-60c1-4918-85e7-fafe734d1804",
   "metadata": {},
   "source": [
    "Implement your model. The model should have the RNN architecture (with LSTM or GRU cells), support stacking and bidirectional feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e54e3784-2f24-42a2-a8a0-164378480a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(prefix: str | None = None, suffix: str | None = None, separator: str = '_') -> str | None:\n",
    "    return prefix and prefix + separator + suffix or suffix or None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90a144e0-b2f7-41a9-8f4f-4a84f40d6077",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, units: int, n_tokens: int, n_labels: int, n_stacks: int, bidirectional: bool, name: str, cell_type):\n",
    "        super(Model, self).__init__()\n",
    "        self.name = name\n",
    "        self.units = units\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        #torch.nn.GRU(input_size, hidden_size, num_layers=1, bias=True, batch_first=False, dropout=0.0, bidirectional=False, device=None, dtype=None)\n",
    "        #torch.nn.LSTM(input_size, hidden_size, num_layers=1, bias=True, batch_first=False, dropout=0.0, bidirectional=False, proj_size=0, device=None, dtype=None)\n",
    "        \n",
    "        self.embeddings = torch.nn.Embedding(n_tokens, units)\n",
    "        self.rnn = cell_type(units, units*2, num_layers=n_stacks, bidirectional=bidirectional)\n",
    "        self.FC = torch.nn.Linear(units*2*2 if bidirectional else units*2, n_labels)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embeds = self.embeddings(text)\n",
    "        \n",
    "        # костыль, если у меня без батчей (var_text)\n",
    "        # надо придумать как сюда батчки пихнуть (var_text)\n",
    "        embeds = embeds.permute(1, 0, 2) if len(embeds.shape) == 3 else embeds\n",
    "        out, _ = self.rnn(embeds)\n",
    "        out = out[-1]\n",
    "\n",
    "        out = self.FC(out)\n",
    "        return out\n",
    "\n",
    "def get_model(\n",
    "    units: int,\n",
    "    n_tokens: int,\n",
    "    n_labels: int,\n",
    "    n_stacks: int = 1,\n",
    "    bidirectional: bool = False,\n",
    "    name: str | None = None,\n",
    "    cell_type: type[torch.nn.modules] = torch.nn.LSTM\n",
    ") -> torch.nn.Module:\n",
    "    '''Creates a model with RNN architecture for sequence multilabel classification.\n",
    "\n",
    "    Arguments:\n",
    "        units: dimensionality of RNN cells OR units: Positive integer, dimensionality of the output space\n",
    "        n_tokens: number of tokens in the tokenizer dictionary\n",
    "        n_labels: number of labels to be predicted\n",
    "        n_stacks: number of RNN cells in the stack (1 -- no stacking)\n",
    "        bidirectional: whether or not the model is bidirectional\n",
    "        name: the model name\n",
    "        cell_type: type of a cell to use, either keras.layers.LSTMCell or keras.layers.GRUCell\n",
    "\n",
    "    Returns:\n",
    "        The model'''\n",
    "    return Model(units, n_tokens, n_labels, n_stacks, bidirectional, name, cell_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c8f8b8ea-b172-462b-88b5-3d8637b6a869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Model(torch.nn.Module):\n",
    "\n",
    "#     def __init__(self, units: int, embed_dim: int, n_tokens: int, n_labels: int, n_stacks: int, bidirectional: bool, name: str, cell_type):\n",
    "#         super(Model, self).__init__()\n",
    "#         self.name = name\n",
    "#         self.units = units\n",
    "#         self.bidirectional = bidirectional\n",
    "        \n",
    "#         #torch.nn.GRU(input_size, hidden_size, num_layers=1, bias=True, batch_first=False, dropout=0.0, bidirectional=False, device=None, dtype=None)\n",
    "#         #torch.nn.LSTM(input_size, hidden_size, num_layers=1, bias=True, batch_first=False, dropout=0.0, bidirectional=False, proj_size=0, device=None, dtype=None)\n",
    "        \n",
    "#         self.embeddings = torch.nn.Embedding(n_tokens, embed_dim)\n",
    "#         #torch.nn.LSTMCell(input_size, hidden_size, bias=True, device=None, dtype=None)\n",
    "#         self.rnn = cell_type(embed_dim, units, num_layers=n_stacks, bidirectional=bidirectional)\n",
    "#         self.FC = torch.nn.Linear(units*2 if bidirectional else units, n_labels)\n",
    "\n",
    "#     def forward(self, text):\n",
    "#         embeds = self.embeddings(text)\n",
    "#         embeds = embeds.permute(1, 0, 2)\n",
    "#         out, _ = self.rnn(embeds)\n",
    "#         out = out[-1]\n",
    "\n",
    "#         # if self.bidirectional:\n",
    "#         #     return out.shape\n",
    "#         #     out = torch.cat((out[0], out[1]), dim=1)\n",
    "\n",
    "#         out = self.FC(out)\n",
    "#         return out\n",
    "\n",
    "# def get_model(\n",
    "#     units: int,\n",
    "#     n_tokens: int,\n",
    "#     n_labels: int,\n",
    "#     n_stacks: int = 1,\n",
    "#     bidirectional: bool = False,\n",
    "#     name: str | None = None,\n",
    "#     cell_type: type[torch.nn.modules] = torch.nn.LSTM\n",
    "# ) -> torch.nn.Module:\n",
    "#     '''Creates a model with RNN architecture for sequence multilabel classification.\n",
    "\n",
    "#     Arguments:\n",
    "#         units: dimensionality of RNN cells OR units: Positive integer, dimensionality of the output space\n",
    "#         n_tokens: number of tokens in the tokenizer dictionary\n",
    "#         n_labels: number of labels to be predicted\n",
    "#         n_stacks: number of RNN cells in the stack (1 -- no stacking)\n",
    "#         bidirectional: whether or not the model is bidirectional\n",
    "#         name: the model name\n",
    "#         cell_type: type of a cell to use, either keras.layers.LSTMCell or keras.layers.GRUCell\n",
    "\n",
    "#     Returns:\n",
    "#         The model'''\n",
    "#     return Model(units, n_tokens, n_labels, n_stacks, bidirectional, name, cell_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1d16ca7-0bcd-4213-a3cd-1b3d35662079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0072, -0.0105, -0.0005,  0.0547,  0.0246, -0.0007, -0.0439,  0.0377,\n",
       "          0.0557,  0.0369, -0.0037, -0.0520,  0.0469,  0.0458,  0.0633, -0.0220,\n",
       "         -0.0224, -0.0493, -0.0416,  0.0249, -0.0491, -0.0241, -0.0395,  0.0190,\n",
       "         -0.0142,  0.0206, -0.0044,  0.0503],\n",
       "        [ 0.0072, -0.0105, -0.0005,  0.0547,  0.0246, -0.0007, -0.0439,  0.0377,\n",
       "          0.0557,  0.0369, -0.0037, -0.0520,  0.0469,  0.0458,  0.0633, -0.0220,\n",
       "         -0.0224, -0.0493, -0.0416,  0.0249, -0.0491, -0.0241, -0.0395,  0.0190,\n",
       "         -0.0142,  0.0206, -0.0044,  0.0503],\n",
       "        [ 0.0072, -0.0105, -0.0005,  0.0547,  0.0246, -0.0007, -0.0439,  0.0377,\n",
       "          0.0557,  0.0369, -0.0037, -0.0520,  0.0469,  0.0458,  0.0633, -0.0220,\n",
       "         -0.0224, -0.0493, -0.0416,  0.0249, -0.0491, -0.0241, -0.0395,  0.0190,\n",
       "         -0.0142,  0.0206, -0.0044,  0.0503]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(units=64, \n",
    "                  n_tokens=len(tokenizer.vocab), \n",
    "                  n_labels=len(emotions), \n",
    "                  n_stacks=100, \n",
    "                  bidirectional=True, \n",
    "                  name='LSTM', \n",
    "                  cell_type=torch.nn.LSTM)\n",
    "#model(torch.Tensor(variable_text[0]).to(int))\n",
    "model(text_fixed[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1790d12f-d3f9-477e-bbfc-067baadf33c6",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42397b6a-e849-4179-a359-647e902300f4",
   "metadata": {},
   "source": [
    "Train several models on the two dataset variants. Use either of the cell types (LSTM or GRU)\n",
    "* Simple RNN (no stacking, one direction)\n",
    "* Stacked RNN (stacking, one direction)\n",
    "* Bidirectional RNN (no stacking, bidirectional)\n",
    "* Stacked Bidirectional RNN (stacking, bidirectional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1382d9b-3da7-4a5d-a272-7ea53efc5e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#units, name, bidirectional, n_stacks, cell_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "07bf0549-2961-432a-a457-9d79bd22f848",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = ['Simple RNN', 'Stacked RNN', 'Bidirectional RNN', 'Stacked Bidirectional RNN']\n",
    "architecture = ['LSTM ', 'GRU ']\n",
    "all_names = [arch + config for arch in architecture for config in configs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "a71e161d-5e01-4d4e-8027-4a5a8838c542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LSTM Simple RNN', Model(\n",
      "  (embeddings): Embedding(50257, 32)\n",
      "  (rnn): LSTM(32, 64)\n",
      "  (FC): Linear(in_features=64, out_features=28, bias=True)\n",
      "))\n",
      "('LSTM Stacked RNN', Model(\n",
      "  (embeddings): Embedding(50257, 32)\n",
      "  (rnn): LSTM(32, 64, num_layers=3)\n",
      "  (FC): Linear(in_features=64, out_features=28, bias=True)\n",
      "))\n",
      "('LSTM Bidirectional RNN', Model(\n",
      "  (embeddings): Embedding(50257, 32)\n",
      "  (rnn): LSTM(32, 64, bidirectional=True)\n",
      "  (FC): Linear(in_features=128, out_features=28, bias=True)\n",
      "))\n",
      "('LSTM Stacked Bidirectional RNN', Model(\n",
      "  (embeddings): Embedding(50257, 32)\n",
      "  (rnn): LSTM(32, 64, num_layers=3, bidirectional=True)\n",
      "  (FC): Linear(in_features=128, out_features=28, bias=True)\n",
      "))\n",
      "('GRU Simple RNN', Model(\n",
      "  (embeddings): Embedding(50257, 32)\n",
      "  (rnn): GRU(32, 64)\n",
      "  (FC): Linear(in_features=64, out_features=28, bias=True)\n",
      "))\n",
      "('GRU Stacked RNN', Model(\n",
      "  (embeddings): Embedding(50257, 32)\n",
      "  (rnn): GRU(32, 64, num_layers=3)\n",
      "  (FC): Linear(in_features=64, out_features=28, bias=True)\n",
      "))\n",
      "('GRU Bidirectional RNN', Model(\n",
      "  (embeddings): Embedding(50257, 32)\n",
      "  (rnn): GRU(32, 64, bidirectional=True)\n",
      "  (FC): Linear(in_features=128, out_features=28, bias=True)\n",
      "))\n",
      "('GRU Stacked Bidirectional RNN', Model(\n",
      "  (embeddings): Embedding(50257, 32)\n",
      "  (rnn): GRU(32, 64, num_layers=3, bidirectional=True)\n",
      "  (FC): Linear(in_features=128, out_features=28, bias=True)\n",
      "))\n"
     ]
    }
   ],
   "source": [
    "super_zip = zip([32] * 8,                                  #units\n",
    "                all_names,                                 #name\n",
    "                ([False] * 2 + [True] * 2) * 2,            #bidirectional\n",
    "                [1, 3] * 4,                                #n_stacks\n",
    "                [torch.nn.LSTM] * 4 + [torch.nn.GRU] * 4,) #cell_type\n",
    "\n",
    "models = [\n",
    "    get_model(\n",
    "        units=units,\n",
    "        n_tokens=len(tokenizer.get_vocab()),\n",
    "        n_labels=len(emotions),\n",
    "        name=name,\n",
    "        bidirectional=bidirectional,\n",
    "        n_stacks=n_stacks,\n",
    "        cell_type=cell_type\n",
    "    )\n",
    "    for units, name, bidirectional, n_stacks, cell_type in super_zip\n",
    "]\n",
    "print(*[(model.name, model) for model in models], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92142b18-0255-416d-812b-b2cce689196a",
   "metadata": {},
   "source": [
    "Which loss should be used to multilabel classification? Which metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "be315f1d-1b09-4a6e-a301-c2e9ac0d3bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "# about hamming score https://wiki.cloudfactory.com/docs/mp-wiki/metrics/hamming-score\n",
    "# about metrics 4 multilabel https://mmuratarat.github.io/2020-01-25/multilabel_classification_metrics\n",
    "def Hamming_score(y_true, y_pred, tr=0.5, use_sigmoid=True):\n",
    "    \n",
    "    if use_sigmoid:\n",
    "        y_pred = 1 / (1 + np.exp(-y_pred))\n",
    "        y_pred = (y_pred > tr).astype(int)\n",
    "\n",
    "    # temp = 0\n",
    "    # for i in range(y_true.shape[0]):\n",
    "    #     temp += sum(np.logical_and(y_true[i], y_pred[i])) / sum(np.logical_or(y_true[i], y_pred[i]))\n",
    "    #return temp / y_true.shape[0]\n",
    "    return ((y_true & y_pred).sum(axis=-1) / (y_true | y_pred).sum(axis=-1)).mean()\n",
    "test_true = np.array([[0, 1, 1], \n",
    "                      [0, 1, 1]])\n",
    "\n",
    "print(Hamming_score(test_true, np.array([[0, 1, 0], \n",
    "                                         [0, 1, 0]])), \n",
    "      Hamming_score(test_true, np.array([[1, 0, 0], \n",
    "                                         [1, 0, 0]])), \n",
    "      Hamming_score(test_true, np.array([[0, 1, 1], \n",
    "                                         [0, 1, 1]])))\n",
    "\n",
    "# пример для 1 объекта\n",
    "# hamping = 0\n",
    "# y_true, y_pred = np.array([0, 1, 1]), np.array([0, 1, 1])\n",
    "# hamping = sum(np.logical_and(y_true, y_pred)) / sum(np.logical_or(y_true, y_pred))\n",
    "# hamping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "bdfa195e-cb43-4c4a-9f6e-b31b5bd1676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Dataset_multilabel(Dataset):\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        super().__init__()\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "        \n",
    "training_data = Dataset_multilabel(X_train_fixed, y_train)\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "b6245c79-6372-4c78-a3fd-037424f6236f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 5812,    11,  7926, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_fixed[0], y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "c416bf78-a954-4837-968c-0ff4365d3fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, optimizer, dataloader, batch_size):\n",
    "    \n",
    "    size = len(dataloader)\n",
    "    model.train()\n",
    "\n",
    "    #percent_of_batch = len(training_data) // batch_size / 2\n",
    "    running_loss = 0\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to('cuda'), y.to('cuda')\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y.float())\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # if batch % percent_of_batch == 0:\n",
    "        #     loss = loss.item()\n",
    "        #     print(f\"{model.name} loss: {loss:>7f}\")\n",
    "    return running_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "b63491c3-5aa6-4f89-a37d-79a33005ddc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loss_fn, dataloader, metric, tr):\n",
    "    \n",
    "    model.eval()\n",
    "    running_metric = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to('cuda'), y.to('cuda')\n",
    "            y_pred = model(X).cpu().numpy()\n",
    "            y_pred = ((1 / (1 + np.exp(-y_pred))) > tr).astype(int)\n",
    "            running_metric += (y.cpu().numpy() == y_pred).mean()\n",
    "    return running_metric / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "25b2824c-1fa5-42a1-bfa8-c17f861ca49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "####optimizer = torch.optim.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "d1652d9f-816d-4b36-9bf7-21d38e764e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n",
      "LSTM Simple RNN loss: 0.6718681007623672\n",
      "Hamming score: 79.40%\n",
      "----------------------------------------\n",
      "Epoch 5:\n",
      "LSTM Simple RNN loss: 0.33520069738497604\n",
      "Hamming score: 95.51%\n",
      "----------------------------------------\n",
      "Epoch 10:\n",
      "LSTM Simple RNN loss: 0.19718081962216544\n",
      "Hamming score: 95.78%\n",
      "----------------------------------------\n",
      "Epoch 15:\n",
      "LSTM Simple RNN loss: 0.16941172846064373\n",
      "Hamming score: 95.78%\n",
      "----------------------------------------\n",
      "Epoch 20:\n",
      "LSTM Simple RNN loss: 0.1607252740477388\n",
      "Hamming score: 95.78%\n",
      "----------------------------------------\n",
      "Epoch 25:\n",
      "LSTM Simple RNN loss: 0.15807717912704558\n",
      "Hamming score: 95.78%\n",
      "----------------------------------------\n",
      "Epoch 30:\n",
      "LSTM Simple RNN loss: 0.15736824470395977\n",
      "Hamming score: 95.78%\n",
      "----------------------------------------\n",
      "Epoch 35:\n",
      "LSTM Simple RNN loss: 0.15718932620979645\n",
      "Hamming score: 95.78%\n",
      "----------------------------------------\n",
      "Epoch 0:\n",
      "LSTM Stacked RNN loss: 0.6660369004349451\n",
      "Hamming score: 79.97%\n",
      "----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[383], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[1;32m     14\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m train(model, loss_fn, optimizer, train_dataloader, BATCH_SIZE)\n\u001b[0;32m---> 15\u001b[0m     train_metric \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mHamming_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m5\u001b[39m:\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[381], line 9\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, loss_fn, dataloader, metric, tr)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m      8\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m), y\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     10\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m ((\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39my_pred))) \u001b[38;5;241m>\u001b[39m tr)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m     11\u001b[0m     running_metric \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (y\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;241m==\u001b[39m y_pred)\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/Рабочий стол/NN-NLP/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Рабочий стол/NN-NLP/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[31], line 22\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# костыль, если у меня без батчей (var_text)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# надо придумать как сюда батчки пихнуть (var_text)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m embeds \u001b[38;5;241m=\u001b[39m embeds\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(embeds\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m embeds\n\u001b[0;32m---> 22\u001b[0m out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m out \u001b[38;5;241m=\u001b[39m out[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     25\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mFC(out)\n",
      "File \u001b[0;32m~/Рабочий стол/NN-NLP/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Рабочий стол/NN-NLP/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Рабочий стол/NN-NLP/venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:917\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    914\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 917\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    920\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    921\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 40\n",
    "BATCH_SIZE = 500\n",
    "\n",
    "training_data = Dataset_multilabel(X_train_fixed, y_train)\n",
    "train_dataloader = DataLoader(training_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "for model in models:\n",
    "    model.to('cuda')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    for i in range(EPOCHS):\n",
    "        \n",
    "        train_loss = train(model, loss_fn, optimizer, train_dataloader, BATCH_SIZE)\n",
    "        train_metric = test(model, loss_fn, train_dataloader, Hamming_score, 0.5)\n",
    "        if not i % 5:\n",
    "            print(f'Epoch {i}:')\n",
    "            print(f'{model.name} loss: {train_loss}')\n",
    "            print(f'Hamming score: {train_metric * 100 :.2f}%')\n",
    "            print('-'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3493fca9-bd27-4ae1-845e-13a621cc06f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    model.compile(\n",
    "        loss=torch.nn.BCEWithLogitsLoss(),\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            ...\n",
    "        ),\n",
    "        metrics=[\n",
    "            ...\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d844e36e-34a4-4a42-8818-96d88ad9ef7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_dataset, test_dataset in datasets:\n",
    "    for model in models:\n",
    "        model.fit(train_dataset, validation_data=test_dataset, epochs=...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d19d6cb-a4b7-415e-9dc6-da3623c5a295",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d9afd3-afb6-4549-9a9f-4eb6102694e1",
   "metadata": {},
   "source": [
    "Evaluate the models you trained on the test datasets. Plot ROC curves for each label (use `sklearn.metrics.RocCurveDisplay`) for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f331fc5c-5d19-4fa8-a5e1-3216d9d4457d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    model: keras.Model,\n",
    "    ax: plt.Axes | None = None\n",
    ") -> float:\n",
    "    '''Plots ROC curves for each of the labels (on a single axes) and outputs mean ROC AUC score.\n",
    "\n",
    "    Arguments:\n",
    "        X: model inputs\n",
    "        y: ground thruths\n",
    "        model: model to plot the curve for\n",
    "        ax: axes to plot on\n",
    "\n",
    "    Returns:\n",
    "        Mean ROC AUC score'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d38c983-510f-47f5-8a11-5344b53c15e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "224c37b8-218a-43d8-b056-2389a3869e8c",
   "metadata": {},
   "source": [
    "Plot the mean ROC AUC scores. Which model has the highest score? On what kind of dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba2b2c8-66ec-40e9-aaec-07ac79c86ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f56b9bca-296b-45cd-be57-6027371d0c5a",
   "metadata": {},
   "source": [
    "Inspect the best model performance closer. Come up with some sentences (in English). Does the model output sensible results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f66686-4319-4762-82d0-963edbad5fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_text(text: str, model: keras.Model, threshold: float = 0.5, max_length: int | None = None) -> list[str]:\n",
    "    '''Computes the model output for `text` and outputs a list of emotions that have a probability of at least `threshold`\n",
    "\n",
    "    Arguments:\n",
    "        text: text to label\n",
    "        model: model to use\n",
    "        threshold: threshold to use\n",
    "        max_length: max length for tokenization\n",
    "    \n",
    "    Return:\n",
    "        List of predicted emotion labels'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b59fe95-b472-4b7b-95f9-23d17bba18db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_emotion_scores(text: str, model: keras.Model, max_length: int | None = None, ax: plt.Axes | None = None):\n",
    "    '''Plots a bar plot of emotion probabilities for given `text` using `model`.\n",
    "\n",
    "    Arguments:\n",
    "        text: text to label\n",
    "        model: model to use        \n",
    "        max_length: max length for tokenization\n",
    "        ax: axes to plot on'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e7a3fd-d086-47da-ab93-4927079cd037",
   "metadata": {},
   "source": [
    "For each of your texts get a list of emotion labels and plot emotion scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ae81dd-ab9c-46a0-825f-ab53b367b75c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c98b8e7f-e826-497c-943a-fe944a4f4ba9",
   "metadata": {},
   "source": [
    "# Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa03eefa-90f1-4be9-9ab0-b17e85993aa1",
   "metadata": {},
   "source": [
    "Train and evaluate the same model as your best one, but use a different cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a1a9da-b0a9-4a4d-9d91-b7061fc903b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
