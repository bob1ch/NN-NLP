{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2dbe8ed-bc36-4ce8-9fd1-22866ca3ad2e",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "* ~~надо придумать как батчи пихнуть (var_text)~~\n",
    "* ~~\"pack\" the sequences in PyTorch~~\n",
    "* ~~Придумать метрику~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4b7aaf-d09b-4b64-91e6-dee2976ce379",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16f89b44-fede-422c-b525-9a267aad4d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bob1ch/Рабочий стол/NN-NLP/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#import keras\n",
    "import os\n",
    "import datasets\n",
    "import numpy as np\n",
    "import transformers\n",
    "import sklearn.metrics\n",
    "#import tensorflow as tf\n",
    "import tqdm.notebook as tqdm\n",
    "import sklearn.model_selection\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc4e64b0-7eef-4af2-9906-44c8cdb86c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pytorch\n",
    "import torch\n",
    "from torcheval.metrics import MultilabelAUPRC\n",
    "from torchmetrics.classification import MultilabelAUROC\n",
    "#from torchsummary import summary\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13985f18-9a23-4c4a-9349-4710dc4d63b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d400cd26-730e-4c4e-aaed-5987f78ef5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfb9f8d-1cf5-4954-8b70-18d47dee46e3",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8cc56a-5c94-4134-902d-e74edf1414aa",
   "metadata": {},
   "source": [
    "Load the dataset (we will be using [go_emotions](https://huggingface.co/datasets/google-research-datasets/go_emotions)). Pretokenize data or make a loader that tokenizes the sentenses as you iterate through the dataset. Implement two datasets: variable and fixed sentence length (in tokens). Don't forget to split the dataset into train and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fea15226-0e61-4fcd-a188-d6330e545465",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset('google-research-datasets/go_emotions', name='raw', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b144fe06-9838-4812-9e19-9b74e903bba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = [\n",
    "    'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity',\n",
    "    'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear',\n",
    "    'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief',\n",
    "    'remorse', 'sadness', 'surprise', 'neutral'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "682d6798-62fe-4d5c-8b8b-99394df534ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bob1ch/Рабочий стол/NN-NLP/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50256"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddcc3ba9-fb2c-40b2-af4b-db4595895756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This person is the smartest person to play town of salem literally 999999999999999999999999999999999999999999999999999999999999999999999999999999999999999991000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001234567898765432345676543345678987654345678909876543234567898765432345678909876543234567898765432345678987654323456787654345676543456543456434543434343434323456765434567654323454323456543345678987654323456789876565656565656565656565656565454545654565454323456765432345678765456 IQ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1212,  1048,   318,   262, 44730,  1048,   284,   711,  3240,   286,\n",
       "          3664,   368,  7360,   860, 24214, 24214, 24214, 24214, 24214, 24214,\n",
       "         24214, 24214, 24214, 24214, 24214, 24214, 24214, 24214, 24214, 24214,\n",
       "         24214, 24214, 24214, 24214, 24214, 24214,    16, 25645, 25645, 25645,\n",
       "         25645, 25645, 25645, 25645, 25645, 25645, 25645, 25645, 25645, 25645,\n",
       "         25645, 25645, 25645,  8269,   405, 10163,  2231, 30924,  4089, 29143,\n",
       "          3559,  1954,  2231,  3134, 39111,  2091,  2231, 30924,  4089, 29143,\n",
       "          3559,  2231,  3134,  4531,  2931,  5774,  2996,  3559,  1954,  2231,\n",
       "         30924,  4089, 29143,  3559,  1954,  2231,  3134,  4531,  2931,  5774,\n",
       "          2996,  3559,  1954,  2231, 30924,  4089, 29143,  3559,  1954,  2231,\n",
       "         30924,  4089, 29143,  3559,  1954,  2231,  3134,  5774,  2996,  3559,\n",
       "          2231,  3134,  2996,  3559,  2231,  2996,  3559,  2231,  2414, 27712,\n",
       "         47101,  2682,  2682,  2682, 32118,  1954,  2231,  3134,  2996,  3559,\n",
       "          2231,  3134,  2996,  3559,  1954,  2231,  3559,  1954,  2231, 39111,\n",
       "          2091,  2231, 30924,  4089, 29143,  3559,  1954,  2231, 30924,  4089,\n",
       "         29143,  2996,  2996,  2996,  2996,  2996,  2996,  2996,  2996,  2996,\n",
       "          2996,  2996,  2996,  2996,  2231,  2231,  2231,  2996,  2231,  2996,\n",
       "          2231,  3559,  1954,  2231,  3134,  2996,  3559,  1954,  2231,  3134,\n",
       "          5774,  2996, 29228, 18248, 50256]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longets_text = dataset['text'][np.argmax(list(map(len, dataset['text'])))]\n",
    "print(longets_text)\n",
    "tokenizer(longets_text, return_tensors='pt', padding='max_length', max_length=185, truncation=True)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02778ee6-1ff7-4fc9-be85-67c3b4895b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1435 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "#text_fixed = tokenizer(dataset['text'], return_tensors='pt', padding='max_length', max_length=128, truncation=True)['input_ids']\n",
    "text_fixed = tokenizer(dataset['text'], return_tensors='pt', padding='max_length', max_length=64, truncation=True)['input_ids']\n",
    "variable_text = tokenizer(dataset['text'])['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99359e1c-dbf9-4d56-858e-18c7291b5efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = list()\n",
    "for c in emotions:\n",
    "    y.append(dataset[c])\n",
    "y = np.array(y).T\n",
    "y[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6533700d-ac9f-4753-a8b6-4a542116f222",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fixed, X_test_fixed, y_train, y_test = sklearn.model_selection.train_test_split(text_fixed, y, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68c0ff65-27ec-4985-b73d-a072584874ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147857"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0462e916-4b28-4e73-bfb6-3781c1f553ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_var, X_test_var, y_train, y_test = sklearn.model_selection.train_test_split(variable_text, y, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd4868c1-cc9a-4828-8e52-b552d8159eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147857"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f392f46-1a6b-4d8c-9d9f-07d9061e4dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[27354,  7616, 12883,  ..., 50256, 50256, 50256],\n",
       "         [ 3987,   447,   247,  ..., 50256, 50256, 50256],\n",
       "         [19485,  2282, 14276,  ..., 50256, 50256, 50256],\n",
       "         ...,\n",
       "         [17784,   284, 15962,  ..., 50256, 50256, 50256],\n",
       "         [   40,   760,  3228,  ..., 50256, 50256, 50256],\n",
       "         [10995,    11,   314,  ..., 50256, 50256, 50256]]),\n",
       " tensor([[0, 0, 0,  ..., 0, 0, 1],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def pad_collate(batch):\n",
    "    (xx, yy) = zip(*batch)\n",
    "    xx = list(map(torch.LongTensor, xx))\n",
    "    xx_pad = torch.nn.utils.rnn.pad_sequence(xx, batch_first=True, padding_value=tokenizer.eos_token_id)\n",
    "    yy = torch.LongTensor(np.array(yy)) #torch.Tensor(list) very slow\n",
    "    return xx_pad, yy\n",
    "\n",
    "class Dataset_multilabel(Dataset):\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        super().__init__()\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "        \n",
    "BATCH_SIZE = 50\n",
    "\n",
    "training_data_fixed = Dataset_multilabel(X_train_fixed, y_train)\n",
    "train_dataloader_fixed = DataLoader(training_data_fixed, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_data_fixed = Dataset_multilabel(X_test_fixed, y_test)\n",
    "test_dataloader_fixed = DataLoader(test_data_fixed, batch_size=BATCH_SIZE)\n",
    "\n",
    "training_data_var = Dataset_multilabel(X_train_var, y_train)\n",
    "train_dataloader_var = DataLoader(training_data_var, batch_size=100, shuffle=True, collate_fn=pad_collate)# 500 не влезал, потому что там может быть много токенов\n",
    "test_data_var = Dataset_multilabel(X_test_var, y_test)\n",
    "test_dataloader_var = DataLoader(test_data_var, batch_size=100, collate_fn=pad_collate)\n",
    "\n",
    "next(iter(train_dataloader_var))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b628be8-1f04-4212-9392-dee3e207f532",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066591d4-60c1-4918-85e7-fafe734d1804",
   "metadata": {},
   "source": [
    "Implement your model. The model should have the RNN architecture (with LSTM or GRU cells), support stacking and bidirectional feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e54e3784-2f24-42a2-a8a0-164378480a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(prefix: str | None = None, suffix: str | None = None, separator: str = '_') -> str | None:\n",
    "    return prefix and prefix + separator + suffix or suffix or None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90a144e0-b2f7-41a9-8f4f-4a84f40d6077",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, units: int, n_tokens: int, n_labels: int, n_stacks: int, bidirectional: bool, name: str, cell_type):\n",
    "        super(Model, self).__init__()\n",
    "        self.name = name\n",
    "        self.units = units\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        #torch.nn.GRU(input_size, hidden_size, num_layers=1, bias=True, batch_first=False, dropout=0.0, bidirectional=False, device=None, dtype=None)\n",
    "        #torch.nn.LSTM(input_size, hidden_size, num_layers=1, bias=True, batch_first=False, dropout=0.0, bidirectional=False, proj_size=0, device=None, dtype=None)\n",
    "        \n",
    "        self.embeddings = torch.nn.Embedding(n_tokens, units)\n",
    "        self.rnn = cell_type(units, units*2, num_layers=n_stacks, bidirectional=bidirectional)\n",
    "        self.FC = torch.nn.Linear(units*2*2 if bidirectional else units*2, n_labels)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embeds = self.embeddings(text)\n",
    "        \n",
    "        # костыль, если у меня без батчей (var_text)\n",
    "        # надо придумать как сюда батчки пихнуть (var_text)\n",
    "        embeds = embeds.permute(1, 0, 2) if len(embeds.shape) == 3 else embeds\n",
    "        out, _ = self.rnn(embeds)\n",
    "        out = out[-1]\n",
    "\n",
    "        out = self.FC(out)\n",
    "        return out\n",
    "\n",
    "def get_model(\n",
    "    units: int,\n",
    "    n_tokens: int,\n",
    "    n_labels: int,\n",
    "    n_stacks: int = 1,\n",
    "    bidirectional: bool = False,\n",
    "    name: str | None = None,\n",
    "    cell_type: type[torch.nn.modules] = torch.nn.LSTM\n",
    ") -> torch.nn.Module:\n",
    "    '''Creates a model with RNN architecture for sequence multilabel classification.\n",
    "\n",
    "    Arguments:\n",
    "        units: dimensionality of RNN cells OR units: Positive integer, dimensionality of the output space\n",
    "        n_tokens: number of tokens in the tokenizer dictionary\n",
    "        n_labels: number of labels to be predicted\n",
    "        n_stacks: number of RNN cells in the stack (1 -- no stacking)\n",
    "        bidirectional: whether or not the model is bidirectional\n",
    "        name: the model name\n",
    "        cell_type: type of a cell to use, either keras.layers.LSTMCell or keras.layers.GRUCell\n",
    "\n",
    "    Returns:\n",
    "        The model'''\n",
    "    return Model(units, n_tokens, n_labels, n_stacks, bidirectional, name, cell_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1d16ca7-0bcd-4213-a3cd-1b3d35662079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0359, -0.0511,  0.0354, -0.0420, -0.0016, -0.0026, -0.0537, -0.0122,\n",
       "          0.0245, -0.0228, -0.0437,  0.0344,  0.0494, -0.0017,  0.0427,  0.0123,\n",
       "         -0.0026, -0.0233, -0.0047, -0.0065,  0.0177,  0.0072, -0.0044, -0.0435,\n",
       "         -0.0106,  0.0424, -0.0164,  0.0124],\n",
       "        [ 0.0359, -0.0511,  0.0354, -0.0420, -0.0016, -0.0026, -0.0537, -0.0122,\n",
       "          0.0245, -0.0228, -0.0437,  0.0344,  0.0494, -0.0017,  0.0427,  0.0123,\n",
       "         -0.0026, -0.0233, -0.0047, -0.0065,  0.0177,  0.0072, -0.0044, -0.0435,\n",
       "         -0.0106,  0.0424, -0.0164,  0.0124],\n",
       "        [ 0.0359, -0.0511,  0.0354, -0.0420, -0.0016, -0.0026, -0.0537, -0.0122,\n",
       "          0.0245, -0.0228, -0.0437,  0.0344,  0.0494, -0.0017,  0.0427,  0.0123,\n",
       "         -0.0026, -0.0233, -0.0047, -0.0065,  0.0177,  0.0072, -0.0044, -0.0435,\n",
       "         -0.0106,  0.0424, -0.0164,  0.0124]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(units=128, \n",
    "                  n_tokens=len(tokenizer.vocab), \n",
    "                  n_labels=len(emotions), \n",
    "                  n_stacks=100, \n",
    "                  bidirectional=True, \n",
    "                  name='LSTM', \n",
    "                  cell_type=torch.nn.LSTM)\n",
    "#model(torch.Tensor(variable_text[0]).to(int))\n",
    "model(text_fixed[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1790d12f-d3f9-477e-bbfc-067baadf33c6",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42397b6a-e849-4179-a359-647e902300f4",
   "metadata": {},
   "source": [
    "Train several models on the two dataset variants. Use either of the cell types (LSTM or GRU)\n",
    "* Simple RNN (no stacking, one direction)\n",
    "* Stacked RNN (stacking, one direction)\n",
    "* Bidirectional RNN (no stacking, bidirectional)\n",
    "* Stacked Bidirectional RNN (stacking, bidirectional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1382d9b-3da7-4a5d-a272-7ea53efc5e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#units, name, bidirectional, n_stacks, cell_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07bf0549-2961-432a-a457-9d79bd22f848",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = ['Simple RNN', 'Stacked RNN', 'Bidirectional RNN', 'Stacked Bidirectional RNN']\n",
    "architecture = ['LSTM ', 'GRU ']\n",
    "all_names = [arch + config for arch in architecture for config in configs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a71e161d-5e01-4d4e-8027-4a5a8838c542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models(verbose = False):\n",
    "    super_zip = zip([64] * 8,                                  #units\n",
    "                    all_names,                                 #name\n",
    "                    ([False] * 2 + [True] * 2) * 2,            #bidirectional\n",
    "                    [1, 3] * 4,                                #n_stacks\n",
    "                    [torch.nn.LSTM] * 4 + [torch.nn.GRU] * 4,) #cell_type\n",
    "\n",
    "    models = [\n",
    "        get_model(\n",
    "            units=units,\n",
    "            n_tokens=len(tokenizer.get_vocab()),\n",
    "            n_labels=len(emotions),\n",
    "            name=name,\n",
    "            bidirectional=bidirectional,\n",
    "            n_stacks=n_stacks,\n",
    "            cell_type=cell_type\n",
    "        )\n",
    "        for units, name, bidirectional, n_stacks, cell_type in super_zip\n",
    "    ]\n",
    "    if verbose:\n",
    "        print(*[(model.name, model) for model in models], sep='\\n')\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92142b18-0255-416d-812b-b2cce689196a",
   "metadata": {},
   "source": [
    "Which loss should be used to multilabel classification? Which metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c416bf78-a954-4837-968c-0ff4365d3fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, optimizer, dataloader, batch_size):\n",
    "    \n",
    "    size = len(dataloader)\n",
    "    model.train()\n",
    "\n",
    "    #percent_of_batch = len(training_data) // batch_size / 2\n",
    "    running_loss = 0\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to('cuda'), y.to('cuda')\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y.float())\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # if batch % percent_of_batch == 0:\n",
    "        #     loss = loss.item()\n",
    "        #     print(f\"{model.name} loss: {loss:>7f}\")\n",
    "    return running_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b63491c3-5aa6-4f89-a37d-79a33005ddc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loss_fn, dataloader, metric, tr):\n",
    "    \n",
    "    model.eval()\n",
    "    running_metric = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to('cuda'), y.to('cuda')\n",
    "            y_pred = 1 / (1 + torch.exp(-model(X))) #сигмойдификация\n",
    "            #y_pred = model(X)\n",
    "            #y_pred = ((1 / (1 + np.exp(-y_pred))) > tr).astype(int)\n",
    "            # running_metric += (y.cpu().numpy() == y_pred).mean()\n",
    "            running_metric += metric(y_pred, y)\n",
    "    return running_metric / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25b2824c-1fa5-42a1-bfa8-c17f861ca49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "####optimizer = torch.optim.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1652d9f-816d-4b36-9bf7-21d38e764e2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bob1ch/Рабочий стол/NN-NLP/venv/lib/python3.12/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n",
      "LSTM Simple RNN loss: 0.1597226993171366\n",
      "MultilabelAUROC(): 36.71%\n",
      "----------------------------------------\n",
      "Epoch 1:\n",
      "LSTM Simple RNN loss: 0.15779461290503452\n",
      "MultilabelAUROC(): 36.68%\n",
      "----------------------------------------\n",
      "Epoch 2:\n",
      "LSTM Simple RNN loss: 0.15779245911799547\n",
      "MultilabelAUROC(): 36.72%\n",
      "----------------------------------------\n",
      "Epoch 3:\n",
      "LSTM Simple RNN loss: 0.1577879330489666\n",
      "MultilabelAUROC(): 36.68%\n",
      "----------------------------------------\n",
      "========================================\n",
      "Epoch 0:\n",
      "LSTM Stacked RNN loss: 0.15963342304242634\n",
      "MultilabelAUROC(): 36.68%\n",
      "----------------------------------------\n",
      "Epoch 1:\n",
      "LSTM Stacked RNN loss: 0.15789211999834027\n",
      "MultilabelAUROC(): 36.68%\n",
      "----------------------------------------\n",
      "Epoch 2:\n",
      "LSTM Stacked RNN loss: 0.15784518506838874\n",
      "MultilabelAUROC(): 36.68%\n",
      "----------------------------------------\n",
      "Epoch 3:\n",
      "LSTM Stacked RNN loss: 0.15788035204053488\n",
      "MultilabelAUROC(): 36.68%\n",
      "----------------------------------------\n",
      "========================================\n",
      "Epoch 0:\n",
      "LSTM Bidirectional RNN loss: 0.15923613494235653\n",
      "MultilabelAUROC(): 36.69%\n",
      "----------------------------------------\n",
      "Epoch 1:\n",
      "LSTM Bidirectional RNN loss: 0.15763208403568804\n",
      "MultilabelAUROC(): 36.67%\n",
      "----------------------------------------\n",
      "Epoch 2:\n",
      "LSTM Bidirectional RNN loss: 0.15757450441237314\n",
      "MultilabelAUROC(): 36.68%\n",
      "----------------------------------------\n",
      "Epoch 3:\n",
      "LSTM Bidirectional RNN loss: 0.15752111915612318\n",
      "MultilabelAUROC(): 36.67%\n",
      "----------------------------------------\n",
      "========================================\n",
      "Epoch 0:\n",
      "LSTM Stacked Bidirectional RNN loss: 0.1594349094430404\n",
      "MultilabelAUROC(): 36.68%\n",
      "----------------------------------------\n",
      "Epoch 1:\n",
      "LSTM Stacked Bidirectional RNN loss: 0.1578458193399924\n",
      "MultilabelAUROC(): 36.69%\n",
      "----------------------------------------\n",
      "Epoch 2:\n",
      "LSTM Stacked Bidirectional RNN loss: 0.15780809963470863\n",
      "MultilabelAUROC(): 36.62%\n",
      "----------------------------------------\n",
      "Epoch 3:\n",
      "LSTM Stacked Bidirectional RNN loss: 0.15778231142218488\n",
      "MultilabelAUROC(): 36.68%\n",
      "----------------------------------------\n",
      "========================================\n",
      "Epoch 0:\n",
      "GRU Simple RNN loss: 0.15936243108916395\n",
      "MultilabelAUROC(): 36.53%\n",
      "----------------------------------------\n",
      "Epoch 1:\n",
      "GRU Simple RNN loss: 0.15784158018632383\n",
      "MultilabelAUROC(): 36.59%\n",
      "----------------------------------------\n",
      "Epoch 2:\n",
      "GRU Simple RNN loss: 0.15774505205094774\n",
      "MultilabelAUROC(): 36.62%\n",
      "----------------------------------------\n",
      "Epoch 3:\n",
      "GRU Simple RNN loss: 0.15750702396992333\n",
      "MultilabelAUROC(): 36.61%\n",
      "----------------------------------------\n",
      "========================================\n",
      "Epoch 0:\n",
      "GRU Stacked RNN loss: 0.15906247512221416\n",
      "MultilabelAUROC(): 36.69%\n",
      "----------------------------------------\n",
      "Epoch 1:\n",
      "GRU Stacked RNN loss: 0.15788780411729303\n",
      "MultilabelAUROC(): 36.67%\n",
      "----------------------------------------\n",
      "Epoch 2:\n",
      "GRU Stacked RNN loss: 0.15788128195762474\n",
      "MultilabelAUROC(): 36.73%\n",
      "----------------------------------------\n",
      "Epoch 3:\n",
      "GRU Stacked RNN loss: 0.15783054035275348\n",
      "MultilabelAUROC(): 36.78%\n",
      "----------------------------------------\n",
      "========================================\n",
      "Epoch 0:\n",
      "GRU Bidirectional RNN loss: 0.15938584044817494\n",
      "MultilabelAUROC(): 36.84%\n",
      "----------------------------------------\n",
      "Epoch 1:\n",
      "GRU Bidirectional RNN loss: 0.15777332185590645\n",
      "MultilabelAUROC(): 36.58%\n",
      "----------------------------------------\n",
      "Epoch 2:\n",
      "GRU Bidirectional RNN loss: 0.15767698688401088\n",
      "MultilabelAUROC(): 36.92%\n",
      "----------------------------------------\n",
      "Epoch 3:\n",
      "GRU Bidirectional RNN loss: 0.15727111461438223\n",
      "MultilabelAUROC(): 36.97%\n",
      "----------------------------------------\n",
      "========================================\n",
      "Epoch 0:\n",
      "GRU Stacked Bidirectional RNN loss: 0.1589372757799606\n",
      "MultilabelAUROC(): 36.71%\n",
      "----------------------------------------\n",
      "Epoch 1:\n",
      "GRU Stacked Bidirectional RNN loss: 0.15783852543064755\n",
      "MultilabelAUROC(): 36.72%\n",
      "----------------------------------------\n",
      "Epoch 2:\n",
      "GRU Stacked Bidirectional RNN loss: 0.1577367422657693\n",
      "MultilabelAUROC(): 36.73%\n",
      "----------------------------------------\n",
      "Epoch 3:\n",
      "GRU Stacked Bidirectional RNN loss: 0.15773295013434263\n",
      "MultilabelAUROC(): 36.73%\n",
      "----------------------------------------\n",
      "========================================\n",
      "CPU times: user 21min 29s, sys: 1.2 s, total: 21min 31s\n",
      "Wall time: 21min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#fixed\n",
    "EPOCHS = 4\n",
    "models = get_models()\n",
    "path_to_save = os.path.join(MODEL_PATH, 'fixed_ds')\n",
    "for model in models:\n",
    "    model.to('cuda')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "    \n",
    "    for i in range(EPOCHS):\n",
    "        \n",
    "        train_loss = train(model, loss_fn, optimizer, train_dataloader_fixed, BATCH_SIZE)\n",
    "        metric = MultilabelAUROC(num_labels=len(emotions), average='macro').to('cuda')\n",
    "        #metric = MultilabelAccuracy(criteria=\"hamming\")\n",
    "        train_metric = test(model, loss_fn, test_dataloader_fixed, metric, 0.4)\n",
    "        scheduler.step(train_loss) #надо лосс на валидации сделать\n",
    "        #if not i % 2:\n",
    "        print(f'Epoch {i}:')\n",
    "        print(f'{model.name} loss: {train_loss}')\n",
    "        print(f'{metric}: {train_metric * 100 :.2f}%')\n",
    "        print('-'*40)\n",
    "    torch.save(model.state_dict(), os.path.join(path_to_save, model.name+'.pth'))\n",
    "    print('='*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a258e251-9b44-4a65-b50e-a89e33e3fd2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bob1ch/Рабочий стол/NN-NLP/venv/lib/python3.12/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n",
      "LSTM Simple RNN loss: 0.16082115646670847\n",
      "MultilabelAUROC(): 43.84%\n",
      "----------------------------------------\n",
      "Epoch 1:\n",
      "LSTM Simple RNN loss: 0.15755947425890968\n",
      "MultilabelAUROC(): 43.75%\n",
      "----------------------------------------\n",
      "Epoch 2:\n",
      "LSTM Simple RNN loss: 0.15613359935264318\n",
      "MultilabelAUROC(): 54.50%\n",
      "----------------------------------------\n",
      "Epoch 3:\n",
      "LSTM Simple RNN loss: 0.14334061402296036\n",
      "MultilabelAUROC(): 64.45%\n",
      "----------------------------------------\n",
      "========================================\n",
      "Epoch 0:\n",
      "LSTM Stacked RNN loss: 0.16088350922211833\n",
      "MultilabelAUROC(): 44.27%\n",
      "----------------------------------------\n",
      "Epoch 1:\n",
      "LSTM Stacked RNN loss: 0.15757044198708087\n",
      "MultilabelAUROC(): 44.18%\n",
      "----------------------------------------\n",
      "Epoch 2:\n",
      "LSTM Stacked RNN loss: 0.15763201740361937\n",
      "MultilabelAUROC(): 43.75%\n",
      "----------------------------------------\n",
      "Epoch 3:\n",
      "LSTM Stacked RNN loss: 0.1576433485327257\n",
      "MultilabelAUROC(): 43.90%\n",
      "----------------------------------------\n",
      "========================================\n",
      "Epoch 0:\n",
      "LSTM Bidirectional RNN loss: 0.1608298410931659\n",
      "MultilabelAUROC(): 45.79%\n",
      "----------------------------------------\n",
      "Epoch 1:\n",
      "LSTM Bidirectional RNN loss: 0.15180571615051144\n",
      "MultilabelAUROC(): 59.25%\n",
      "----------------------------------------\n",
      "Epoch 2:\n",
      "LSTM Bidirectional RNN loss: 0.14036069092535344\n",
      "MultilabelAUROC(): 65.06%\n",
      "----------------------------------------\n",
      "Epoch 3:\n",
      "LSTM Bidirectional RNN loss: 0.13227362672346843\n",
      "MultilabelAUROC(): 69.18%\n",
      "----------------------------------------\n",
      "========================================\n",
      "Epoch 0:\n",
      "LSTM Stacked Bidirectional RNN loss: 0.1605809548563696\n",
      "MultilabelAUROC(): 44.29%\n",
      "----------------------------------------\n",
      "Epoch 1:\n",
      "LSTM Stacked Bidirectional RNN loss: 0.15773052734809603\n",
      "MultilabelAUROC(): 43.64%\n",
      "----------------------------------------\n",
      "Epoch 2:\n",
      "LSTM Stacked Bidirectional RNN loss: 0.15765119404950764\n",
      "MultilabelAUROC(): 42.06%\n",
      "----------------------------------------\n",
      "Epoch 3:\n",
      "LSTM Stacked Bidirectional RNN loss: 0.15762345995590282\n",
      "MultilabelAUROC(): 45.45%\n",
      "----------------------------------------\n",
      "========================================\n",
      "Epoch 0:\n",
      "GRU Simple RNN loss: 0.15448589837575297\n",
      "MultilabelAUROC(): 61.41%\n",
      "----------------------------------------\n",
      "Epoch 1:\n",
      "GRU Simple RNN loss: 0.13343771589394757\n",
      "MultilabelAUROC(): 69.54%\n",
      "----------------------------------------\n",
      "Epoch 2:\n",
      "GRU Simple RNN loss: 0.12409218302987733\n",
      "MultilabelAUROC(): 72.88%\n",
      "----------------------------------------\n",
      "Epoch 3:\n",
      "GRU Simple RNN loss: 0.11856481312516576\n",
      "MultilabelAUROC(): 74.72%\n",
      "----------------------------------------\n",
      "========================================\n",
      "Epoch 0:\n",
      "GRU Stacked RNN loss: 0.15819728699908858\n",
      "MultilabelAUROC(): 54.29%\n",
      "----------------------------------------\n",
      "Epoch 1:\n",
      "GRU Stacked RNN loss: 0.14113105493997544\n",
      "MultilabelAUROC(): 65.44%\n",
      "----------------------------------------\n",
      "Epoch 2:\n",
      "GRU Stacked RNN loss: 0.1293200797289912\n",
      "MultilabelAUROC(): 70.91%\n",
      "----------------------------------------\n",
      "Epoch 3:\n",
      "GRU Stacked RNN loss: 0.12140016528784704\n",
      "MultilabelAUROC(): 74.00%\n",
      "----------------------------------------\n",
      "========================================\n",
      "Epoch 0:\n",
      "GRU Bidirectional RNN loss: 0.15316536630666924\n",
      "MultilabelAUROC(): 62.90%\n",
      "----------------------------------------\n",
      "Epoch 1:\n",
      "GRU Bidirectional RNN loss: 0.13237031912928582\n",
      "MultilabelAUROC(): 69.75%\n",
      "----------------------------------------\n",
      "Epoch 2:\n",
      "GRU Bidirectional RNN loss: 0.12360330956702784\n",
      "MultilabelAUROC(): 73.07%\n",
      "----------------------------------------\n",
      "Epoch 3:\n",
      "GRU Bidirectional RNN loss: 0.11806787778651738\n",
      "MultilabelAUROC(): 74.70%\n",
      "----------------------------------------\n",
      "========================================\n",
      "Epoch 0:\n",
      "GRU Stacked Bidirectional RNN loss: 0.1511804355438131\n",
      "MultilabelAUROC(): 62.72%\n",
      "----------------------------------------\n",
      "Epoch 1:\n",
      "GRU Stacked Bidirectional RNN loss: 0.13147403111403017\n",
      "MultilabelAUROC(): 70.96%\n",
      "----------------------------------------\n",
      "Epoch 2:\n",
      "GRU Stacked Bidirectional RNN loss: 0.1215869539478407\n",
      "MultilabelAUROC(): 74.29%\n",
      "----------------------------------------\n",
      "Epoch 3:\n",
      "GRU Stacked Bidirectional RNN loss: 0.11513040225859668\n",
      "MultilabelAUROC(): 76.60%\n",
      "----------------------------------------\n",
      "========================================\n",
      "CPU times: user 21min 42s, sys: 2.79 s, total: 21min 45s\n",
      "Wall time: 21min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#var\n",
    "EPOCHS = 4\n",
    "BATCH_SIZE = BATCH_SIZE\n",
    "models = get_models()\n",
    "path_to_save = os.path.join(MODEL_PATH, 'var_ds')\n",
    "for model in models:\n",
    "    model.to('cuda')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "    \n",
    "    for i in range(EPOCHS):\n",
    "        \n",
    "        train_loss = train(model, loss_fn, optimizer, train_dataloader_var, BATCH_SIZE)\n",
    "        metric = MultilabelAUROC(num_labels=len(emotions), average='macro').to('cuda')\n",
    "        train_metric = test(model, loss_fn, test_dataloader_var, metric, 0.5)\n",
    "        scheduler.step(train_loss)\n",
    "        print(f'Epoch {i}:')\n",
    "        print(f'{model.name} loss: {train_loss}')\n",
    "        print(f'{metric}: {train_metric * 100 :.2f}%')\n",
    "        print('-'*40)\n",
    "    torch.save(model.state_dict(), os.path.join(path_to_save, model.name+'.pth'))\n",
    "    print('='*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f98bb76-0e35-495c-87fe-a0155c3508c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(models, folder):\n",
    "    for model in models:\n",
    "        path = os.path.join(folder, model.name + '.pth')\n",
    "        model.load_state_dict(torch.load(path))\n",
    "        model.eval()\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3efddeac-6174-4c37-a547-b062214ca4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2038/1622655647.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Model(\n",
       "   (embeddings): Embedding(50257, 64)\n",
       "   (rnn): LSTM(64, 128)\n",
       "   (FC): Linear(in_features=128, out_features=28, bias=True)\n",
       " ),\n",
       " Model(\n",
       "   (embeddings): Embedding(50257, 64)\n",
       "   (rnn): LSTM(64, 128, num_layers=3)\n",
       "   (FC): Linear(in_features=128, out_features=28, bias=True)\n",
       " ),\n",
       " Model(\n",
       "   (embeddings): Embedding(50257, 64)\n",
       "   (rnn): LSTM(64, 128, bidirectional=True)\n",
       "   (FC): Linear(in_features=256, out_features=28, bias=True)\n",
       " ),\n",
       " Model(\n",
       "   (embeddings): Embedding(50257, 64)\n",
       "   (rnn): LSTM(64, 128, num_layers=3, bidirectional=True)\n",
       "   (FC): Linear(in_features=256, out_features=28, bias=True)\n",
       " ),\n",
       " Model(\n",
       "   (embeddings): Embedding(50257, 64)\n",
       "   (rnn): GRU(64, 128)\n",
       "   (FC): Linear(in_features=128, out_features=28, bias=True)\n",
       " ),\n",
       " Model(\n",
       "   (embeddings): Embedding(50257, 64)\n",
       "   (rnn): GRU(64, 128, num_layers=3)\n",
       "   (FC): Linear(in_features=128, out_features=28, bias=True)\n",
       " ),\n",
       " Model(\n",
       "   (embeddings): Embedding(50257, 64)\n",
       "   (rnn): GRU(64, 128, bidirectional=True)\n",
       "   (FC): Linear(in_features=256, out_features=28, bias=True)\n",
       " ),\n",
       " Model(\n",
       "   (embeddings): Embedding(50257, 64)\n",
       "   (rnn): GRU(64, 128, num_layers=3, bidirectional=True)\n",
       "   (FC): Linear(in_features=256, out_features=28, bias=True)\n",
       " )]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_models(models, 'models/var_ds/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "597a36ce-01bd-432b-b0f0-015c4c0fa62a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7528, device='cuda:0')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(models[-1].to('cuda'), torch.nn.BCEWithLogitsLoss(), train_dataloader_var, MultilabelAUROC(num_labels=len(emotions), average='macro').to('cuda'), 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d19d6cb-a4b7-415e-9dc6-da3623c5a295",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d9afd3-afb6-4549-9a9f-4eb6102694e1",
   "metadata": {},
   "source": [
    "Evaluate the models you trained on the test datasets. Plot ROC curves for each label (use `sklearn.metrics.RocCurveDisplay`) for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f331fc5c-5d19-4fa8-a5e1-3216d9d4457d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    model: keras.Model,\n",
    "    ax: plt.Axes | None = None\n",
    ") -> float:\n",
    "    '''Plots ROC curves for each of the labels (on a single axes) and outputs mean ROC AUC score.\n",
    "\n",
    "    Arguments:\n",
    "        X: model inputs\n",
    "        y: ground thruths\n",
    "        model: model to plot the curve for\n",
    "        ax: axes to plot on\n",
    "\n",
    "    Returns:\n",
    "        Mean ROC AUC score'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d38c983-510f-47f5-8a11-5344b53c15e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "224c37b8-218a-43d8-b056-2389a3869e8c",
   "metadata": {},
   "source": [
    "Plot the mean ROC AUC scores. Which model has the highest score? On what kind of dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba2b2c8-66ec-40e9-aaec-07ac79c86ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f56b9bca-296b-45cd-be57-6027371d0c5a",
   "metadata": {},
   "source": [
    "Inspect the best model performance closer. Come up with some sentences (in English). Does the model output sensible results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f66686-4319-4762-82d0-963edbad5fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_text(text: str, model: keras.Model, threshold: float = 0.5, max_length: int | None = None) -> list[str]:\n",
    "    '''Computes the model output for `text` and outputs a list of emotions that have a probability of at least `threshold`\n",
    "\n",
    "    Arguments:\n",
    "        text: text to label\n",
    "        model: model to use\n",
    "        threshold: threshold to use\n",
    "        max_length: max length for tokenization\n",
    "    \n",
    "    Return:\n",
    "        List of predicted emotion labels'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b59fe95-b472-4b7b-95f9-23d17bba18db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_emotion_scores(text: str, model: keras.Model, max_length: int | None = None, ax: plt.Axes | None = None):\n",
    "    '''Plots a bar plot of emotion probabilities for given `text` using `model`.\n",
    "\n",
    "    Arguments:\n",
    "        text: text to label\n",
    "        model: model to use        \n",
    "        max_length: max length for tokenization\n",
    "        ax: axes to plot on'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e7a3fd-d086-47da-ab93-4927079cd037",
   "metadata": {},
   "source": [
    "For each of your texts get a list of emotion labels and plot emotion scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ae81dd-ab9c-46a0-825f-ab53b367b75c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c98b8e7f-e826-497c-943a-fe944a4f4ba9",
   "metadata": {},
   "source": [
    "# Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa03eefa-90f1-4be9-9ab0-b17e85993aa1",
   "metadata": {},
   "source": [
    "Train and evaluate the same model as your best one, but use a different cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a1a9da-b0a9-4a4d-9d91-b7061fc903b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
