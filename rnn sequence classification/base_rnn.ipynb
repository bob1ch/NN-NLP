{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f4b7aaf-d09b-4b64-91e6-dee2976ce379",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16f89b44-fede-422c-b525-9a267aad4d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bob1ch/Рабочий стол/NN-NLP/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#import keras\n",
    "import datasets\n",
    "import numpy as np\n",
    "import transformers\n",
    "import sklearn.metrics\n",
    "#import tensorflow as tf\n",
    "import tqdm.notebook as tqdm\n",
    "import sklearn.model_selection\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc4e64b0-7eef-4af2-9906-44c8cdb86c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pytorch\n",
    "import torch\n",
    "#from torchsummary import summary\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d400cd26-730e-4c4e-aaed-5987f78ef5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfb9f8d-1cf5-4954-8b70-18d47dee46e3",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8cc56a-5c94-4134-902d-e74edf1414aa",
   "metadata": {},
   "source": [
    "Load the dataset (we will be using [go_emotions](https://huggingface.co/datasets/google-research-datasets/go_emotions)). Pretokenize data or make a loader that tokenizes the sentenses as you iterate through the dataset. Implement two datasets: variable and fixed sentence length (in tokens). Don't forget to split the dataset into train and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fea15226-0e61-4fcd-a188-d6330e545465",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset('google-research-datasets/go_emotions', name='raw', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b144fe06-9838-4812-9e19-9b74e903bba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = [\n",
    "    'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity',\n",
    "    'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear',\n",
    "    'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief',\n",
    "    'remorse', 'sadness', 'surprise', 'neutral'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "682d6798-62fe-4d5c-8b8b-99394df534ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bob1ch/Рабочий стол/NN-NLP/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50256"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ddcc3ba9-fb2c-40b2-af4b-db4595895756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This person is the smartest person to play town of salem literally 999999999999999999999999999999999999999999999999999999999999999999999999999999999999999991000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001234567898765432345676543345678987654345678909876543234567898765432345678909876543234567898765432345678987654323456787654345676543456543456434543434343434323456765434567654323454323456543345678987654323456789876565656565656565656565656565454545654565454323456765432345678765456 IQ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1212,  1048,   318,   262, 44730,  1048,   284,   711,  3240,   286,\n",
       "          3664,   368,  7360,   860, 24214, 24214, 24214, 24214, 24214, 24214,\n",
       "         24214, 24214, 24214, 24214, 24214, 24214, 24214, 24214, 24214, 24214,\n",
       "         24214, 24214, 24214, 24214, 24214, 24214,    16, 25645, 25645, 25645,\n",
       "         25645, 25645, 25645, 25645, 25645, 25645, 25645, 25645, 25645, 25645,\n",
       "         25645, 25645, 25645,  8269,   405, 10163,  2231, 30924,  4089, 29143,\n",
       "          3559,  1954,  2231,  3134, 39111,  2091,  2231, 30924,  4089, 29143,\n",
       "          3559,  2231,  3134,  4531,  2931,  5774,  2996,  3559,  1954,  2231,\n",
       "         30924,  4089, 29143,  3559,  1954,  2231,  3134,  4531,  2931,  5774,\n",
       "          2996,  3559,  1954,  2231, 30924,  4089, 29143,  3559,  1954,  2231,\n",
       "         30924,  4089, 29143,  3559,  1954,  2231,  3134,  5774,  2996,  3559,\n",
       "          2231,  3134,  2996,  3559,  2231,  2996,  3559,  2231,  2414, 27712,\n",
       "         47101,  2682,  2682,  2682, 32118,  1954,  2231,  3134,  2996,  3559,\n",
       "          2231,  3134,  2996,  3559,  1954,  2231,  3559,  1954,  2231, 39111,\n",
       "          2091,  2231, 30924,  4089, 29143,  3559,  1954,  2231, 30924,  4089,\n",
       "         29143,  2996,  2996,  2996,  2996,  2996,  2996,  2996,  2996,  2996,\n",
       "          2996,  2996,  2996,  2996,  2231,  2231,  2231,  2996,  2231,  2996,\n",
       "          2231,  3559,  1954,  2231,  3134,  2996,  3559,  1954,  2231,  3134,\n",
       "          5774,  2996, 29228, 18248, 50256]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longets_text = dataset['text'][np.argmax(list(map(len, dataset['text'])))]\n",
    "print(longets_text)\n",
    "tokenizer(longets_text, return_tensors='pt', padding='max_length', max_length=185, truncation=True)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "02778ee6-1ff7-4fc9-be85-67c3b4895b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_fixed = tokenizer(dataset['text'], return_tensors='pt', padding='max_length', max_length=128, truncation=True)['input_ids']\n",
    "#text_variable = tokenizer(dataset['text'], return_tensors='pt', truncation=True)['input_ids']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b628be8-1f04-4212-9392-dee3e207f532",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066591d4-60c1-4918-85e7-fafe734d1804",
   "metadata": {},
   "source": [
    "Implement your model. The model should have the RNN architecture (with LSTM or GRU cells), support stacking and bidirectional feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e54e3784-2f24-42a2-a8a0-164378480a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(prefix: str | None = None, suffix: str | None = None, separator: str = '_') -> str | None:\n",
    "    return prefix and prefix + separator + suffix or suffix or None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "90a144e0-b2f7-41a9-8f4f-4a84f40d6077",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, units: int, n_tokens: int, n_labels: int, n_stacks: int, bidirectional: bool, name: str, cell_type):\n",
    "        super(Model, self).__init__()\n",
    "        self.name = name\n",
    "        self.units = units\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        #torch.nn.GRU(input_size, hidden_size, num_layers=1, bias=True, batch_first=False, dropout=0.0, bidirectional=False, device=None, dtype=None)\n",
    "        #torch.nn.LSTM(input_size, hidden_size, num_layers=1, bias=True, batch_first=False, dropout=0.0, bidirectional=False, proj_size=0, device=None, dtype=None)\n",
    "        \n",
    "        self.embeddings = torch.nn.Embedding(n_tokens, units)\n",
    "        self.rnn = cell_type(units, units, num_layers=n_stacks, bidirectional=bidirectional)\n",
    "        self.FC = torch.nn.Linear(units*2 if bidirectional else units, n_labels)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embeds = self.embeddings(text)\n",
    "        embeds = embeds.permute(1, 0, 2)\n",
    "        out, _ = self.rnn(embeds)\n",
    "        out = out[-1]\n",
    "\n",
    "        # if self.bidirectional:\n",
    "        #     return out.shape\n",
    "        #     out = torch.cat((out[0], out[1]), dim=1)\n",
    "\n",
    "        out = self.FC(out)\n",
    "        return out\n",
    "\n",
    "def get_model(\n",
    "    units: int,\n",
    "    n_tokens: int,\n",
    "    n_labels: int,\n",
    "    n_stacks: int = 1,\n",
    "    bidirectional: bool = False,\n",
    "    name: str | None = None,\n",
    "    cell_type: type[torch.nn.modules] = torch.nn.LSTM\n",
    ") -> torch.nn.Module:\n",
    "    '''Creates a model with RNN architecture for sequence multilabel classification.\n",
    "\n",
    "    Arguments:\n",
    "        units: dimensionality of RNN cells OR units: Positive integer, dimensionality of the output space\n",
    "        n_tokens: number of tokens in the tokenizer dictionary\n",
    "        n_labels: number of labels to be predicted\n",
    "        n_stacks: number of RNN cells in the stack (1 -- no stacking)\n",
    "        bidirectional: whether or not the model is bidirectional\n",
    "        name: the model name\n",
    "        cell_type: type of a cell to use, either keras.layers.LSTMCell or keras.layers.GRUCell\n",
    "\n",
    "    Returns:\n",
    "        The model'''\n",
    "    return Model(units, n_tokens, n_labels, n_stacks, bidirectional, name, cell_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f1d16ca7-0bcd-4213-a3cd-1b3d35662079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0513, -0.0866, -0.0917,  0.0040, -0.0494,  0.0126, -0.0477, -0.0015,\n",
       "          0.0725,  0.0641,  0.0749, -0.0691,  0.0195,  0.0304,  0.0627, -0.0181,\n",
       "          0.0173, -0.0354, -0.0221,  0.0750, -0.0240,  0.0331, -0.0431, -0.0543,\n",
       "         -0.0012,  0.0021, -0.0939, -0.1041],\n",
       "        [ 0.0513, -0.0866, -0.0917,  0.0040, -0.0494,  0.0126, -0.0477, -0.0015,\n",
       "          0.0725,  0.0641,  0.0749, -0.0691,  0.0195,  0.0304,  0.0627, -0.0181,\n",
       "          0.0173, -0.0354, -0.0221,  0.0750, -0.0240,  0.0331, -0.0431, -0.0543,\n",
       "         -0.0012,  0.0021, -0.0939, -0.1041],\n",
       "        [ 0.0513, -0.0866, -0.0917,  0.0040, -0.0494,  0.0126, -0.0477, -0.0015,\n",
       "          0.0725,  0.0641,  0.0749, -0.0691,  0.0195,  0.0304,  0.0627, -0.0181,\n",
       "          0.0173, -0.0354, -0.0221,  0.0750, -0.0240,  0.0331, -0.0431, -0.0543,\n",
       "         -0.0012,  0.0021, -0.0939, -0.1041]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(units=64, \n",
    "                  n_tokens=len(tokenizer.vocab), \n",
    "                  n_labels=len(emotions), \n",
    "                  n_stacks=100, \n",
    "                  bidirectional=True, \n",
    "                  name='LSTM', \n",
    "                  cell_type=torch.nn.LSTM)\n",
    "model(text_fixed[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3c83d87a-bdc5-4e09-bb5d-eb66114194ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embeddings): Embedding(50257, 64)\n",
       "  (rnn): LSTM(64, 64)\n",
       "  (FC): Linear(in_features=64, out_features=28, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1790d12f-d3f9-477e-bbfc-067baadf33c6",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42397b6a-e849-4179-a359-647e902300f4",
   "metadata": {},
   "source": [
    "Train several models on the two dataset variants. Use either of the cell types (LSTM or GRU)\n",
    "* Simple RNN (no stacking, one direction)\n",
    "* Stacked RNN (stacking, one direction)\n",
    "* Bidirectional RNN (no stacking, bidirectional)\n",
    "* Stacked Bidirectional RNN (stacking, bidirectional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1382d9b-3da7-4a5d-a272-7ea53efc5e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "units, name, bidirectional, n_stacks, cell_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "20f7972c-7bf0-41cc-a31b-24231234998a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LSTM Simple RNN',\n",
       " 'LSTM Stacked RNN',\n",
       " 'LSTM Bidirectional RNN',\n",
       " 'LSTM Stacked Bidirectional RNN',\n",
       " 'GRU Simple RNN',\n",
       " 'GRU Stacked RNN',\n",
       " 'GRU Bidirectional RNN',\n",
       " 'GRU Stacked Bidirectional RNN']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_names = list(zip(['LSTM '] * 4, ['Simple RNN', 'Stacked RNN', 'Bidirectional RNN', 'Stacked Bidirectional RNN'])) + list(zip(['GRU '] * 4, ['Simple RNN', 'Stacked RNN', 'Bidirectional RNN', 'Stacked Bidirectional RNN']))\n",
    "all_names = list(map(lambda x: x[0] + x[1], all_names))\n",
    "all_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8c1adf9c-7fa3-4748-a74d-8bb820091197",
   "metadata": {},
   "outputs": [],
   "source": [
    "super_zip = zip([64] * 8,\n",
    "all_names,\n",
    "([False] * 2 + [True] * 2) * 2,\n",
    "[1, 3] * 4,\n",
    "[torch.nn.LSTM] * 4 + [torch.nn.GRU] * 4,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ba388137-37d7-4690-9234-47c992238a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(super_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a71e161d-5e01-4d4e-8027-4a5a8838c542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(\n",
       "   (embeddings): Embedding(50257, 64)\n",
       "   (rnn): LSTM(64, 64)\n",
       "   (FC): Linear(in_features=64, out_features=28, bias=True)\n",
       " ),\n",
       " Model(\n",
       "   (embeddings): Embedding(50257, 64)\n",
       "   (rnn): LSTM(64, 64, num_layers=3)\n",
       "   (FC): Linear(in_features=64, out_features=28, bias=True)\n",
       " ),\n",
       " Model(\n",
       "   (embeddings): Embedding(50257, 64)\n",
       "   (rnn): LSTM(64, 64, bidirectional=True)\n",
       "   (FC): Linear(in_features=128, out_features=28, bias=True)\n",
       " ),\n",
       " Model(\n",
       "   (embeddings): Embedding(50257, 64)\n",
       "   (rnn): LSTM(64, 64, num_layers=3, bidirectional=True)\n",
       "   (FC): Linear(in_features=128, out_features=28, bias=True)\n",
       " ),\n",
       " Model(\n",
       "   (embeddings): Embedding(50257, 64)\n",
       "   (rnn): GRU(64, 64)\n",
       "   (FC): Linear(in_features=64, out_features=28, bias=True)\n",
       " ),\n",
       " Model(\n",
       "   (embeddings): Embedding(50257, 64)\n",
       "   (rnn): GRU(64, 64, num_layers=3)\n",
       "   (FC): Linear(in_features=64, out_features=28, bias=True)\n",
       " ),\n",
       " Model(\n",
       "   (embeddings): Embedding(50257, 64)\n",
       "   (rnn): GRU(64, 64, bidirectional=True)\n",
       "   (FC): Linear(in_features=128, out_features=28, bias=True)\n",
       " ),\n",
       " Model(\n",
       "   (embeddings): Embedding(50257, 64)\n",
       "   (rnn): GRU(64, 64, num_layers=3, bidirectional=True)\n",
       "   (FC): Linear(in_features=128, out_features=28, bias=True)\n",
       " )]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "super_zip = zip([64] * 8,                                  #units\n",
    "                all_names,                                 #name\n",
    "                ([False] * 2 + [True] * 2) * 2,            #bidirectional\n",
    "                [1, 3] * 4,                                #n_stacks\n",
    "                [torch.nn.LSTM] * 4 + [torch.nn.GRU] * 4,) #cell_type\n",
    "\n",
    "models = [\n",
    "    get_model(\n",
    "        units=units,\n",
    "        n_tokens=len(tokenizer.get_vocab()),\n",
    "        n_labels=len(emotions),\n",
    "        name=name,\n",
    "        bidirectional=bidirectional,\n",
    "        n_stacks=n_stacks,\n",
    "        cell_type=cell_type\n",
    "    )\n",
    "    for units, name, bidirectional, n_stacks, cell_type in super_zip\n",
    "]\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92142b18-0255-416d-812b-b2cce689196a",
   "metadata": {},
   "source": [
    "Which loss should be used to multilabel classification? Which metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3493fca9-bd27-4ae1-845e-13a621cc06f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    model.compile(\n",
    "        loss=torch.nn.BCEWithLogitsLoss(),\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            ...\n",
    "        ),\n",
    "        metrics=[\n",
    "            ...\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d844e36e-34a4-4a42-8818-96d88ad9ef7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_dataset, test_dataset in datasets:\n",
    "    for model in models:\n",
    "        model.fit(train_dataset, validation_data=test_dataset, epochs=...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d19d6cb-a4b7-415e-9dc6-da3623c5a295",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d9afd3-afb6-4549-9a9f-4eb6102694e1",
   "metadata": {},
   "source": [
    "Evaluate the models you trained on the test datasets. Plot ROC curves for each label (use `sklearn.metrics.RocCurveDisplay`) for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f331fc5c-5d19-4fa8-a5e1-3216d9d4457d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    model: keras.Model,\n",
    "    ax: plt.Axes | None = None\n",
    ") -> float:\n",
    "    '''Plots ROC curves for each of the labels (on a single axes) and outputs mean ROC AUC score.\n",
    "\n",
    "    Arguments:\n",
    "        X: model inputs\n",
    "        y: ground thruths\n",
    "        model: model to plot the curve for\n",
    "        ax: axes to plot on\n",
    "\n",
    "    Returns:\n",
    "        Mean ROC AUC score'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d38c983-510f-47f5-8a11-5344b53c15e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "224c37b8-218a-43d8-b056-2389a3869e8c",
   "metadata": {},
   "source": [
    "Plot the mean ROC AUC scores. Which model has the highest score? On what kind of dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba2b2c8-66ec-40e9-aaec-07ac79c86ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f56b9bca-296b-45cd-be57-6027371d0c5a",
   "metadata": {},
   "source": [
    "Inspect the best model performance closer. Come up with some sentences (in English). Does the model output sensible results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f66686-4319-4762-82d0-963edbad5fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_text(text: str, model: keras.Model, threshold: float = 0.5, max_length: int | None = None) -> list[str]:\n",
    "    '''Computes the model output for `text` and outputs a list of emotions that have a probability of at least `threshold`\n",
    "\n",
    "    Arguments:\n",
    "        text: text to label\n",
    "        model: model to use\n",
    "        threshold: threshold to use\n",
    "        max_length: max length for tokenization\n",
    "    \n",
    "    Return:\n",
    "        List of predicted emotion labels'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b59fe95-b472-4b7b-95f9-23d17bba18db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_emotion_scores(text: str, model: keras.Model, max_length: int | None = None, ax: plt.Axes | None = None):\n",
    "    '''Plots a bar plot of emotion probabilities for given `text` using `model`.\n",
    "\n",
    "    Arguments:\n",
    "        text: text to label\n",
    "        model: model to use        \n",
    "        max_length: max length for tokenization\n",
    "        ax: axes to plot on'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e7a3fd-d086-47da-ab93-4927079cd037",
   "metadata": {},
   "source": [
    "For each of your texts get a list of emotion labels and plot emotion scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ae81dd-ab9c-46a0-825f-ab53b367b75c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c98b8e7f-e826-497c-943a-fe944a4f4ba9",
   "metadata": {},
   "source": [
    "# Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa03eefa-90f1-4be9-9ab0-b17e85993aa1",
   "metadata": {},
   "source": [
    "Train and evaluate the same model as your best one, but use a different cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a1a9da-b0a9-4a4d-9d91-b7061fc903b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
